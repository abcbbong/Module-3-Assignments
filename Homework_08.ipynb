{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 08: Classification\n",
    "\n",
    "**Due:** Midnight on June 11th, BUT no late points will be charged if you get it in by the last late deadline. \n",
    "\n",
    "### Overview\n",
    "\n",
    "In this final homework before starting our course project, we will introduce the essential machine learning paradigm of **classification**. We will work with the **UCI Adult** dataset. This is a binary classification task.\n",
    "\n",
    "As we’ve discussed in this week’s lessons, the classification workflow is similar to what we’ve done for regression, with a few key differences:\n",
    "- We use `StratifiedKFold` instead of plain `KFold` so that every fold keeps the original class proportions.\n",
    "- We use classification metrics (e.g., accuracy, precision, recall, F1-score for binary classification) instead of regression metrics.\n",
    "- We could explore misclassified instances through a confusion matrix (though we will not do that in this homework).\n",
    "\n",
    "For this assignment, you’ll build a gradient boosting classification using `HistGradientBoostingClassifier` (HGBC) and explore ways of tuning the hyperparameters, including using the technique of early stopping, which basically avoiding have to tune the number of estimators (called `max_iter` in HGBC). \n",
    "\n",
    "HGBC has many advantages, which we explain below. \n",
    "\n",
    "\n",
    "### Grading\n",
    "\n",
    "There are 7 graded problems, each worth 7 points, and you get 1 point free if you complete the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abcbb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General utilities\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import zipfile\n",
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# Data handling and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    " \n",
    "# Data source\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    " \n",
    "# scikit-learn core tools \n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    " \n",
    "# Import model \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    " \n",
    "# Metrics\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    " \n",
    "# Distributions for random search\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "\n",
    "# pandas dtypes helpers\n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "from pandas import CategoricalDtype\n",
    "\n",
    "# Optuna Hyperparameter Search tool    (may need to be installed)\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Misc\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "def format_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelude 1: Load and Preprocess the UCI Adult Income Dataset\n",
    "\n",
    "- Load the dataset from sklearn\n",
    "- Preliminary EDA\n",
    "- Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   age             48842 non-null  int64   \n",
      " 1   workclass       46043 non-null  category\n",
      " 2   fnlwgt          48842 non-null  int64   \n",
      " 3   education       48842 non-null  category\n",
      " 4   education-num   48842 non-null  int64   \n",
      " 5   marital-status  48842 non-null  category\n",
      " 6   occupation      46033 non-null  category\n",
      " 7   relationship    48842 non-null  category\n",
      " 8   race            48842 non-null  category\n",
      " 9   sex             48842 non-null  category\n",
      " 10  capital-gain    48842 non-null  int64   \n",
      " 11  capital-loss    48842 non-null  int64   \n",
      " 12  hours-per-week  48842 non-null  int64   \n",
      " 13  native-country  47985 non-null  category\n",
      " 14  class           48842 non-null  category\n",
      "dtypes: category(9), int64(6)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Load and clean\n",
    "df = fetch_openml(name='adult', version=2, as_frame=True).frame\n",
    "\n",
    "df.replace(\"?\", np.nan, inplace=True)            # Some datasets use ? instead of Nan for missing data\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check: Is the dataset imbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "<=50K    0.760718\n",
      ">50K     0.239282\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YES:** It looks like this dataset is somewhat imbalanced. Therefore, we will \n",
    "1. Tell the model to compensate during training by setting `class_weight='balanced'` when defining the model;\n",
    "2. Evaluate it `balanced_accuracy` instead of `accuracy` and with class-aware metrics (precision, recall, F1); and\n",
    "3. [Optional] Adjust the probability threshold instead of relying on raw accuracy alone after examining the precision-recall trade-off you observe at 0.5.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Based on the considerations in **Appendix One**, we'll make the following changes to the dataset to facilitate training:\n",
    "\n",
    "\n",
    "1. Drop `fnlwgt` and `education`.   \n",
    "3. Replace `capital-gain` and `capital-loss` by their difference `capital_net` and add a log-scaled version `capital_net_log`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   age              48842 non-null  int64   \n",
      " 1   workclass        46043 non-null  category\n",
      " 2   education-num    48842 non-null  int64   \n",
      " 3   marital-status   48842 non-null  category\n",
      " 4   occupation       46033 non-null  category\n",
      " 5   relationship     48842 non-null  category\n",
      " 6   race             48842 non-null  category\n",
      " 7   sex              48842 non-null  category\n",
      " 8   hours-per-week   48842 non-null  int64   \n",
      " 9   native-country   47985 non-null  category\n",
      " 10  class            48842 non-null  category\n",
      " 11  capital_net      48842 non-null  int64   \n",
      " 12  capital_net_log  48842 non-null  float64 \n",
      "dtypes: category(8), float64(1), int64(4)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop the survey-weight column\n",
    "df_eng = df.drop(columns=[\"fnlwgt\"])\n",
    "\n",
    "# Keep only the ordinal education feature\n",
    "df_eng = df_eng.drop(columns=[\"education\"])      # retain 'education-num'\n",
    "\n",
    "# Combine capital gains and losses, add a log-scaled variant\n",
    "df_eng[\"capital_net\"]     = df_eng[\"capital-gain\"] - df_eng[\"capital-loss\"]\n",
    "df_eng[\"capital_net_log\"] = np.log1p(df_eng[\"capital_net\"].clip(lower=0))\n",
    "df_eng = df_eng.drop(columns=[\"capital-gain\", \"capital-loss\"])\n",
    "\n",
    "# check\n",
    "df_eng.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate target and split\n",
    "\n",
    "Create the feature set `X` and the target set `y` (using `class` as the target) and split the dataset into 80% training and 20% testing sets, making sure to stratify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (39073, 12) (39073,)\n",
      "Test : (9769, 12) (9769,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_eng.drop(columns=[\"class\"])\n",
    "y = (df_eng[\"class\"] == \">50K\").astype(int)\n",
    "\n",
    "# Split (with stratification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=random_seed,\n",
    "    stratify=y                           # So same proportion of classes in train and test sets\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test :\", X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelude 2: Create a data pipeline and the `HistGradientBoostingClassifier` model\n",
    "\n",
    "Histogram-based gradient boosting improves on the standard version by:\n",
    "\n",
    "* **Histogram splits:** bins each feature into ≤ `max_bins` quantiles (i.e., each bin is approximately the same size) and tests splits only between bins, slashing compute time and scaling to large data sets. Default for `max_bins` = 255. \n",
    "* **Native NaN handling:** treats missing values as their own bin—no imputation needed.\n",
    "* **Native Categorical Support**: accepts integer-encoded categories directly and tests “category c vs. all others” splits, eliminating one-hot blow-ups and fake orderings.\n",
    "* **Built-in early stopping:** stops training after no improvement in validation loss after `n_iter_no_change` rounds. `tol` defines \"improvement\" (default is 1e-7). \n",
    "* **Leaf shrinkage:** adds `l2_regularization`, which ridge-shrinks each leaf value (without changing tree shape) so tiny, noisy leaves have less effect.\n",
    "\n",
    ">**Summary:**  Histogram-based GB trades a tiny approximation error (binning) for a **huge speed-up** and adds extra conveniences, making it the preferred choice for large tabular data sets. Tuning workflow relies on **Early stopping** to stop training before overfitting occurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a baseline model \n",
    "\n",
    "HGBC_model = HistGradientBoostingClassifier(\n",
    "    # tree structure and learning rate\n",
    "    learning_rate=0.1,            # These 5 parameters are at defaults for our baseline training in Problem 1             \n",
    "    max_leaf_nodes=31,            # but will be tuned by randomized search in Problem 2 and Optuna in Problem 3               \n",
    "    max_depth=None,               \n",
    "    min_samples_leaf=20,          \n",
    "    l2_regularization=0.0,        \n",
    "\n",
    "    # bins and iteration\n",
    "    max_bins=255,                 # default\n",
    "    max_iter=500,                 # high enough for early stopping\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    validation_fraction=0.2,      # 20% monitored for early stopping\n",
    "    tol=1e-7,                     # default tolerance for validation improvement\n",
    "\n",
    "    # class imbalance\n",
    "    class_weight=\"balanced\",\n",
    "\n",
    "    random_state=random_seed,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline appropriate for HGBC \n",
    "\n",
    "**Why use a `Pipeline` instead of encoding in the dataset first?**\n",
    "\n",
    "* **Avoid data leakage.** In each CV fold, the `OrdinalEncoder` is refit only on that fold’s training data, so the validation split never influences the encoder.\n",
    "* **Single, reusable object.** The pipeline bundles preprocessing + model, letting you call `fit`/`predict` on raw data anywhere (CV, Optuna, production) with identical behavior.\n",
    "* **Compatible with search tools.** `cross_validate`, `GridSearchCV`, and Optuna expect an estimator that can be cloned and refit; a pipeline meets that requirement automatically.\n",
    "\n",
    "Put simply, the pipeline gives you leak-free evaluation and portable, hassle-free tuning without extra code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",   # Allow unseen categories during transform\n",
    "    unknown_value=-1,                     # Code for unseen categories\n",
    "    encoded_missing_value=-2,             # Code for missing values (NaN)\n",
    "    dtype=np.int64                        # Needed for HistGradientBoostingClassifier\n",
    ")\n",
    "\n",
    "# Categorical features\n",
    "cat_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "# Numeric features (everything that isn’t object / category)\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [(\"cat\", enc, cat_cols),\n",
    "     (\"num\", \"passthrough\", num_cols)]\n",
    ")\n",
    "\n",
    "pipelined_model = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"gb\",   HGBC_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Baseline Cross-Validation with F1\n",
    "\n",
    "In this problem, you will run a baseline cross-validation evaluation of your `HistGradientBoostingClassifier` pipeline, using `HGBC_model` defined above. \n",
    "\n",
    "**Background:**\n",
    "\n",
    "* Since the Adult dataset is imbalanced (about 24% positives, 76% negatives), accuracy alone is not reliable.\n",
    "* We will use the **F1 score** as the evaluation metric, since it balances precision (avoiding false positives) and recall (avoiding false negatives) in a single measure. This is a fairer metric for imbalanced classification, where both types of error matter.\n",
    "* We will apply **5-fold stratified cross-validation** to make sure each fold has the same proportion of the classes as the original dataset.\n",
    "* Repeated cross-validation is optional and not required here, because the Adult dataset is large and `HistGradientBoostingClassifier` is robust to small sampling differences. \n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Set up a `StratifiedKFold` cross-validation object with 5 splits, shuffling enabled, and `random_state=random_seed`.\n",
    "2. Use `cross_val_score` to estimate the mean F1 score and its standard deviation across the folds.\n",
    "3. Print out the mean and standard deviation of the F1 score, rounded to 4 decimal places.\n",
    "4. Answer the graded question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basesline F1 Score: 0.7123 +/- 0.0035\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "#Set up the 5 fold stratified cross-validation\n",
    "skf = StratifiedKFold(\n",
    "    n_splits = 5,\n",
    "    shuffle= True,\n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "# Calculate F1 scores using cross-validation\n",
    "#The peplnined_model bundles preprocessing and HGBC model.\n",
    "#cv=skf ensure straified splits are used\n",
    "#scoring='f1' specified the evalusation metric\n",
    "f1_scores = cross_val_score(\n",
    "    pipelined_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "# Calculate the mean and standard deviation of the F1 scores\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "# Print the results, formatted to 4 decical places\n",
    "print(f\"Basesline F1 Score: {mean_f1:.4f} +/- {std_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Graded Answer\n",
    "\n",
    "Set `a1` to the mean F1 score of the baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a1 = mean_f1                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = 0.7123\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a1 = {a1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Hyperparameter Optimization with Randomized Search for F1\n",
    "\n",
    "In this problem, you will tune your `pipelined_model` using `RandomizedSearchCV` to identify the best combination of tree structure and learning rate parameters that maximize the **F1 score**.\n",
    "\n",
    "**Background:**\n",
    "The F1 score is our main metric because it balances precision and recall on an imbalanced dataset. Optimizing hyperparameters for F1 ensures we manage both false positives and false negatives in a single measure.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Set up a randomized search over the following hyperparameter ranges, using appropriate random-number distributions:\n",
    "\n",
    "   * `learning_rate` (log-uniform between 1e-3 and 0.3)\n",
    "   * `max_leaf_nodes` (integer from 16 to 256)\n",
    "   * `max_depth` (integer from 2 to 10)\n",
    "   * `min_samples_leaf` (integer from 10 to 200)\n",
    "   * `l2_regularization` (uniform between 0.0 and 2.0)\n",
    "2. Use **5-fold stratified cross-validation**, with the same settings as in Problem 1.\n",
    "3. Set `n_iter` to at least 100 trials. More trials will generally yield better results, if your time and machine allow.\n",
    "4. After running the search, show a neatly formatted table of the top 5 results, using `display(...)` showing their mean F1 scores, standard deviation, and the chosen hyperparameter values.\n",
    "5. Answer the graded question.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Search completed in 00:01:28.\n",
      "\n",
      "Top-5 parameter sets by mean F1:\n",
      " mean_test_score  std_test_score  param_gb__learning_rate  param_gb__max_leaf_nodes  param_gb__max_depth  param_gb__min_samples_leaf  param_gb__l2_regularization\n",
      "        0.712122        0.003238                 0.255401                        27                    5                          48                     0.727259\n",
      "        0.712020        0.003146                 0.166921                       175                    6                          18                     0.186206\n",
      "        0.711805        0.003347                 0.243783                       131                    2                         169                     1.933310\n",
      "        0.711772        0.003205                 0.101566                       167                    2                          22                     1.618722\n",
      "        0.711707        0.002373                 0.218286                       143                    5                         169                     1.887783\n",
      "\n",
      "Best params: {'gb__l2_regularization': 0.727259204758588, 'gb__learning_rate': 0.2554006816661351, 'gb__max_depth': 5, 'gb__max_leaf_nodes': 27, 'gb__min_samples_leaf': 48}\n",
      "Best mean CV F1: 0.7121222889240192\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "# The 'gb__' prefix targets the 'gb' (HistGradientBosstingClassifier) setp in the pipeline.\n",
    "param_dist_rs = {\n",
    "    'gb__learning_rate': loguniform(1e-3, 0.3),\n",
    "    'gb__max_leaf_nodes': randint(16, 256),\n",
    "    'gb__max_depth': randint(2, 10),\n",
    "    'gb__min_samples_leaf': randint(10, 200),\n",
    "    'gb__l2_regularization': uniform(0.0, 2.0)\n",
    "}\n",
    "\n",
    "# Set up the same stratified K-fold cross-validator as before\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "# Set up RandomizedSearchCV to find the best F1 score\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipelined_model,      # pipeline object created earlier\n",
    "    param_distributions=param_dist_rs,\n",
    "    n_iter=100,\n",
    "    scoring=\"f1\",\n",
    "    cv=skf,\n",
    "    random_state=random_seed,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Running RandomizedSearchCV...\")\n",
    "# Start the Timer\n",
    "start_time_rs = time.time()\n",
    "\n",
    "# Fit the model to the training data to start the search.\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time_rs = time.time() - start_time_rs\n",
    "print(f\"Search completed in {format_hms(elapsed_time_rs)}.\")\n",
    "\n",
    "# Creaate a df with the results for easy viewing\n",
    "rs_results_df = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "# Define columns to display for clarity\n",
    "cols_to_show = [\n",
    "    'mean_test_score', 'std_test_score', 'param_gb__learning_rate',\n",
    "    'param_gb__max_leaf_nodes', 'param_gb__max_depth', 'param_gb__min_samples_leaf',\n",
    "    'param_gb__l2_regularization'\n",
    "]\n",
    "\n",
    "# Sort by the best mean test score and display the top 5 results\n",
    "top_5_rs_results = rs_results_df.sort_values(by='mean_test_score', ascending=False)[cols_to_show].head(5)\n",
    "\n",
    "print(\"\\nTop-5 parameter sets by mean F1:\")\n",
    "print(top_5_rs_results.to_string(index=False))\n",
    "\n",
    "print(\"\\nBest params:\", random_search.best_params_)\n",
    "print(\"Best mean CV F1:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Graded Answer\n",
    "\n",
    "Set `a2` to the mean F1 score of the best model found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a2 = random_search.best_score_                  # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = 0.7121\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a2 = {a2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Hyperparameter Optimization with Optuna for F1\n",
    "\n",
    "In this problem, you will explore **Optuna**, a powerful hyperparameter optimization framework, to identify the best combination of hyperparameters that maximize the F1 score of your `pipelined_model`.\n",
    "\n",
    "**Background:**\n",
    "Optuna uses a smarter sampling strategy than grid search or randomized search, allowing you to explore the hyperparameter space more efficiently. It also supports *pruning*, which can stop unpromising trials early to save time. This makes it a popular SOTA optimization tool.\n",
    "\n",
    "**Before you start** browse the [Optuna documentation](https://optuna.org) and view the [tutorial video](https://optuna.readthedocs.io/en/stable/tutorial/index.html). \n",
    "\n",
    "As before, we focus on the **F1 score** because it balances precision and recall, making it more robust on an imbalanced dataset.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Define an Optuna objective function to optimize F1 score, sampling the exact same hyperparameter ranges you did in Problem 2 and using the same CV settings.  \n",
    "3. Set up an Optuna study with a reasonable number of trials (e.g., 100–500 depending on runtime resources--on my machine Optuna runs about 10x faster than randomized search for the same number of trials, but YMMV).\n",
    "4. After running the optimization, `display` a clean table with the top 5 trials showing their F1 scores and corresponding hyperparameter settings.\n",
    "5. Answer the graded question. \n",
    "\n",
    "**Note:**  There are many resources on Optuna you can find on the web, but for this problem, you have my permission to let ChatGPT write the code for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 21:32:33,339] A new study created in memory with name: hgbc_f1_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Optuna Search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 21:32:41,055] Trial 0 finished with value: 0.6842014766177479 and parameters: {'learning_rate': 0.005386035226911338, 'max_leaf_nodes': 233, 'max_depth': 7, 'min_samples_leaf': 60, 'l2_regularization': 1.8883510548893858}. Best is trial 0 with value: 0.6842014766177479.\n",
      "[I 2025-07-03 21:32:43,182] Trial 1 finished with value: 0.7047475986302517 and parameters: {'learning_rate': 0.07603013758078839, 'max_leaf_nodes': 137, 'max_depth': 2, 'min_samples_leaf': 127, 'l2_regularization': 1.6910158791692909}. Best is trial 1 with value: 0.7047475986302517.\n",
      "[I 2025-07-03 21:32:45,583] Trial 2 finished with value: 0.7114868872260057 and parameters: {'learning_rate': 0.09954538080147463, 'max_leaf_nodes': 210, 'max_depth': 10, 'min_samples_leaf': 125, 'l2_regularization': 0.896726908095917}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:32:54,299] Trial 3 finished with value: 0.6743205677936676 and parameters: {'learning_rate': 0.0026461421053951195, 'max_leaf_nodes': 194, 'max_depth': 9, 'min_samples_leaf': 184, 'l2_regularization': 1.6467036806333806}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:01,747] Trial 4 finished with value: 0.7008893295160024 and parameters: {'learning_rate': 0.01346382690322936, 'max_leaf_nodes': 173, 'max_depth': 10, 'min_samples_leaf': 199, 'l2_regularization': 0.3313224438952709}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:04,262] Trial 5 finished with value: 0.7101021636475915 and parameters: {'learning_rate': 0.10590309639348672, 'max_leaf_nodes': 149, 'max_depth': 7, 'min_samples_leaf': 182, 'l2_regularization': 0.2689601418225267}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:06,515] Trial 6 finished with value: 0.7112776550750534 and parameters: {'learning_rate': 0.10249005779597481, 'max_leaf_nodes': 185, 'max_depth': 6, 'min_samples_leaf': 87, 'l2_regularization': 0.3357913196814144}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:09,412] Trial 7 finished with value: 0.7099948465989577 and parameters: {'learning_rate': 0.09531159625823978, 'max_leaf_nodes': 218, 'max_depth': 6, 'min_samples_leaf': 90, 'l2_regularization': 1.4039043210123163}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:11,614] Trial 8 finished with value: 0.6747194361637776 and parameters: {'learning_rate': 0.013369150405914468, 'max_leaf_nodes': 221, 'max_depth': 2, 'min_samples_leaf': 147, 'l2_regularization': 0.6431283222698723}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:25,244] Trial 9 finished with value: 0.6817010106041288 and parameters: {'learning_rate': 0.003963043410044257, 'max_leaf_nodes': 193, 'max_depth': 10, 'min_samples_leaf': 73, 'l2_regularization': 1.33613618223266}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:26,430] Trial 10 finished with value: 0.7112331388883756 and parameters: {'learning_rate': 0.22369693306447017, 'max_leaf_nodes': 57, 'max_depth': 4, 'min_samples_leaf': 33, 'l2_regularization': 0.965290648868495}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:30,348] Trial 11 finished with value: 0.7061757740355892 and parameters: {'learning_rate': 0.02616420153526974, 'max_leaf_nodes': 87, 'max_depth': 5, 'min_samples_leaf': 123, 'l2_regularization': 0.040818814801362735}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:31,617] Trial 12 finished with value: 0.7112197175540332 and parameters: {'learning_rate': 0.2682132817746138, 'max_leaf_nodes': 108, 'max_depth': 8, 'min_samples_leaf': 11, 'l2_regularization': 0.8033991778580004}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:35,148] Trial 13 finished with value: 0.708829565644181 and parameters: {'learning_rate': 0.03561182866778435, 'max_leaf_nodes': 168, 'max_depth': 5, 'min_samples_leaf': 145, 'l2_regularization': 0.5737280512766701}. Best is trial 2 with value: 0.7114868872260057.\n",
      "[I 2025-07-03 21:33:39,505] Trial 14 finished with value: 0.7118900766546595 and parameters: {'learning_rate': 0.05913348454533773, 'max_leaf_nodes': 252, 'max_depth': 8, 'min_samples_leaf': 100, 'l2_regularization': 1.1740195759199925}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:33:49,773] Trial 15 finished with value: 0.6696333326946468 and parameters: {'learning_rate': 0.0012658322508700935, 'max_leaf_nodes': 252, 'max_depth': 9, 'min_samples_leaf': 111, 'l2_regularization': 1.2066087915482486}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:33:54,121] Trial 16 finished with value: 0.7106645720884284 and parameters: {'learning_rate': 0.04562900676012124, 'max_leaf_nodes': 232, 'max_depth': 8, 'min_samples_leaf': 157, 'l2_regularization': 1.140778651778022}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:33:55,699] Trial 17 finished with value: 0.7089978415934909 and parameters: {'learning_rate': 0.19749654630137825, 'max_leaf_nodes': 253, 'max_depth': 9, 'min_samples_leaf': 49, 'l2_regularization': 0.9331161579311501}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:00,404] Trial 18 finished with value: 0.7110810635127776 and parameters: {'learning_rate': 0.05291932687732596, 'max_leaf_nodes': 210, 'max_depth': 10, 'min_samples_leaf': 95, 'l2_regularization': 1.519960460808058}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:04,621] Trial 19 finished with value: 0.7081717626103258 and parameters: {'learning_rate': 0.029135518389276083, 'max_leaf_nodes': 18, 'max_depth': 8, 'min_samples_leaf': 118, 'l2_regularization': 0.759421828347568}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:06,434] Trial 20 finished with value: 0.7106059442246406 and parameters: {'learning_rate': 0.14769287244102586, 'max_leaf_nodes': 256, 'max_depth': 9, 'min_samples_leaf': 163, 'l2_regularization': 1.1028237226409585}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:09,721] Trial 21 finished with value: 0.7104845525067631 and parameters: {'learning_rate': 0.07049186567748046, 'max_leaf_nodes': 182, 'max_depth': 7, 'min_samples_leaf': 80, 'l2_regularization': 0.5450557657661372}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:11,753] Trial 22 finished with value: 0.7112530170587756 and parameters: {'learning_rate': 0.1303271928228589, 'max_leaf_nodes': 211, 'max_depth': 6, 'min_samples_leaf': 104, 'l2_regularization': 0.3685969051522726}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:14,903] Trial 23 finished with value: 0.6998614225970807 and parameters: {'learning_rate': 0.02301353253285132, 'max_leaf_nodes': 166, 'max_depth': 4, 'min_samples_leaf': 136, 'l2_regularization': 0.03852583987496011}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:18,373] Trial 24 finished with value: 0.7110822629036302 and parameters: {'learning_rate': 0.05678486192819529, 'max_leaf_nodes': 200, 'max_depth': 5, 'min_samples_leaf': 65, 'l2_regularization': 0.8424135863008375}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:19,987] Trial 25 finished with value: 0.7101545225634135 and parameters: {'learning_rate': 0.151724672847398, 'max_leaf_nodes': 238, 'max_depth': 6, 'min_samples_leaf': 91, 'l2_regularization': 0.17965514228214804}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:27,493] Trial 26 finished with value: 0.6942438152040823 and parameters: {'learning_rate': 0.008361116780572251, 'max_leaf_nodes': 117, 'max_depth': 8, 'min_samples_leaf': 106, 'l2_regularization': 1.231778742279046}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:29,957] Trial 27 finished with value: 0.7108825178730822 and parameters: {'learning_rate': 0.09962921988424919, 'max_leaf_nodes': 149, 'max_depth': 7, 'min_samples_leaf': 81, 'l2_regularization': 0.4811214854924776}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:40,850] Trial 28 finished with value: 0.708172500794537 and parameters: {'learning_rate': 0.018017524447975806, 'max_leaf_nodes': 235, 'max_depth': 10, 'min_samples_leaf': 43, 'l2_regularization': 1.053126069085757}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:44,229] Trial 29 finished with value: 0.7103844374260768 and parameters: {'learning_rate': 0.06934510244196458, 'max_leaf_nodes': 230, 'max_depth': 7, 'min_samples_leaf': 62, 'l2_regularization': 1.941188619461627}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:45,409] Trial 30 finished with value: 0.7092286064007828 and parameters: {'learning_rate': 0.28317777914049785, 'max_leaf_nodes': 186, 'max_depth': 4, 'min_samples_leaf': 132, 'l2_regularization': 0.6777658566348932}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:47,232] Trial 31 finished with value: 0.7102518876853162 and parameters: {'learning_rate': 0.14777691166785364, 'max_leaf_nodes': 203, 'max_depth': 6, 'min_samples_leaf': 104, 'l2_regularization': 0.3488277863435507}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:49,722] Trial 32 finished with value: 0.710220995499036 and parameters: {'learning_rate': 0.11952821967756364, 'max_leaf_nodes': 216, 'max_depth': 5, 'min_samples_leaf': 100, 'l2_regularization': 0.18504319247923753}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:54,033] Trial 33 finished with value: 0.7101283983078372 and parameters: {'learning_rate': 0.039973475847526016, 'max_leaf_nodes': 154, 'max_depth': 6, 'min_samples_leaf': 118, 'l2_regularization': 0.41449702185466175}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:57,091] Trial 34 finished with value: 0.7107965217512819 and parameters: {'learning_rate': 0.08075021869341233, 'max_leaf_nodes': 242, 'max_depth': 7, 'min_samples_leaf': 80, 'l2_regularization': 1.7095123234796912}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:34:58,939] Trial 35 finished with value: 0.7090967592917211 and parameters: {'learning_rate': 0.14888885968488297, 'max_leaf_nodes': 207, 'max_depth': 9, 'min_samples_leaf': 113, 'l2_regularization': 0.19684396398690956}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:35:00,450] Trial 36 finished with value: 0.7089409389210007 and parameters: {'learning_rate': 0.19251779379742331, 'max_leaf_nodes': 182, 'max_depth': 6, 'min_samples_leaf': 127, 'l2_regularization': 1.3832669083389757}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:35:04,389] Trial 37 finished with value: 0.711197726012906 and parameters: {'learning_rate': 0.06027474775673242, 'max_leaf_nodes': 220, 'max_depth': 7, 'min_samples_leaf': 86, 'l2_regularization': 0.8974857805817322}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:35:06,846] Trial 38 finished with value: 0.7111505427043951 and parameters: {'learning_rate': 0.09718286108505074, 'max_leaf_nodes': 132, 'max_depth': 3, 'min_samples_leaf': 140, 'l2_regularization': 0.6784787362993137}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:35:14,860] Trial 39 finished with value: 0.7023751514220344 and parameters: {'learning_rate': 0.010376144035656443, 'max_leaf_nodes': 226, 'max_depth': 8, 'min_samples_leaf': 70, 'l2_regularization': 1.7987313784986363}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:35:17,109] Trial 40 finished with value: 0.7101330520190589 and parameters: {'learning_rate': 0.12061683205649994, 'max_leaf_nodes': 192, 'max_depth': 10, 'min_samples_leaf': 164, 'l2_regularization': 1.5223342106757318}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:35:18,328] Trial 41 finished with value: 0.7113937562712496 and parameters: {'learning_rate': 0.21180046055753105, 'max_leaf_nodes': 29, 'max_depth': 4, 'min_samples_leaf': 20, 'l2_regularization': 0.9896252654231025}. Best is trial 14 with value: 0.7118900766546595.\n",
      "[I 2025-07-03 21:35:19,988] Trial 42 finished with value: 0.7130380942444006 and parameters: {'learning_rate': 0.20634090046602513, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.2845835660554386}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:21,519] Trial 43 finished with value: 0.7127174757770953 and parameters: {'learning_rate': 0.21234736238683033, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.271171626452063}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:23,224] Trial 44 finished with value: 0.712077199927504 and parameters: {'learning_rate': 0.21863289558945836, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.2609706669228664}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:24,736] Trial 45 finished with value: 0.7119611761880373 and parameters: {'learning_rate': 0.29017905062297733, 'max_leaf_nodes': 43, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 1.246814271185792}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:26,280] Trial 46 finished with value: 0.7119050938484002 and parameters: {'learning_rate': 0.23610025704607462, 'max_leaf_nodes': 46, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 1.2837477506025419}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:27,858] Trial 47 finished with value: 0.7114353611405194 and parameters: {'learning_rate': 0.26494250929187224, 'max_leaf_nodes': 54, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 1.2815700259738048}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:29,646] Trial 48 finished with value: 0.7128597521365126 and parameters: {'learning_rate': 0.18272031684296983, 'max_leaf_nodes': 46, 'max_depth': 3, 'min_samples_leaf': 11, 'l2_regularization': 1.5476543535013125}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:30,698] Trial 49 finished with value: 0.7116603108769364 and parameters: {'learning_rate': 0.29896105185168015, 'max_leaf_nodes': 67, 'max_depth': 3, 'min_samples_leaf': 11, 'l2_regularization': 1.495306451560602}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:32,327] Trial 50 finished with value: 0.7126342583964976 and parameters: {'learning_rate': 0.18046820153677337, 'max_leaf_nodes': 35, 'max_depth': 3, 'min_samples_leaf': 43, 'l2_regularization': 1.4307474658469097}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:34,044] Trial 51 finished with value: 0.7108538454488885 and parameters: {'learning_rate': 0.19094813884947895, 'max_leaf_nodes': 32, 'max_depth': 3, 'min_samples_leaf': 41, 'l2_regularization': 1.6161031023950851}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:35,815] Trial 52 finished with value: 0.7128389729888707 and parameters: {'learning_rate': 0.16338652092264208, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.434902691907674}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:37,420] Trial 53 finished with value: 0.7114155468392654 and parameters: {'learning_rate': 0.17624202085252375, 'max_leaf_nodes': 16, 'max_depth': 3, 'min_samples_leaf': 18, 'l2_regularization': 1.445693268599047}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:39,372] Trial 54 finished with value: 0.711601232620817 and parameters: {'learning_rate': 0.17467915539043896, 'max_leaf_nodes': 71, 'max_depth': 2, 'min_samples_leaf': 36, 'l2_regularization': 1.3666757717220346}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:42,020] Trial 55 finished with value: 0.6260133578630702 and parameters: {'learning_rate': 0.0019367533347388875, 'max_leaf_nodes': 27, 'max_depth': 3, 'min_samples_leaf': 53, 'l2_regularization': 1.5945095158463394}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:43,772] Trial 56 finished with value: 0.7119189028148277 and parameters: {'learning_rate': 0.22884891738157828, 'max_leaf_nodes': 42, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.7038924053921964}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:45,885] Trial 57 finished with value: 0.7086417667981036 and parameters: {'learning_rate': 0.07840502545785814, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 32, 'l2_regularization': 1.4270532118890205}. Best is trial 42 with value: 0.7130380942444006.\n",
      "[I 2025-07-03 21:35:47,848] Trial 58 finished with value: 0.7131688739771121 and parameters: {'learning_rate': 0.1228199629151071, 'max_leaf_nodes': 36, 'max_depth': 3, 'min_samples_leaf': 11, 'l2_regularization': 1.8053887319315374}. Best is trial 58 with value: 0.7131688739771121.\n",
      "[I 2025-07-03 21:35:49,845] Trial 59 finished with value: 0.713770699963931 and parameters: {'learning_rate': 0.12289859767003747, 'max_leaf_nodes': 85, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.8523015859271919}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:35:52,298] Trial 60 finished with value: 0.7116662051751015 and parameters: {'learning_rate': 0.08699542030671069, 'max_leaf_nodes': 88, 'max_depth': 4, 'min_samples_leaf': 10, 'l2_regularization': 1.8484744999937468}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:35:54,414] Trial 61 finished with value: 0.7123935575860466 and parameters: {'learning_rate': 0.11834827760757202, 'max_leaf_nodes': 36, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.8310862321164956}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:35:56,195] Trial 62 finished with value: 0.7118289545627168 and parameters: {'learning_rate': 0.14949527931625475, 'max_leaf_nodes': 54, 'max_depth': 3, 'min_samples_leaf': 22, 'l2_regularization': 1.7571795677376478}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:35:58,770] Trial 63 finished with value: 0.6658539260000322 and parameters: {'learning_rate': 0.004888060816772908, 'max_leaf_nodes': 63, 'max_depth': 3, 'min_samples_leaf': 32, 'l2_regularization': 1.9533614662419172}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:00,643] Trial 64 finished with value: 0.7111470584291301 and parameters: {'learning_rate': 0.1717727030628343, 'max_leaf_nodes': 86, 'max_depth': 3, 'min_samples_leaf': 53, 'l2_regularization': 1.5556723680787876}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:02,723] Trial 65 finished with value: 0.709777814928484 and parameters: {'learning_rate': 0.11028420316894877, 'max_leaf_nodes': 36, 'max_depth': 2, 'min_samples_leaf': 45, 'l2_regularization': 1.6477086756565844}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:04,657] Trial 66 finished with value: 0.7106396113551624 and parameters: {'learning_rate': 0.12783594935662446, 'max_leaf_nodes': 80, 'max_depth': 4, 'min_samples_leaf': 15, 'l2_regularization': 1.8984110308156574}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:06,188] Trial 67 finished with value: 0.7110120555515305 and parameters: {'learning_rate': 0.2338592964477194, 'max_leaf_nodes': 49, 'max_depth': 3, 'min_samples_leaf': 37, 'l2_regularization': 1.9894821186852405}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:08,021] Trial 68 finished with value: 0.7118832121686679 and parameters: {'learning_rate': 0.16696736676289678, 'max_leaf_nodes': 35, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 1.1094395967797874}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:10,176] Trial 69 finished with value: 0.7127321277948794 and parameters: {'learning_rate': 0.13550667021397786, 'max_leaf_nodes': 98, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.4450257160409297}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:12,295] Trial 70 finished with value: 0.701961773090189 and parameters: {'learning_rate': 0.04786701834043579, 'max_leaf_nodes': 106, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.1749229135535144}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:14,220] Trial 71 finished with value: 0.7121676284104066 and parameters: {'learning_rate': 0.13186468741358082, 'max_leaf_nodes': 23, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.4728925459104076}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:16,449] Trial 72 finished with value: 0.7109192975228938 and parameters: {'learning_rate': 0.10596027679477064, 'max_leaf_nodes': 101, 'max_depth': 3, 'min_samples_leaf': 32, 'l2_regularization': 1.3324352025866106}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:18,147] Trial 73 finished with value: 0.7119619594973297 and parameters: {'learning_rate': 0.24423863304002208, 'max_leaf_nodes': 62, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.324612821199484}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:19,684] Trial 74 finished with value: 0.7122525501029005 and parameters: {'learning_rate': 0.2006348457442777, 'max_leaf_nodes': 16, 'max_depth': 4, 'min_samples_leaf': 39, 'l2_regularization': 1.550085467395928}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:22,225] Trial 75 finished with value: 0.7105924124583065 and parameters: {'learning_rate': 0.06462627744124401, 'max_leaf_nodes': 73, 'max_depth': 3, 'min_samples_leaf': 30, 'l2_regularization': 1.7297292764998826}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:24,735] Trial 76 finished with value: 0.7108937712442787 and parameters: {'learning_rate': 0.09133296815133995, 'max_leaf_nodes': 49, 'max_depth': 4, 'min_samples_leaf': 21, 'l2_regularization': 1.3973897466552732}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:26,830] Trial 77 finished with value: 0.7120978576236113 and parameters: {'learning_rate': 0.14364107410712726, 'max_leaf_nodes': 40, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.620765336538755}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:28,690] Trial 78 finished with value: 0.7114840184922339 and parameters: {'learning_rate': 0.1680175240063263, 'max_leaf_nodes': 121, 'max_depth': 3, 'min_samples_leaf': 47, 'l2_regularization': 1.6790261213699051}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:30,588] Trial 79 finished with value: 0.7133654657621644 and parameters: {'learning_rate': 0.19875406722390446, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.7604480243879204}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:32,114] Trial 80 finished with value: 0.7123362388473107 and parameters: {'learning_rate': 0.26046798613672784, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.7809126138295117}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:34,034] Trial 81 finished with value: 0.7125579445088215 and parameters: {'learning_rate': 0.19238518601409008, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.8805091889774528}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:36,017] Trial 82 finished with value: 0.7113239032824644 and parameters: {'learning_rate': 0.1276385489672315, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.5721648121925693}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:37,871] Trial 83 finished with value: 0.7125368371918903 and parameters: {'learning_rate': 0.14306960224935286, 'max_leaf_nodes': 37, 'max_depth': 3, 'min_samples_leaf': 28, 'l2_regularization': 1.5018763985481884}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:40,094] Trial 84 finished with value: 0.7102071575563131 and parameters: {'learning_rate': 0.10548062552474716, 'max_leaf_nodes': 97, 'max_depth': 2, 'min_samples_leaf': 36, 'l2_regularization': 1.6655368732201197}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:41,572] Trial 85 finished with value: 0.7113065454909523 and parameters: {'learning_rate': 0.20461367633152028, 'max_leaf_nodes': 58, 'max_depth': 3, 'min_samples_leaf': 22, 'l2_regularization': 1.4470488181091312}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:43,266] Trial 86 finished with value: 0.7125476930487805 and parameters: {'learning_rate': 0.2437095703720742, 'max_leaf_nodes': 48, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.3350004984708144}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:45,377] Trial 87 finished with value: 0.711900788959487 and parameters: {'learning_rate': 0.16901777389298642, 'max_leaf_nodes': 28, 'max_depth': 3, 'min_samples_leaf': 192, 'l2_regularization': 1.2113464274130687}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:48,005] Trial 88 finished with value: 0.7112290345147525 and parameters: {'learning_rate': 0.07566786981680407, 'max_leaf_nodes': 44, 'max_depth': 5, 'min_samples_leaf': 19, 'l2_regularization': 1.8168774596834587}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:50,208] Trial 89 finished with value: 0.7088381304748185 and parameters: {'learning_rate': 0.08726976767984738, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 29, 'l2_regularization': 1.379494342671602}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:52,362] Trial 90 finished with value: 0.693637695472281 and parameters: {'learning_rate': 0.03136437074051086, 'max_leaf_nodes': 77, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.7563247242583218}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:54,205] Trial 91 finished with value: 0.7134364767806629 and parameters: {'learning_rate': 0.20237514870634588, 'max_leaf_nodes': 23, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.8997607635759124}. Best is trial 59 with value: 0.713770699963931.\n",
      "[I 2025-07-03 21:36:56,031] Trial 92 finished with value: 0.7143385553968834 and parameters: {'learning_rate': 0.2064973124713652, 'max_leaf_nodes': 32, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.8887186490913288}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:36:57,713] Trial 93 finished with value: 0.7126645361826125 and parameters: {'learning_rate': 0.2116249638816774, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.9150238188178843}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:36:59,302] Trial 94 finished with value: 0.7118205965489961 and parameters: {'learning_rate': 0.2899110087801246, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.9883952758461445}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:01,398] Trial 95 finished with value: 0.7134790426238966 and parameters: {'learning_rate': 0.15337897621760221, 'max_leaf_nodes': 17, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.8486615694745239}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:03,447] Trial 96 finished with value: 0.711701089005515 and parameters: {'learning_rate': 0.15388211883264824, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 34, 'l2_regularization': 1.8554534907707747}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:05,623] Trial 97 finished with value: 0.710491242009162 and parameters: {'learning_rate': 0.11072128146624462, 'max_leaf_nodes': 40, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 1.9248541776270383}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:07,708] Trial 98 finished with value: 0.7121994688315907 and parameters: {'learning_rate': 0.13643957338526247, 'max_leaf_nodes': 136, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 1.7859423261530303}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:09,722] Trial 99 finished with value: 0.7136218911721721 and parameters: {'learning_rate': 0.16153194185053787, 'max_leaf_nodes': 57, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.856530423051552}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:11,267] Trial 100 finished with value: 0.7112868878377111 and parameters: {'learning_rate': 0.2583906997553752, 'max_leaf_nodes': 54, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.876719284929532}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:12,927] Trial 101 finished with value: 0.712190947206264 and parameters: {'learning_rate': 0.19076444898273184, 'max_leaf_nodes': 32, 'max_depth': 2, 'min_samples_leaf': 29, 'l2_regularization': 1.7153699936499405}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:14,902] Trial 102 finished with value: 0.7112760252888796 and parameters: {'learning_rate': 0.12154687849515339, 'max_leaf_nodes': 117, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.9642008879952284}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:16,690] Trial 103 finished with value: 0.7120142091516476 and parameters: {'learning_rate': 0.1562521026100695, 'max_leaf_nodes': 40, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.822258297219061}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:18,829] Trial 104 finished with value: 0.6069567226690468 and parameters: {'learning_rate': 0.001084692435892942, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.749894042998984}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:20,979] Trial 105 finished with value: 0.6869824520684882 and parameters: {'learning_rate': 0.022024606647979172, 'max_leaf_nodes': 50, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.9004005806772015}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:22,750] Trial 106 finished with value: 0.7121365910346331 and parameters: {'learning_rate': 0.2231080274371003, 'max_leaf_nodes': 61, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.8020541698488173}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:24,600] Trial 107 finished with value: 0.7122784182234391 and parameters: {'learning_rate': 0.16207148974618746, 'max_leaf_nodes': 26, 'max_depth': 3, 'min_samples_leaf': 23, 'l2_regularization': 1.9444659702512956}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:26,770] Trial 108 finished with value: 0.7114645518151124 and parameters: {'learning_rate': 0.13802812866336409, 'max_leaf_nodes': 90, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 1.8442348112761693}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:28,412] Trial 109 finished with value: 0.7117136280083345 and parameters: {'learning_rate': 0.18396723886535482, 'max_leaf_nodes': 44, 'max_depth': 3, 'min_samples_leaf': 19, 'l2_regularization': 1.6965641330498247}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:30,720] Trial 110 finished with value: 0.6198137833260375 and parameters: {'learning_rate': 0.003147159713925576, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 36, 'l2_regularization': 1.6301530647527376}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:32,884] Trial 111 finished with value: 0.7132054928768587 and parameters: {'learning_rate': 0.2115022720849714, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.2952143751758554}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:35,176] Trial 112 finished with value: 0.7111853555953749 and parameters: {'learning_rate': 0.09618005455945969, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.0617088416386848}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:36,994] Trial 113 finished with value: 0.711260019606701 and parameters: {'learning_rate': 0.22036508839146687, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.879511053634335}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:38,569] Trial 114 finished with value: 0.7125036501807173 and parameters: {'learning_rate': 0.26963206984792526, 'max_leaf_nodes': 68, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.7636104184657464}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:40,830] Trial 115 finished with value: 0.7117208526798758 and parameters: {'learning_rate': 0.11882422259727066, 'max_leaf_nodes': 39, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.3025524660228982}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:42,656] Trial 116 finished with value: 0.7115480377463819 and parameters: {'learning_rate': 0.18494820786495972, 'max_leaf_nodes': 19, 'max_depth': 3, 'min_samples_leaf': 32, 'l2_regularization': 1.5302318167786961}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:44,238] Trial 117 finished with value: 0.7116756841889036 and parameters: {'learning_rate': 0.16068139732363124, 'max_leaf_nodes': 16, 'max_depth': 4, 'min_samples_leaf': 22, 'l2_regularization': 1.1683491079305508}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:45,864] Trial 118 finished with value: 0.7124596576171607 and parameters: {'learning_rate': 0.24482704216433282, 'max_leaf_nodes': 52, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.473244602831514}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:47,509] Trial 119 finished with value: 0.71193259655778 and parameters: {'learning_rate': 0.20632316440985135, 'max_leaf_nodes': 26, 'max_depth': 3, 'min_samples_leaf': 20, 'l2_regularization': 1.929427937738821}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:49,613] Trial 120 finished with value: 0.7122684841045779 and parameters: {'learning_rate': 0.1436091809152792, 'max_leaf_nodes': 35, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 1.9931169122562098}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:51,324] Trial 121 finished with value: 0.7121853290533691 and parameters: {'learning_rate': 0.20784168519212276, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.5841289278686814}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:53,203] Trial 122 finished with value: 0.7123807785035365 and parameters: {'learning_rate': 0.17903291552592707, 'max_leaf_nodes': 30, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.2399686585042164}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:55,423] Trial 123 finished with value: 0.6744279698229924 and parameters: {'learning_rate': 0.014223253201817193, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.2706360532191492}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:56,865] Trial 124 finished with value: 0.7121405011564912 and parameters: {'learning_rate': 0.2973371562914057, 'max_leaf_nodes': 43, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.3593954882094585}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:37:58,299] Trial 125 finished with value: 0.7119359731914628 and parameters: {'learning_rate': 0.23235346663573933, 'max_leaf_nodes': 34, 'max_depth': 3, 'min_samples_leaf': 40, 'l2_regularization': 1.8677152548060316}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:00,344] Trial 126 finished with value: 0.7113960334067796 and parameters: {'learning_rate': 0.1309294188108319, 'max_leaf_nodes': 46, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 1.8161577161138887}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:01,907] Trial 127 finished with value: 0.7111846178690004 and parameters: {'learning_rate': 0.16083826800471981, 'max_leaf_nodes': 21, 'max_depth': 5, 'min_samples_leaf': 22, 'l2_regularization': 1.6585839912645601}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:03,296] Trial 128 finished with value: 0.7112860106193631 and parameters: {'learning_rate': 0.25456531125340703, 'max_leaf_nodes': 37, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 1.4206066090313847}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:05,411] Trial 129 finished with value: 0.712298757447129 and parameters: {'learning_rate': 0.1925694936958807, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 175, 'l2_regularization': 1.7283271219314948}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:07,729] Trial 130 finished with value: 0.6610531850233858 and parameters: {'learning_rate': 0.007115009134733553, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.4647595080571993}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:09,570] Trial 131 finished with value: 0.7118920671957751 and parameters: {'learning_rate': 0.21639877723424697, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 11, 'l2_regularization': 1.9114597812840777}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:11,412] Trial 132 finished with value: 0.7118936726781047 and parameters: {'learning_rate': 0.17361031189247286, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.9120500989359808}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:13,557] Trial 133 finished with value: 0.7110818900273829 and parameters: {'learning_rate': 0.11182417965733814, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.848907395783271}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:15,584] Trial 134 finished with value: 0.711327064399564 and parameters: {'learning_rate': 0.21041908095844808, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.9741479406910625}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:17,572] Trial 135 finished with value: 0.7128530009620995 and parameters: {'learning_rate': 0.15308355717376373, 'max_leaf_nodes': 39, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.8159440505934037}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:19,404] Trial 136 finished with value: 0.7123837416338547 and parameters: {'learning_rate': 0.14661986777159935, 'max_leaf_nodes': 41, 'max_depth': 3, 'min_samples_leaf': 17, 'l2_regularization': 1.1334273764294494}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:21,477] Trial 137 finished with value: 0.7108127051202388 and parameters: {'learning_rate': 0.10102513615896866, 'max_leaf_nodes': 157, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.7933778653592132}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:23,496] Trial 138 finished with value: 0.7120589297061964 and parameters: {'learning_rate': 0.15781338007634355, 'max_leaf_nodes': 56, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 1.7544851216923922}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:25,554] Trial 139 finished with value: 0.7124296876592409 and parameters: {'learning_rate': 0.11881885798354823, 'max_leaf_nodes': 79, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.3872893131255306}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:27,485] Trial 140 finished with value: 0.7124719358008211 and parameters: {'learning_rate': 0.12771735149496652, 'max_leaf_nodes': 131, 'max_depth': 3, 'min_samples_leaf': 14, 'l2_regularization': 1.8120021752013686}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:29,296] Trial 141 finished with value: 0.7124445843731877 and parameters: {'learning_rate': 0.18923959587700456, 'max_leaf_nodes': 35, 'max_depth': 2, 'min_samples_leaf': 11, 'l2_regularization': 1.9371318520665635}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:31,095] Trial 142 finished with value: 0.7118701523596253 and parameters: {'learning_rate': 0.2262610416396129, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.854128703598849}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:32,742] Trial 143 finished with value: 0.711585198791855 and parameters: {'learning_rate': 0.26790753911896265, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.8920641138480767}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:34,622] Trial 144 finished with value: 0.7128399746492848 and parameters: {'learning_rate': 0.17556016290033222, 'max_leaf_nodes': 46, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.3129983821486082}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:36,546] Trial 145 finished with value: 0.7116378838585413 and parameters: {'learning_rate': 0.14000355530648437, 'max_leaf_nodes': 49, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 1.2925853404528818}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:38,278] Trial 146 finished with value: 0.7120255375734965 and parameters: {'learning_rate': 0.17200934776610582, 'max_leaf_nodes': 45, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.344190377263365}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:40,164] Trial 147 finished with value: 0.712403689792276 and parameters: {'learning_rate': 0.1602305106664112, 'max_leaf_nodes': 60, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 1.2091194739970565}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:41,623] Trial 148 finished with value: 0.7121921517181201 and parameters: {'learning_rate': 0.1898869542890852, 'max_leaf_nodes': 65, 'max_depth': 3, 'min_samples_leaf': 19, 'l2_regularization': 1.419496612826549}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:43,242] Trial 149 finished with value: 0.7113404072901904 and parameters: {'learning_rate': 0.2418745260486829, 'max_leaf_nodes': 93, 'max_depth': 2, 'min_samples_leaf': 31, 'l2_regularization': 1.5102511173835707}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:45,189] Trial 150 finished with value: 0.7135163603206586 and parameters: {'learning_rate': 0.13520860473530996, 'max_leaf_nodes': 38, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.3158132255568884}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:47,155] Trial 151 finished with value: 0.7124508026774856 and parameters: {'learning_rate': 0.14251386460267637, 'max_leaf_nodes': 39, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.250403835609444}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:49,227] Trial 152 finished with value: 0.7127906338546729 and parameters: {'learning_rate': 0.1295706437671246, 'max_leaf_nodes': 32, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.170164929858228}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:51,295] Trial 153 finished with value: 0.7085865947937682 and parameters: {'learning_rate': 0.08397083403217466, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.1635423202075275}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:53,362] Trial 154 finished with value: 0.709296562081231 and parameters: {'learning_rate': 0.1232124433352971, 'max_leaf_nodes': 53, 'max_depth': 2, 'min_samples_leaf': 150, 'l2_regularization': 1.3116977074050937}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:55,423] Trial 155 finished with value: 0.7101918080596633 and parameters: {'learning_rate': 0.09418810190797884, 'max_leaf_nodes': 39, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.3417881147723025}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:57,506] Trial 156 finished with value: 0.7110111342982105 and parameters: {'learning_rate': 0.10745303762550354, 'max_leaf_nodes': 45, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 1.205533731552233}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:38:59,454] Trial 157 finished with value: 0.7133093163105266 and parameters: {'learning_rate': 0.13288806484056934, 'max_leaf_nodes': 32, 'max_depth': 3, 'min_samples_leaf': 14, 'l2_regularization': 1.3693553265913005}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:01,146] Trial 158 finished with value: 0.7121649337344398 and parameters: {'learning_rate': 0.15286367221334354, 'max_leaf_nodes': 32, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 1.0211314438441794}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:02,787] Trial 159 finished with value: 0.7105138332872406 and parameters: {'learning_rate': 0.17880514781386983, 'max_leaf_nodes': 37, 'max_depth': 4, 'min_samples_leaf': 26, 'l2_regularization': 1.3858162238162062}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:04,818] Trial 160 finished with value: 0.7133067042147243 and parameters: {'learning_rate': 0.1282625677450776, 'max_leaf_nodes': 27, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.315599383750589}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:06,900] Trial 161 finished with value: 0.7128142524385661 and parameters: {'learning_rate': 0.12653855921817292, 'max_leaf_nodes': 29, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.247864460552687}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:08,884] Trial 162 finished with value: 0.7118636324064201 and parameters: {'learning_rate': 0.11302216119290116, 'max_leaf_nodes': 22, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.306050945040688}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:10,517] Trial 163 finished with value: 0.7120165675018367 and parameters: {'learning_rate': 0.15913639821150902, 'max_leaf_nodes': 27, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 1.356315676017809}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:12,416] Trial 164 finished with value: 0.7124877827485003 and parameters: {'learning_rate': 0.13510222080511444, 'max_leaf_nodes': 20, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.4050098545762082}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:15,033] Trial 165 finished with value: 0.6197040338952581 and parameters: {'learning_rate': 0.0016405353246065043, 'max_leaf_nodes': 41, 'max_depth': 3, 'min_samples_leaf': 73, 'l2_regularization': 1.2561558254742335}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:16,581] Trial 166 finished with value: 0.7123165876165066 and parameters: {'learning_rate': 0.19844311073975496, 'max_leaf_nodes': 29, 'max_depth': 3, 'min_samples_leaf': 20, 'l2_regularization': 1.850324884151169}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:17,932] Trial 167 finished with value: 0.7118381670728448 and parameters: {'learning_rate': 0.17679913153878393, 'max_leaf_nodes': 48, 'max_depth': 4, 'min_samples_leaf': 16, 'l2_regularization': 1.281897091672986}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:20,172] Trial 168 finished with value: 0.7116940665046732 and parameters: {'learning_rate': 0.10204075472674502, 'max_leaf_nodes': 35, 'max_depth': 3, 'min_samples_leaf': 14, 'l2_regularization': 1.77560034964706}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:22,017] Trial 169 finished with value: 0.7123316318770685 and parameters: {'learning_rate': 0.14868376472551023, 'max_leaf_nodes': 26, 'max_depth': 3, 'min_samples_leaf': 20, 'l2_regularization': 1.7117166979628342}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:24,501] Trial 170 finished with value: 0.712022223407826 and parameters: {'learning_rate': 0.07173878247120163, 'max_leaf_nodes': 43, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.226696216569284}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:26,551] Trial 171 finished with value: 0.7125231570990231 and parameters: {'learning_rate': 0.1280143481649616, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.1966406640438694}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:28,533] Trial 172 finished with value: 0.712294723660556 and parameters: {'learning_rate': 0.11899985729502813, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.0846052304913598}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:30,079] Trial 173 finished with value: 0.7113884163204499 and parameters: {'learning_rate': 0.13807625550153227, 'max_leaf_nodes': 31, 'max_depth': 4, 'min_samples_leaf': 17, 'l2_regularization': 1.3331950417458434}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:31,823] Trial 174 finished with value: 0.7113572415738817 and parameters: {'learning_rate': 0.1639210417547828, 'max_leaf_nodes': 37, 'max_depth': 3, 'min_samples_leaf': 24, 'l2_regularization': 1.2916469051183603}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:33,748] Trial 175 finished with value: 0.7133881403337936 and parameters: {'learning_rate': 0.19055026734044492, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.8222650879047366}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:35,266] Trial 176 finished with value: 0.7122066688995797 and parameters: {'learning_rate': 0.19659581887505745, 'max_leaf_nodes': 16, 'max_depth': 3, 'min_samples_leaf': 21, 'l2_regularization': 1.8238046552329163}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:36,911] Trial 177 finished with value: 0.7121708337308348 and parameters: {'learning_rate': 0.22501525472608802, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.881028446103563}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:38,851] Trial 178 finished with value: 0.7137278381199897 and parameters: {'learning_rate': 0.17569683920454046, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.788273427655581}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:40,694] Trial 179 finished with value: 0.7120958625393935 and parameters: {'learning_rate': 0.17647355292099176, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.7701503079344958}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:42,447] Trial 180 finished with value: 0.7115257161359646 and parameters: {'learning_rate': 0.20801061016416245, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 1.8120966618117247}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:44,392] Trial 181 finished with value: 0.7127175981520479 and parameters: {'learning_rate': 0.15506035211643612, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.8486856846422668}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:46,462] Trial 182 finished with value: 0.7126423249219446 and parameters: {'learning_rate': 0.17599836153355083, 'max_leaf_nodes': 37, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.941637453382495}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:48,444] Trial 183 finished with value: 0.7136122230587054 and parameters: {'learning_rate': 0.19788577075387714, 'max_leaf_nodes': 19, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.7253718021548616}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:50,186] Trial 184 finished with value: 0.7123996875392137 and parameters: {'learning_rate': 0.248757885361238, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.6815040405783221}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:52,023] Trial 185 finished with value: 0.7129768367769875 and parameters: {'learning_rate': 0.2004049537727706, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.7328647286305958}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:53,916] Trial 186 finished with value: 0.7128249261800018 and parameters: {'learning_rate': 0.20665490674000073, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.7404650300589843}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:55,707] Trial 187 finished with value: 0.71186577772414 and parameters: {'learning_rate': 0.2316630158745367, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 1.7895098534612202}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:57,593] Trial 188 finished with value: 0.7117010268123323 and parameters: {'learning_rate': 0.19731531210099926, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 34, 'l2_regularization': 1.6365699127007307}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:39:59,495] Trial 189 finished with value: 0.713877351889715 and parameters: {'learning_rate': 0.1826704332016835, 'max_leaf_nodes': 43, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.6787061482117211}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:00,914] Trial 190 finished with value: 0.711644978361142 and parameters: {'learning_rate': 0.27612258727745875, 'max_leaf_nodes': 41, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 1.7338934717892467}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:02,793] Trial 191 finished with value: 0.7117793189127359 and parameters: {'learning_rate': 0.17507033681180437, 'max_leaf_nodes': 51, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.7092625003936053}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:04,603] Trial 192 finished with value: 0.7125205945108755 and parameters: {'learning_rate': 0.21863851814889138, 'max_leaf_nodes': 34, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.68776526426063}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:06,488] Trial 193 finished with value: 0.7112457522849565 and parameters: {'learning_rate': 0.1891122303035849, 'max_leaf_nodes': 46, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.5964558105557956}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:08,586] Trial 194 finished with value: 0.7124948701460745 and parameters: {'learning_rate': 0.1501791405719, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.7883473941997197}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:10,558] Trial 195 finished with value: 0.7127847147381791 and parameters: {'learning_rate': 0.16492499909699118, 'max_leaf_nodes': 40, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.8290533870745023}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:12,286] Trial 196 finished with value: 0.7119512863911549 and parameters: {'learning_rate': 0.24359976784871412, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.890145141421411}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:14,094] Trial 197 finished with value: 0.7113445550704357 and parameters: {'learning_rate': 0.18771098212318835, 'max_leaf_nodes': 23, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.7498652203963234}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:15,882] Trial 198 finished with value: 0.7122567033388403 and parameters: {'learning_rate': 0.20954944835434455, 'max_leaf_nodes': 55, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.8086930712609315}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:17,935] Trial 199 finished with value: 0.7118527234756167 and parameters: {'learning_rate': 0.14515466574798086, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 1.6648871937397351}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:19,910] Trial 200 finished with value: 0.7131238865617154 and parameters: {'learning_rate': 0.16556368971738186, 'max_leaf_nodes': 45, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.8727345632514718}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:21,866] Trial 201 finished with value: 0.7120547528555 and parameters: {'learning_rate': 0.17084586040246674, 'max_leaf_nodes': 50, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.8563991775946187}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:23,791] Trial 202 finished with value: 0.7126523110757411 and parameters: {'learning_rate': 0.1882599810769401, 'max_leaf_nodes': 43, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.9071555959140534}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:25,858] Trial 203 finished with value: 0.7130133106594585 and parameters: {'learning_rate': 0.15892526007623253, 'max_leaf_nodes': 35, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.8471331231045047}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:27,883] Trial 204 finished with value: 0.7124602491947998 and parameters: {'learning_rate': 0.15327745805644244, 'max_leaf_nodes': 37, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.779517433855926}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:29,614] Trial 205 finished with value: 0.7118219469912372 and parameters: {'learning_rate': 0.2221901083698916, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.8721826899350256}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:31,635] Trial 206 finished with value: 0.7121392482706922 and parameters: {'learning_rate': 0.14310091352070264, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.8299741981989963}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:33,348] Trial 207 finished with value: 0.7132155946357732 and parameters: {'learning_rate': 0.20089944078593377, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.9500122155220503}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:35,035] Trial 208 finished with value: 0.7116743197642098 and parameters: {'learning_rate': 0.25040934089890243, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 1.9514278426357428}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:36,994] Trial 209 finished with value: 0.7125753803224062 and parameters: {'learning_rate': 0.21058692668933085, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.9052520922736695}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:38,668] Trial 210 finished with value: 0.7118398541375661 and parameters: {'learning_rate': 0.19181270053933197, 'max_leaf_nodes': 30, 'max_depth': 3, 'min_samples_leaf': 20, 'l2_regularization': 1.9881768654932541}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:40,890] Trial 211 finished with value: 0.7135023341478958 and parameters: {'learning_rate': 0.16315094542049963, 'max_leaf_nodes': 38, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.851990858829713}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:42,889] Trial 212 finished with value: 0.7112868609637314 and parameters: {'learning_rate': 0.1679094316110003, 'max_leaf_nodes': 36, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.8818558056882342}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:44,951] Trial 213 finished with value: 0.7130046214731077 and parameters: {'learning_rate': 0.20026627037908207, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.9372310428620898}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:46,628] Trial 214 finished with value: 0.713006965403457 and parameters: {'learning_rate': 0.22947720511000852, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.9177812143474282}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:48,432] Trial 215 finished with value: 0.7117556138865024 and parameters: {'learning_rate': 0.2309064832784685, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 59, 'l2_regularization': 1.9425208909325091}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:49,833] Trial 216 finished with value: 0.7118626170029614 and parameters: {'learning_rate': 0.2653708371138352, 'max_leaf_nodes': 27, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.9236685105561335}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:52,014] Trial 217 finished with value: 0.7118068217163869 and parameters: {'learning_rate': 0.1309544834604208, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.9486651817781218}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:54,330] Trial 218 finished with value: 0.6993753524744502 and parameters: {'learning_rate': 0.041308573949965136, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.9932019686612974}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:56,380] Trial 219 finished with value: 0.7105047345982044 and parameters: {'learning_rate': 0.2283022844894822, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 94, 'l2_regularization': 1.8756437227225387}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:40:58,141] Trial 220 finished with value: 0.7109073474727208 and parameters: {'learning_rate': 0.16423212691531075, 'max_leaf_nodes': 34, 'max_depth': 5, 'min_samples_leaf': 14, 'l2_regularization': 1.841636245330846}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:41:00,135] Trial 221 finished with value: 0.712915683329199 and parameters: {'learning_rate': 0.1986738078919542, 'max_leaf_nodes': 18, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 1.8982169081991875}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:41:02,217] Trial 222 finished with value: 0.7119124218625454 and parameters: {'learning_rate': 0.1880713401631973, 'max_leaf_nodes': 19, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.8429913590206082}. Best is trial 92 with value: 0.7143385553968834.\n",
      "[I 2025-07-03 21:41:04,128] Trial 223 finished with value: 0.7148864553158866 and parameters: {'learning_rate': 0.20787700729016054, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9344877277799697}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:06,347] Trial 224 finished with value: 0.7127281184289693 and parameters: {'learning_rate': 0.2128897905486731, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.9187921670469958}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:08,039] Trial 225 finished with value: 0.7115763403195265 and parameters: {'learning_rate': 0.1729620337751184, 'max_leaf_nodes': 30, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.8482628863816483}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:10,107] Trial 226 finished with value: 0.7128354031447154 and parameters: {'learning_rate': 0.1467157969041284, 'max_leaf_nodes': 175, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8630609205653942}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:11,566] Trial 227 finished with value: 0.7110166522827784 and parameters: {'learning_rate': 0.2959879986891218, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.961945930511369}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:13,175] Trial 228 finished with value: 0.7131523604253562 and parameters: {'learning_rate': 0.2374996453137499, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.8926605281496368}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:14,842] Trial 229 finished with value: 0.7117114592273176 and parameters: {'learning_rate': 0.23460867802490099, 'max_leaf_nodes': 38, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.9390031608233134}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:16,900] Trial 230 finished with value: 0.711395971614541 and parameters: {'learning_rate': 0.11443014671875852, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.9185175851747144}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:18,490] Trial 231 finished with value: 0.7136653601490536 and parameters: {'learning_rate': 0.25052157946001286, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.9546959011667798}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:19,940] Trial 232 finished with value: 0.7132122478833526 and parameters: {'learning_rate': 0.2648001614616328, 'max_leaf_nodes': 27, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 0.8940477157228903}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:21,325] Trial 233 finished with value: 0.7119911872054329 and parameters: {'learning_rate': 0.2683904976186635, 'max_leaf_nodes': 34, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.7993272309520109}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:22,671] Trial 234 finished with value: 0.7118189193128501 and parameters: {'learning_rate': 0.25536020712420876, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.942353840900735}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:24,133] Trial 235 finished with value: 0.7134685631272992 and parameters: {'learning_rate': 0.2942084552723637, 'max_leaf_nodes': 40, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.8823291583981842}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:25,718] Trial 236 finished with value: 0.7126055920238679 and parameters: {'learning_rate': 0.24440679724692907, 'max_leaf_nodes': 38, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.001579228318133}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:27,157] Trial 237 finished with value: 0.7114717790786973 and parameters: {'learning_rate': 0.2645371560665737, 'max_leaf_nodes': 42, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.7539549234702174}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:28,715] Trial 238 finished with value: 0.7121477253474049 and parameters: {'learning_rate': 0.2752140986566174, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.8930500230725074}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:30,178] Trial 239 finished with value: 0.7118334259310849 and parameters: {'learning_rate': 0.2840973154832553, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.8827364426772653}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:31,266] Trial 240 finished with value: 0.7106403339153077 and parameters: {'learning_rate': 0.2177367683103684, 'max_leaf_nodes': 26, 'max_depth': 9, 'min_samples_leaf': 14, 'l2_regularization': 0.9821050467948758}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:32,571] Trial 241 finished with value: 0.7101188828413793 and parameters: {'learning_rate': 0.2896914380654169, 'max_leaf_nodes': 36, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.8000059387129288}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:34,533] Trial 242 finished with value: 0.7127680943182124 and parameters: {'learning_rate': 0.17841137688355607, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9668714177471817}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:36,184] Trial 243 finished with value: 0.7125123358430945 and parameters: {'learning_rate': 0.21407309371516747, 'max_leaf_nodes': 42, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.8278741952836364}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:37,704] Trial 244 finished with value: 0.712543632539121 and parameters: {'learning_rate': 0.24334046462423478, 'max_leaf_nodes': 108, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.8791791973825865}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:38,909] Trial 245 finished with value: 0.7131183346907692 and parameters: {'learning_rate': 0.2994601418082661, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.0208353005802242}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:40,279] Trial 246 finished with value: 0.7123234222574552 and parameters: {'learning_rate': 0.2961034422994007, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.0450762938897613}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:41,864] Trial 247 finished with value: 0.7134644096013629 and parameters: {'learning_rate': 0.2568163645294287, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.8992045738840826}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:43,199] Trial 248 finished with value: 0.7119099882899205 and parameters: {'learning_rate': 0.2977487539693215, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8163338931709659}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:44,294] Trial 249 finished with value: 0.70976687278056 and parameters: {'learning_rate': 0.2614219552130329, 'max_leaf_nodes': 25, 'max_depth': 6, 'min_samples_leaf': 14, 'l2_regularization': 0.9241754902989423}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:45,435] Trial 250 finished with value: 0.7102000456513432 and parameters: {'learning_rate': 0.24468861742925746, 'max_leaf_nodes': 39, 'max_depth': 8, 'min_samples_leaf': 17, 'l2_regularization': 0.9456597516645905}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:47,094] Trial 251 finished with value: 0.7108204108324675 and parameters: {'learning_rate': 0.25973059582932845, 'max_leaf_nodes': 30, 'max_depth': 2, 'min_samples_leaf': 124, 'l2_regularization': 0.9088565311533318}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:48,744] Trial 252 finished with value: 0.7123920986260297 and parameters: {'learning_rate': 0.2343917946595749, 'max_leaf_nodes': 34, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.9778267669225112}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:50,626] Trial 253 finished with value: 0.7122286566626664 and parameters: {'learning_rate': 0.2059919385502732, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 116, 'l2_regularization': 0.7532194082066602}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:52,452] Trial 254 finished with value: 0.7131957515321469 and parameters: {'learning_rate': 0.19051127718748892, 'max_leaf_nodes': 44, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.8688003918757199}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:54,443] Trial 255 finished with value: 0.7120594115678109 and parameters: {'learning_rate': 0.18498770664811565, 'max_leaf_nodes': 46, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.8480961182390566}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:56,246] Trial 256 finished with value: 0.7130111307680718 and parameters: {'learning_rate': 0.19870049865833544, 'max_leaf_nodes': 142, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.8948377389331779}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:41:58,344] Trial 257 finished with value: 0.6709025683026424 and parameters: {'learning_rate': 0.01119687542645136, 'max_leaf_nodes': 42, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.8704795851743483}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:00,311] Trial 258 finished with value: 0.7126832054238608 and parameters: {'learning_rate': 0.13618590354844762, 'max_leaf_nodes': 48, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.967674531996714}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:02,205] Trial 259 finished with value: 0.7131737082011034 and parameters: {'learning_rate': 0.1615241127903497, 'max_leaf_nodes': 40, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.8563546773062072}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:03,639] Trial 260 finished with value: 0.7113235323663727 and parameters: {'learning_rate': 0.22226262462297233, 'max_leaf_nodes': 38, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 0.7869692889759545}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:05,719] Trial 261 finished with value: 0.6826532195495643 and parameters: {'learning_rate': 0.01921700296139463, 'max_leaf_nodes': 32, 'max_depth': 2, 'min_samples_leaf': 108, 'l2_regularization': 0.914832146187691}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:07,294] Trial 262 finished with value: 0.7111511866723138 and parameters: {'learning_rate': 0.18117151968355005, 'max_leaf_nodes': 37, 'max_depth': 3, 'min_samples_leaf': 17, 'l2_regularization': 0.8507386575882502}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:09,159] Trial 263 finished with value: 0.711558822728136 and parameters: {'learning_rate': 0.14305435994926013, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8963991058980724}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:11,422] Trial 264 finished with value: 0.7124528684182814 and parameters: {'learning_rate': 0.1210755721991622, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.9384492213790427}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:13,520] Trial 265 finished with value: 0.7123693758087254 and parameters: {'learning_rate': 0.15637599776254332, 'max_leaf_nodes': 73, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.7890937487772067}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:15,294] Trial 266 finished with value: 0.713212392092658 and parameters: {'learning_rate': 0.20422502094663486, 'max_leaf_nodes': 41, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.7223191181150173}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:16,699] Trial 267 finished with value: 0.7113125078038272 and parameters: {'learning_rate': 0.19388915869308684, 'max_leaf_nodes': 43, 'max_depth': 10, 'min_samples_leaf': 10, 'l2_regularization': 0.8320811650348894}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:18,285] Trial 268 finished with value: 0.7118021341247088 and parameters: {'learning_rate': 0.17089769831466586, 'max_leaf_nodes': 52, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 0.7712653040734033}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:20,196] Trial 269 finished with value: 0.7119762103578576 and parameters: {'learning_rate': 0.21070834587438061, 'max_leaf_nodes': 39, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.7774094916628917}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:22,313] Trial 270 finished with value: 0.7129605764102738 and parameters: {'learning_rate': 0.13396612862614593, 'max_leaf_nodes': 41, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.6416530261050161}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:24,304] Trial 271 finished with value: 0.7118083955474999 and parameters: {'learning_rate': 0.15717941531599403, 'max_leaf_nodes': 36, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 0.7210528928014786}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:26,086] Trial 272 finished with value: 0.7115910625310562 and parameters: {'learning_rate': 0.1852710920334253, 'max_leaf_nodes': 19, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.8182837341793459}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:28,401] Trial 273 finished with value: 0.6451454077639743 and parameters: {'learning_rate': 0.004599555108723529, 'max_leaf_nodes': 23, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 1.7466989815255511}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:31,033] Trial 274 finished with value: 0.7028564657439272 and parameters: {'learning_rate': 0.030231550521061846, 'max_leaf_nodes': 48, 'max_depth': 3, 'min_samples_leaf': 23, 'l2_regularization': 0.09202177617087237}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:32,920] Trial 275 finished with value: 0.7116279920407342 and parameters: {'learning_rate': 0.17317711641404365, 'max_leaf_nodes': 56, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.8099519330006082}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:34,605] Trial 276 finished with value: 0.7124617478640152 and parameters: {'learning_rate': 0.21769830103982865, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.5348452721781954}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:36,466] Trial 277 finished with value: 0.7132648171282353 and parameters: {'learning_rate': 0.1942690455183014, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 0.6642386901998375}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:38,205] Trial 278 finished with value: 0.7135046791426826 and parameters: {'learning_rate': 0.1980268916367873, 'max_leaf_nodes': 17, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.7220150298434633}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:40,107] Trial 279 finished with value: 0.712361205593901 and parameters: {'learning_rate': 0.20356645578627963, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.6307932469259278}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:41,738] Trial 280 finished with value: 0.712945570585733 and parameters: {'learning_rate': 0.23863703173658282, 'max_leaf_nodes': 19, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.7022158485425554}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:43,523] Trial 281 finished with value: 0.7136535592286628 and parameters: {'learning_rate': 0.19274868937512973, 'max_leaf_nodes': 23, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.5853528781066896}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:45,061] Trial 282 finished with value: 0.7122078623844914 and parameters: {'learning_rate': 0.2154446189048106, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.5733809351960694}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:46,723] Trial 283 finished with value: 0.7138995319211644 and parameters: {'learning_rate': 0.2502012556858904, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.6978093417987657}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:48,177] Trial 284 finished with value: 0.7123995503940219 and parameters: {'learning_rate': 0.25754154065531615, 'max_leaf_nodes': 17, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.5039797065650428}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:49,732] Trial 285 finished with value: 0.7124780583075031 and parameters: {'learning_rate': 0.2651978838342338, 'max_leaf_nodes': 19, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.7089197009063527}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:51,485] Trial 286 finished with value: 0.7117837855349012 and parameters: {'learning_rate': 0.2309482874673404, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.59633041790372}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:53,336] Trial 287 finished with value: 0.7125581846312693 and parameters: {'learning_rate': 0.19414892142390722, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 0.6810821820386582}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:55,024] Trial 288 finished with value: 0.7121229372844887 and parameters: {'learning_rate': 0.18306636484490302, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.503722720602043}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:56,129] Trial 289 finished with value: 0.7112057203590478 and parameters: {'learning_rate': 0.24279141309998142, 'max_leaf_nodes': 25, 'max_depth': 7, 'min_samples_leaf': 15, 'l2_regularization': 0.6579186174870563}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:57,836] Trial 290 finished with value: 0.7121485058010961 and parameters: {'learning_rate': 0.220372051020669, 'max_leaf_nodes': 23, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.623268914332204}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:42:59,789] Trial 291 finished with value: 0.7124616776198436 and parameters: {'learning_rate': 0.17043294922228436, 'max_leaf_nodes': 27, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.4374644415582203}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:01,316] Trial 292 finished with value: 0.7124154145886188 and parameters: {'learning_rate': 0.2686101526650586, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.7070384701702718}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:03,125] Trial 293 finished with value: 0.7128637795234659 and parameters: {'learning_rate': 0.20858277652626625, 'max_leaf_nodes': 85, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.5659137183453979}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:05,013] Trial 294 finished with value: 0.7114791760341852 and parameters: {'learning_rate': 0.14466913085659888, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.7269240047855456}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:07,074] Trial 295 finished with value: 0.7124969327821562 and parameters: {'learning_rate': 0.19032741065338152, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 0.6505404453650219}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:08,916] Trial 296 finished with value: 0.7121517511714195 and parameters: {'learning_rate': 0.24346203633401176, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 177, 'l2_regularization': 0.6086034362766116}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:11,292] Trial 297 finished with value: 0.7122310207609421 and parameters: {'learning_rate': 0.1572797565219614, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 1.0105220015598155}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:13,116] Trial 298 finished with value: 0.7128644385738595 and parameters: {'learning_rate': 0.204989465677798, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.083688147925506}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:15,146] Trial 299 finished with value: 0.7113498705724485 and parameters: {'learning_rate': 0.1746512387140176, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 140, 'l2_regularization': 0.666122139218098}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:16,474] Trial 300 finished with value: 0.709599267403687 and parameters: {'learning_rate': 0.228936206354466, 'max_leaf_nodes': 126, 'max_depth': 5, 'min_samples_leaf': 84, 'l2_regularization': 0.7716375247017377}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:18,056] Trial 301 finished with value: 0.7123302253617343 and parameters: {'learning_rate': 0.27676412770696956, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.7349378183685932}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:20,196] Trial 302 finished with value: 0.6568348259590244 and parameters: {'learning_rate': 0.0065245712322134644, 'max_leaf_nodes': 245, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.864881755144159}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:22,076] Trial 303 finished with value: 0.713047964189119 and parameters: {'learning_rate': 0.18877287632172182, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.691687228711203}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:23,986] Trial 304 finished with value: 0.7118877591442144 and parameters: {'learning_rate': 0.14898775231997713, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 1.7162813239703645}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:27,388] Trial 305 finished with value: 0.6520389724708388 and parameters: {'learning_rate': 0.0027127509484304504, 'max_leaf_nodes': 27, 'max_depth': 4, 'min_samples_leaf': 199, 'l2_regularization': 1.8764805380707208}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:29,143] Trial 306 finished with value: 0.7103646121736023 and parameters: {'learning_rate': 0.2243634336770827, 'max_leaf_nodes': 32, 'max_depth': 2, 'min_samples_leaf': 129, 'l2_regularization': 1.8393155938123917}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:31,126] Trial 307 finished with value: 0.7128853272448216 and parameters: {'learning_rate': 0.1719060137001921, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.5467148012815446}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:32,508] Trial 308 finished with value: 0.7128528119316809 and parameters: {'learning_rate': 0.2484465382089944, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.7889069280727956}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:34,368] Trial 309 finished with value: 0.7133190391040058 and parameters: {'learning_rate': 0.19804985772840514, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.6124655008244296}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:36,140] Trial 310 finished with value: 0.7132881661021173 and parameters: {'learning_rate': 0.196400706921877, 'max_leaf_nodes': 34, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.5986111147245186}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:38,295] Trial 311 finished with value: 0.7114556215342225 and parameters: {'learning_rate': 0.13581430680178952, 'max_leaf_nodes': 34, 'max_depth': 2, 'min_samples_leaf': 65, 'l2_regularization': 0.5927072211679577}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:40,060] Trial 312 finished with value: 0.7110395669497682 and parameters: {'learning_rate': 0.1554005542504576, 'max_leaf_nodes': 32, 'max_depth': 3, 'min_samples_leaf': 26, 'l2_regularization': 0.6360592047712031}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:42,016] Trial 313 finished with value: 0.7129793970887357 and parameters: {'learning_rate': 0.18667853607154922, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.5297163464302219}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:43,924] Trial 314 finished with value: 0.7129525428656548 and parameters: {'learning_rate': 0.16986309327260032, 'max_leaf_nodes': 30, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.6102489186592234}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:45,713] Trial 315 finished with value: 0.7137434955795353 and parameters: {'learning_rate': 0.19858017857924112, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.5924277275608871}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:47,848] Trial 316 finished with value: 0.7122788209745072 and parameters: {'learning_rate': 0.10976116741733931, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.5862734194949158}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:49,949] Trial 317 finished with value: 0.7126566767128371 and parameters: {'learning_rate': 0.16010802550724174, 'max_leaf_nodes': 19, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.5738839538108093}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:51,996] Trial 318 finished with value: 0.7115360383475183 and parameters: {'learning_rate': 0.1246061178757586, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.623277712614682}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:54,056] Trial 319 finished with value: 0.7118274601015224 and parameters: {'learning_rate': 0.18685820221088942, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 33, 'l2_regularization': 0.6585123933455596}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:55,489] Trial 320 finished with value: 0.7111262975754923 and parameters: {'learning_rate': 0.2116361891811711, 'max_leaf_nodes': 27, 'max_depth': 3, 'min_samples_leaf': 22, 'l2_regularization': 0.42679372248956177}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:57,095] Trial 321 finished with value: 0.7099928693868389 and parameters: {'learning_rate': 0.1359574941860849, 'max_leaf_nodes': 23, 'max_depth': 8, 'min_samples_leaf': 19, 'l2_regularization': 0.456503061099692}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:43:59,200] Trial 322 finished with value: 0.7129012697027752 and parameters: {'learning_rate': 0.17351202671523708, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.5723858352739738}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:01,022] Trial 323 finished with value: 0.7121969576530663 and parameters: {'learning_rate': 0.22581613985957413, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.677550403055376}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:03,065] Trial 324 finished with value: 0.7128883420482647 and parameters: {'learning_rate': 0.14958288757213903, 'max_leaf_nodes': 36, 'max_depth': 2, 'min_samples_leaf': 29, 'l2_regularization': 0.5077554194165317}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:05,091] Trial 325 finished with value: 0.7130974133414449 and parameters: {'learning_rate': 0.19076904024335523, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.7707562654824875}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:07,006] Trial 326 finished with value: 0.7118758256751251 and parameters: {'learning_rate': 0.2049489920937048, 'max_leaf_nodes': 108, 'max_depth': 2, 'min_samples_leaf': 160, 'l2_regularization': 0.5574016364817187}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:08,848] Trial 327 finished with value: 0.7130712195229002 and parameters: {'learning_rate': 0.1699842937358514, 'max_leaf_nodes': 25, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 1.6788351287374286}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:10,812] Trial 328 finished with value: 0.7110295771657141 and parameters: {'learning_rate': 0.23128987603553616, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 51, 'l2_regularization': 1.7453747794638017}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:13,035] Trial 329 finished with value: 0.710752068263075 and parameters: {'learning_rate': 0.14421208470612382, 'max_leaf_nodes': 30, 'max_depth': 4, 'min_samples_leaf': 190, 'l2_regularization': 0.6254425200859703}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:14,714] Trial 330 finished with value: 0.712267898952423 and parameters: {'learning_rate': 0.2980594215616463, 'max_leaf_nodes': 34, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.8116937444664813}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:16,679] Trial 331 finished with value: 0.7127591883197013 and parameters: {'learning_rate': 0.1957185677596502, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.6692345818919689}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:18,665] Trial 332 finished with value: 0.712186143212261 and parameters: {'learning_rate': 0.16172913089078328, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.0505324300972205}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:20,233] Trial 333 finished with value: 0.7133753897645179 and parameters: {'learning_rate': 0.24999709005711446, 'max_leaf_nodes': 23, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.1319532646778987}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:21,690] Trial 334 finished with value: 0.7134077230639587 and parameters: {'learning_rate': 0.2444827529815623, 'max_leaf_nodes': 37, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.2854936705857253}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:23,304] Trial 335 finished with value: 0.7126816937744608 and parameters: {'learning_rate': 0.2466629568364179, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.1163248718820964}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:24,396] Trial 336 finished with value: 0.7085777961842118 and parameters: {'learning_rate': 0.26784522765647684, 'max_leaf_nodes': 38, 'max_depth': 9, 'min_samples_leaf': 10, 'l2_regularization': 0.37821087919936036}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:26,009] Trial 337 finished with value: 0.7126869826177161 and parameters: {'learning_rate': 0.25405852824747466, 'max_leaf_nodes': 30, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.0035612903596554}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:27,197] Trial 338 finished with value: 0.7126133968487274 and parameters: {'learning_rate': 0.2688200733826401, 'max_leaf_nodes': 25, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 0.13882656123459305}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:28,922] Trial 339 finished with value: 0.7130407636004319 and parameters: {'learning_rate': 0.22706530845070136, 'max_leaf_nodes': 36, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.04104218698002132}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:30,688] Trial 340 finished with value: 0.7117958529592181 and parameters: {'learning_rate': 0.22239254124426655, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.8475935326272508}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:31,870] Trial 341 finished with value: 0.7119703310721759 and parameters: {'learning_rate': 0.2504558974891822, 'max_leaf_nodes': 67, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 0.37934400364102616}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:34,080] Trial 342 finished with value: 0.7040829385928036 and parameters: {'learning_rate': 0.055158974002027406, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.2026231528739102}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:35,547] Trial 343 finished with value: 0.7125403743645665 and parameters: {'learning_rate': 0.2968897446110539, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.9455697097250282}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:37,654] Trial 344 finished with value: 0.7109632903812866 and parameters: {'learning_rate': 0.099083460079858, 'max_leaf_nodes': 38, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.904152232634667}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:39,842] Trial 345 finished with value: 0.7120924839152615 and parameters: {'learning_rate': 0.1204423514822899, 'max_leaf_nodes': 32, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.34603453627252495}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:41,671] Trial 346 finished with value: 0.712987045071164 and parameters: {'learning_rate': 0.2264085395410523, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.6193857581203677}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:43,747] Trial 347 finished with value: 0.7124933628336794 and parameters: {'learning_rate': 0.13208533238120818, 'max_leaf_nodes': 45, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.7140294792850668}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:45,166] Trial 348 finished with value: 0.710808468202789 and parameters: {'learning_rate': 0.21246248879015653, 'max_leaf_nodes': 60, 'max_depth': 3, 'min_samples_leaf': 20, 'l2_regularization': 0.24318393806038036}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:46,948] Trial 349 finished with value: 0.712780661246627 and parameters: {'learning_rate': 0.2485040434762924, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.9789851753153045}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:48,904] Trial 350 finished with value: 0.71352657382927 and parameters: {'learning_rate': 0.17728536638653156, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.2576507511090218}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:50,892] Trial 351 finished with value: 0.7126474003439267 and parameters: {'learning_rate': 0.17828543034756794, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.19203867847656103}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:52,706] Trial 352 finished with value: 0.7112724113373521 and parameters: {'learning_rate': 0.20852391823408303, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.30455136430022306}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:54,433] Trial 353 finished with value: 0.7116325689412821 and parameters: {'learning_rate': 0.1807752978872838, 'max_leaf_nodes': 37, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 0.326414376650631}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:56,064] Trial 354 finished with value: 0.7125176276970906 and parameters: {'learning_rate': 0.26768545832725027, 'max_leaf_nodes': 162, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.2378737156614787}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:44:58,190] Trial 355 finished with value: 0.7114603566145801 and parameters: {'learning_rate': 0.15698578061763532, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 151, 'l2_regularization': 0.28367514514368103}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:00,411] Trial 356 finished with value: 0.6978554500930317 and parameters: {'learning_rate': 0.03630089621448647, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 1.8275806886660007}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:02,145] Trial 357 finished with value: 0.7110678009035988 and parameters: {'learning_rate': 0.23916032697781708, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 35, 'l2_regularization': 0.266374854538722}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:03,940] Trial 358 finished with value: 0.7130836502246175 and parameters: {'learning_rate': 0.2018954331363165, 'max_leaf_nodes': 199, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.7791472630825396}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:05,787] Trial 359 finished with value: 0.7119333232771653 and parameters: {'learning_rate': 0.173957655558514, 'max_leaf_nodes': 146, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.1322281062633763}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:07,388] Trial 360 finished with value: 0.7122985894963586 and parameters: {'learning_rate': 0.2239034361977212, 'max_leaf_nodes': 41, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.8869002929814642}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:08,877] Trial 361 finished with value: 0.7120446149601583 and parameters: {'learning_rate': 0.2949829727778373, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.0408772210984731}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:10,770] Trial 362 finished with value: 0.7105033865152928 and parameters: {'learning_rate': 0.1538465108319796, 'max_leaf_nodes': 27, 'max_depth': 5, 'min_samples_leaf': 22, 'l2_regularization': 1.864401118748536}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:12,877] Trial 363 finished with value: 0.7110721862095105 and parameters: {'learning_rate': 0.1827193226830658, 'max_leaf_nodes': 75, 'max_depth': 2, 'min_samples_leaf': 99, 'l2_regularization': 1.8103351441795623}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:14,661] Trial 364 finished with value: 0.7112994619276034 and parameters: {'learning_rate': 0.20256559820454678, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 1.7440371519919589}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:16,253] Trial 365 finished with value: 0.7118991093426196 and parameters: {'learning_rate': 0.24021214044304684, 'max_leaf_nodes': 35, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.13361809452751397}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:18,216] Trial 366 finished with value: 0.7131085433761714 and parameters: {'learning_rate': 0.16839301337441134, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.48444375595430333}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:20,062] Trial 367 finished with value: 0.7121367824071243 and parameters: {'learning_rate': 0.2684846414391594, 'max_leaf_nodes': 48, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.0807749204741968}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:21,900] Trial 368 finished with value: 0.7127171273157756 and parameters: {'learning_rate': 0.21315174727982558, 'max_leaf_nodes': 30, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 1.5692154132397322}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:23,734] Trial 369 finished with value: 0.7116686376046781 and parameters: {'learning_rate': 0.1879098365470525, 'max_leaf_nodes': 35, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.8981796412114147}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:25,231] Trial 370 finished with value: 0.7105238597841992 and parameters: {'learning_rate': 0.14574384381857042, 'max_leaf_nodes': 16, 'max_depth': 6, 'min_samples_leaf': 10, 'l2_regularization': 1.8464042997978682}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:26,957] Trial 371 finished with value: 0.7111447055664215 and parameters: {'learning_rate': 0.2321611106643701, 'max_leaf_nodes': 83, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.949744448962906}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:28,781] Trial 372 finished with value: 0.7119685162932641 and parameters: {'learning_rate': 0.16295491156798073, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.8138555265433182}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:30,543] Trial 373 finished with value: 0.7117110213625194 and parameters: {'learning_rate': 0.19491954199946213, 'max_leaf_nodes': 41, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.6568807572948288}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:32,085] Trial 374 finished with value: 0.7122145460625977 and parameters: {'learning_rate': 0.2635137876141798, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 1.7982788121719873}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:33,989] Trial 375 finished with value: 0.71221695707631 and parameters: {'learning_rate': 0.21637172989744638, 'max_leaf_nodes': 99, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.7570593797440046}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:35,954] Trial 376 finished with value: 0.7129229047730705 and parameters: {'learning_rate': 0.17599891038138313, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.8653422641798825}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:36,976] Trial 377 finished with value: 0.7126047097410101 and parameters: {'learning_rate': 0.29939103932792993, 'max_leaf_nodes': 24, 'max_depth': 4, 'min_samples_leaf': 10, 'l2_regularization': 1.9248117743506634}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:38,455] Trial 378 finished with value: 0.7119622546320922 and parameters: {'learning_rate': 0.24532518751150892, 'max_leaf_nodes': 117, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.7014911642539934}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:40,636] Trial 379 finished with value: 0.7128033191326967 and parameters: {'learning_rate': 0.1488295870643423, 'max_leaf_nodes': 38, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.8080428798698003}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:42,336] Trial 380 finished with value: 0.7127643155647556 and parameters: {'learning_rate': 0.20614658663517307, 'max_leaf_nodes': 30, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.4846993390454268}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:44,469] Trial 381 finished with value: 0.6873019457614195 and parameters: {'learning_rate': 0.02223914817852114, 'max_leaf_nodes': 51, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.7568284713191614}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:46,317] Trial 382 finished with value: 0.712970687620623 and parameters: {'learning_rate': 0.18349554129128087, 'max_leaf_nodes': 44, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9720372308174617}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:48,101] Trial 383 finished with value: 0.7128036274343124 and parameters: {'learning_rate': 0.22770486021182812, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.9237441589633408}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:50,197] Trial 384 finished with value: 0.711382969578295 and parameters: {'learning_rate': 0.13851116735814048, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.22775354356906863}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:52,071] Trial 385 finished with value: 0.7125762691643799 and parameters: {'learning_rate': 0.16330366055005252, 'max_leaf_nodes': 227, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.8479765944499262}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:53,774] Trial 386 finished with value: 0.7113749856447049 and parameters: {'learning_rate': 0.26622211648989186, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 32, 'l2_regularization': 1.909786096233744}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:55,861] Trial 387 finished with value: 0.6770325474348494 and parameters: {'learning_rate': 0.01603886942593858, 'max_leaf_nodes': 35, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.78365045251502}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:57,857] Trial 388 finished with value: 0.7122230071898816 and parameters: {'learning_rate': 0.19701217338230162, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 77, 'l2_regularization': 0.15315294744409408}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:45:59,676] Trial 389 finished with value: 0.7119711427007481 and parameters: {'learning_rate': 0.21896844123380935, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.7252674164937174}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:01,700] Trial 390 finished with value: 0.713634615534065 and parameters: {'learning_rate': 0.17378737431849697, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.015345211017939}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:03,601] Trial 391 finished with value: 0.7118537573440049 and parameters: {'learning_rate': 0.17880568229684832, 'max_leaf_nodes': 34, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 1.0213992277718065}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:05,368] Trial 392 finished with value: 0.7129189578945948 and parameters: {'learning_rate': 0.19401910741918854, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.0069229672547924}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:07,384] Trial 393 finished with value: 0.7123302628411597 and parameters: {'learning_rate': 0.16599816929558878, 'max_leaf_nodes': 40, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.939442701474307}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:08,989] Trial 394 finished with value: 0.7126731799101952 and parameters: {'learning_rate': 0.24611284499889838, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.7872352713013402}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:10,973] Trial 395 finished with value: 0.7113339187653019 and parameters: {'learning_rate': 0.2153784478175257, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 57, 'l2_regularization': 1.1467999282836228}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:12,888] Trial 396 finished with value: 0.712458627942026 and parameters: {'learning_rate': 0.1821370953353092, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.837437250288905}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:14,986] Trial 397 finished with value: 0.669070436928346 and parameters: {'learning_rate': 0.01034980487565589, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.31219896931818814}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:16,995] Trial 398 finished with value: 0.713068455594162 and parameters: {'learning_rate': 0.15949464212701864, 'max_leaf_nodes': 45, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9839851158287718}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:19,052] Trial 399 finished with value: 0.7061189778143782 and parameters: {'learning_rate': 0.06360582924363482, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.097382202243489}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:20,669] Trial 400 finished with value: 0.7121859395987464 and parameters: {'learning_rate': 0.24030311718002034, 'max_leaf_nodes': 38, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.0614089078533548}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:22,539] Trial 401 finished with value: 0.7127492522290357 and parameters: {'learning_rate': 0.2039609623976294, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 41, 'l2_regularization': 1.8253850174496553}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:23,914] Trial 402 finished with value: 0.7123512927667977 and parameters: {'learning_rate': 0.26996502890487284, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.8873718847580854}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:25,984] Trial 403 finished with value: 0.7112762845004424 and parameters: {'learning_rate': 0.22091660042843383, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 90, 'l2_regularization': 1.9506629655672976}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:27,380] Trial 404 finished with value: 0.7097222037826272 and parameters: {'learning_rate': 0.18407223316387936, 'max_leaf_nodes': 56, 'max_depth': 6, 'min_samples_leaf': 24, 'l2_regularization': 0.9246468530069024}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:29,426] Trial 405 finished with value: 0.7107052098871085 and parameters: {'learning_rate': 0.15315924840400016, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 168, 'l2_regularization': 1.8446420137150277}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:31,354] Trial 406 finished with value: 0.7132535013021999 and parameters: {'learning_rate': 0.19942725386996868, 'max_leaf_nodes': 35, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.7824155001137874}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:32,995] Trial 407 finished with value: 0.7125525552325824 and parameters: {'learning_rate': 0.24657465277395532, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8948917523636226}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:35,066] Trial 408 finished with value: 0.7013840849904358 and parameters: {'learning_rate': 0.04480985876806613, 'max_leaf_nodes': 43, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.5236925280594515}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:37,106] Trial 409 finished with value: 0.7126286829028159 and parameters: {'learning_rate': 0.16815916599645178, 'max_leaf_nodes': 188, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.7646562674212687}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:38,696] Trial 410 finished with value: 0.711345832925981 and parameters: {'learning_rate': 0.2734209879437374, 'max_leaf_nodes': 92, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.2645698227068889}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:40,562] Trial 411 finished with value: 0.7117220646077559 and parameters: {'learning_rate': 0.2216634624894945, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 1.8823412067128122}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:42,578] Trial 412 finished with value: 0.7123863515319291 and parameters: {'learning_rate': 0.18282041856428086, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.45471725808821606}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:44,150] Trial 413 finished with value: 0.7108259659896203 and parameters: {'learning_rate': 0.2988097825584325, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.9986294184044582}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:46,171] Trial 414 finished with value: 0.7120322818740411 and parameters: {'learning_rate': 0.1493921271394772, 'max_leaf_nodes': 39, 'max_depth': 2, 'min_samples_leaf': 31, 'l2_regularization': 1.8129095355408338}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:47,901] Trial 415 finished with value: 0.7118084894187545 and parameters: {'learning_rate': 0.20517714159616238, 'max_leaf_nodes': 33, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.678328366610939}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:49,580] Trial 416 finished with value: 0.7120103419092305 and parameters: {'learning_rate': 0.2431370833152425, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.8689688276473422}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:51,454] Trial 417 finished with value: 0.7117687531419236 and parameters: {'learning_rate': 0.18921743160763987, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.8036898408383636}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:53,488] Trial 418 finished with value: 0.7136490299957483 and parameters: {'learning_rate': 0.16074124878830715, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.7339693066325332}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:55,587] Trial 419 finished with value: 0.7127781307269785 and parameters: {'learning_rate': 0.140546984587683, 'max_leaf_nodes': 104, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 1.720694131791021}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:57,566] Trial 420 finished with value: 0.7120831919830239 and parameters: {'learning_rate': 0.15809287304410838, 'max_leaf_nodes': 50, 'max_depth': 2, 'min_samples_leaf': 36, 'l2_regularization': 1.694383123409308}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:46:59,682] Trial 421 finished with value: 0.711299436702405 and parameters: {'learning_rate': 0.12814280736543152, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 1.6319050522618668}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:01,612] Trial 422 finished with value: 0.7119322215729184 and parameters: {'learning_rate': 0.1745767339231915, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.7526250484636243}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:03,727] Trial 423 finished with value: 0.7130957683743804 and parameters: {'learning_rate': 0.1406393556809747, 'max_leaf_nodes': 37, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 1.7487005620359788}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:05,628] Trial 424 finished with value: 0.7119759294925266 and parameters: {'learning_rate': 0.16272341197481008, 'max_leaf_nodes': 69, 'max_depth': 2, 'min_samples_leaf': 33, 'l2_regularization': 0.3918505748931691}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:07,345] Trial 425 finished with value: 0.7131735110698594 and parameters: {'learning_rate': 0.21498473558123873, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.8227382709123827}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:09,584] Trial 426 finished with value: 0.6074806271977345 and parameters: {'learning_rate': 0.0013818048391922434, 'max_leaf_nodes': 30, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.1849971222625024}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:11,723] Trial 427 finished with value: 0.6322418771168846 and parameters: {'learning_rate': 0.003738203071815056, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.9601182065852559}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:13,258] Trial 428 finished with value: 0.7107048273609109 and parameters: {'learning_rate': 0.17236052507098223, 'max_leaf_nodes': 63, 'max_depth': 7, 'min_samples_leaf': 23, 'l2_regularization': 1.86334543368326}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:15,380] Trial 429 finished with value: 0.712086832045596 and parameters: {'learning_rate': 0.11646774271381678, 'max_leaf_nodes': 43, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 1.9224589159100658}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:17,018] Trial 430 finished with value: 0.7124199495085775 and parameters: {'learning_rate': 0.24701079330691694, 'max_leaf_nodes': 217, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.7856795005556956}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:18,721] Trial 431 finished with value: 0.7109729189768574 and parameters: {'learning_rate': 0.2648194963715256, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 1.032403119463682}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:20,699] Trial 432 finished with value: 0.7132618680228505 and parameters: {'learning_rate': 0.14778574071771552, 'max_leaf_nodes': 177, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.023790567919989902}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:22,448] Trial 433 finished with value: 0.712884639313921 and parameters: {'learning_rate': 0.19557215192955058, 'max_leaf_nodes': 35, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.09329806640615534}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:24,149] Trial 434 finished with value: 0.71012169799048 and parameters: {'learning_rate': 0.2304014214065077, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 120, 'l2_regularization': 1.840206139461929}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:26,166] Trial 435 finished with value: 0.7130945937382458 and parameters: {'learning_rate': 0.16544900867787948, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.7184643708275449}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:27,991] Trial 436 finished with value: 0.7124678666414861 and parameters: {'learning_rate': 0.21856677289867313, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.900059274256116}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:29,896] Trial 437 finished with value: 0.711631352227014 and parameters: {'learning_rate': 0.18686447074769916, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.8906373501608138}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:31,352] Trial 438 finished with value: 0.7114376113129521 and parameters: {'learning_rate': 0.2806141134860427, 'max_leaf_nodes': 40, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.801002259753267}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:33,410] Trial 439 finished with value: 0.7130625019672779 and parameters: {'learning_rate': 0.13342099612359504, 'max_leaf_nodes': 47, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.766136298311893}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:35,195] Trial 440 finished with value: 0.7117666594090117 and parameters: {'learning_rate': 0.17193555624300869, 'max_leaf_nodes': 20, 'max_depth': 3, 'min_samples_leaf': 20, 'l2_regularization': 1.65119230277436}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:36,646] Trial 441 finished with value: 0.712554042511013 and parameters: {'learning_rate': 0.23500054691239602, 'max_leaf_nodes': 34, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.8396235289975809}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:38,838] Trial 442 finished with value: 0.6904981322430044 and parameters: {'learning_rate': 0.026522791070803017, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 1.9392498815559926}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:40,774] Trial 443 finished with value: 0.7133353020947824 and parameters: {'learning_rate': 0.20486675720399375, 'max_leaf_nodes': 23, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.7474438308261231}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:42,730] Trial 444 finished with value: 0.7123218610039438 and parameters: {'learning_rate': 0.1498130443399368, 'max_leaf_nodes': 36, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.9240440050534544}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:44,490] Trial 445 finished with value: 0.7113841427505012 and parameters: {'learning_rate': 0.26185599566666873, 'max_leaf_nodes': 29, 'max_depth': 2, 'min_samples_leaf': 29, 'l2_regularization': 1.871435396487739}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:46,336] Trial 446 finished with value: 0.7116749388196386 and parameters: {'learning_rate': 0.18301409015418518, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.6922879675740803}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:48,195] Trial 447 finished with value: 0.7127343260836165 and parameters: {'learning_rate': 0.2079409198268198, 'max_leaf_nodes': 25, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.9715100175672021}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:50,214] Trial 448 finished with value: 0.7143811929185659 and parameters: {'learning_rate': 0.160122699954156, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.823534240870395}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:52,397] Trial 449 finished with value: 0.7120958641824643 and parameters: {'learning_rate': 0.12613054343736188, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.8434802868207927}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:54,504] Trial 450 finished with value: 0.7117488191560605 and parameters: {'learning_rate': 0.15303172422473355, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 45, 'l2_regularization': 1.8888335446826972}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:56,737] Trial 451 finished with value: 0.7111802636305238 and parameters: {'learning_rate': 0.13525292312774911, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 67, 'l2_regularization': 1.964443735414009}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:58,286] Trial 452 finished with value: 0.7134359394298837 and parameters: {'learning_rate': 0.29943667589600703, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.003724361993451}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:47:59,258] Trial 453 finished with value: 0.7085345168025355 and parameters: {'learning_rate': 0.28598593440860726, 'max_leaf_nodes': 16, 'max_depth': 10, 'min_samples_leaf': 17, 'l2_regularization': 1.0257253218191953}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:01,236] Trial 454 finished with value: 0.71276368490284 and parameters: {'learning_rate': 0.16115109434953323, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.9130700849653073}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:02,297] Trial 455 finished with value: 0.7106019746369884 and parameters: {'learning_rate': 0.2923195393325783, 'max_leaf_nodes': 54, 'max_depth': 3, 'min_samples_leaf': 18, 'l2_regularization': 1.0003326439791014}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:04,451] Trial 456 finished with value: 0.6187080904493474 and parameters: {'learning_rate': 0.0021156814845366577, 'max_leaf_nodes': 125, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.8192897207029355}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:06,387] Trial 457 finished with value: 0.7122975833969241 and parameters: {'learning_rate': 0.14344357998479784, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.8580257192543606}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:07,848] Trial 458 finished with value: 0.7121277382945551 and parameters: {'learning_rate': 0.29823772516348324, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.5296314265103286}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:09,976] Trial 459 finished with value: 0.7109826240648858 and parameters: {'learning_rate': 0.1108030799482432, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 1.7932840029503425}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:11,862] Trial 460 finished with value: 0.7136285150405671 and parameters: {'learning_rate': 0.17849772222661633, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.8699955529641067}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:13,945] Trial 461 finished with value: 0.7129600147566382 and parameters: {'learning_rate': 0.17055934869192316, 'max_leaf_nodes': 19, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.8769635686857609}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:16,071] Trial 462 finished with value: 0.713853516092781 and parameters: {'learning_rate': 0.1458710339749827, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.8627950887332188}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:18,156] Trial 463 finished with value: 0.7113334163645761 and parameters: {'learning_rate': 0.11431896434499196, 'max_leaf_nodes': 16, 'max_depth': 3, 'min_samples_leaf': 22, 'l2_regularization': 0.8053417227610175}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:20,056] Trial 464 finished with value: 0.7112281943962788 and parameters: {'learning_rate': 0.12663103211182047, 'max_leaf_nodes': 20, 'max_depth': 5, 'min_samples_leaf': 27, 'l2_regularization': 0.866963722957507}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:22,110] Trial 465 finished with value: 0.7134730816071184 and parameters: {'learning_rate': 0.1439929384709928, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.9155735587074448}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:24,233] Trial 466 finished with value: 0.7124320749018074 and parameters: {'learning_rate': 0.1371974284874191, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 33, 'l2_regularization': 0.8389933731245649}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:26,118] Trial 467 finished with value: 0.7129867363743317 and parameters: {'learning_rate': 0.1507669236897562, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.9081126335729665}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:28,166] Trial 468 finished with value: 0.7102101378025283 and parameters: {'learning_rate': 0.09260321446756249, 'max_leaf_nodes': 25, 'max_depth': 7, 'min_samples_leaf': 27, 'l2_regularization': 0.8206065066565594}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:30,202] Trial 469 finished with value: 0.711905131948624 and parameters: {'learning_rate': 0.12288348073375367, 'max_leaf_nodes': 113, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.8851592422232917}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:32,283] Trial 470 finished with value: 0.712475667539915 and parameters: {'learning_rate': 0.14532613172554276, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 0.9327400061488476}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:34,454] Trial 471 finished with value: 0.7106756022805591 and parameters: {'learning_rate': 0.10536820815756198, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 38, 'l2_regularization': 0.7839332743962965}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:36,363] Trial 472 finished with value: 0.7133126638992222 and parameters: {'learning_rate': 0.15988168153493698, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.8705492250875037}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:38,470] Trial 473 finished with value: 0.7121240953985 and parameters: {'learning_rate': 0.14312715558680889, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.8428077811858692}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:40,514] Trial 474 finished with value: 0.7121929195473083 and parameters: {'learning_rate': 0.1704724349436452, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.8911649855785093}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:42,269] Trial 475 finished with value: 0.7119204090917524 and parameters: {'learning_rate': 0.1353981579447232, 'max_leaf_nodes': 23, 'max_depth': 3, 'min_samples_leaf': 25, 'l2_regularization': 0.9566160220872634}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:44,299] Trial 476 finished with value: 0.7133331243754703 and parameters: {'learning_rate': 0.15822725632860243, 'max_leaf_nodes': 211, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.9109918621726781}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:46,391] Trial 477 finished with value: 0.7128666405239761 and parameters: {'learning_rate': 0.12234653431233784, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.7632313547269336}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:48,335] Trial 478 finished with value: 0.7119769639171828 and parameters: {'learning_rate': 0.17618751197788968, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.9383823916782726}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:50,221] Trial 479 finished with value: 0.7122420953832853 and parameters: {'learning_rate': 0.15073525669123133, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.8199601054086858}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:52,039] Trial 480 finished with value: 0.7125907162797255 and parameters: {'learning_rate': 0.1788746489020149, 'max_leaf_nodes': 32, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.7235646812435172}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:54,006] Trial 481 finished with value: 0.7130443777319915 and parameters: {'learning_rate': 0.15694501977452793, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.8524145421160839}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:56,035] Trial 482 finished with value: 0.7095234230358816 and parameters: {'learning_rate': 0.13346210016632337, 'max_leaf_nodes': 21, 'max_depth': 2, 'min_samples_leaf': 111, 'l2_regularization': 0.9611301666171554}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:57,888] Trial 483 finished with value: 0.7122404306222936 and parameters: {'learning_rate': 0.18768066794639277, 'max_leaf_nodes': 32, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 0.7992045416090913}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:48:59,895] Trial 484 finished with value: 0.7127336735683236 and parameters: {'learning_rate': 0.16983477813314293, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.9056973668254796}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:01,898] Trial 485 finished with value: 0.7125863618148329 and parameters: {'learning_rate': 0.14373569734239605, 'max_leaf_nodes': 27, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.8645395507517133}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:04,059] Trial 486 finished with value: 0.7090850106848047 and parameters: {'learning_rate': 0.1182772803378393, 'max_leaf_nodes': 79, 'max_depth': 2, 'min_samples_leaf': 134, 'l2_regularization': 0.688863479846285}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:05,778] Trial 487 finished with value: 0.7119395921103555 and parameters: {'learning_rate': 0.18859822428670034, 'max_leaf_nodes': 22, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.9254558494628979}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:07,681] Trial 488 finished with value: 0.7130798163727021 and parameters: {'learning_rate': 0.16289085275154414, 'max_leaf_nodes': 39, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.9192985447742514}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:09,562] Trial 489 finished with value: 0.713617973304404 and parameters: {'learning_rate': 0.19786651499582875, 'max_leaf_nodes': 32, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.4732208747932835}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:11,421] Trial 490 finished with value: 0.7133280674565501 and parameters: {'learning_rate': 0.1670209296310249, 'max_leaf_nodes': 44, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.5342503715805307}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:12,961] Trial 491 finished with value: 0.7114892394464005 and parameters: {'learning_rate': 0.1865468504848056, 'max_leaf_nodes': 34, 'max_depth': 3, 'min_samples_leaf': 26, 'l2_regularization': 0.45050466529686295}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:15,006] Trial 492 finished with value: 0.7125525977666737 and parameters: {'learning_rate': 0.1359214583309329, 'max_leaf_nodes': 60, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.7241609291855576}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:16,954] Trial 493 finished with value: 0.7133142781267929 and parameters: {'learning_rate': 0.20000625959486584, 'max_leaf_nodes': 40, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.5678223910798498}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:18,839] Trial 494 finished with value: 0.7130348102234119 and parameters: {'learning_rate': 0.1576172367977762, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.5104374288928066}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:20,542] Trial 495 finished with value: 0.713467679451793 and parameters: {'learning_rate': 0.2144168539914783, 'max_leaf_nodes': 49, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.40239754664412863}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:22,649] Trial 496 finished with value: 0.7081224881862196 and parameters: {'learning_rate': 0.08125538205652653, 'max_leaf_nodes': 53, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.6533093251457668}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:24,583] Trial 497 finished with value: 0.7129232003891615 and parameters: {'learning_rate': 0.1810867222058567, 'max_leaf_nodes': 50, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.35740155705033294}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:26,141] Trial 498 finished with value: 0.7124488028349383 and parameters: {'learning_rate': 0.20725050021941224, 'max_leaf_nodes': 44, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.45137790297521085}. Best is trial 223 with value: 0.7148864553158866.\n",
      "[I 2025-07-03 21:49:28,053] Trial 499 finished with value: 0.7129047476794632 and parameters: {'learning_rate': 0.14876788666152377, 'max_leaf_nodes': 47, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.4830113899897081}. Best is trial 223 with value: 0.7148864553158866.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search complete in 00:16:54.\n",
      "\n",
      "Top 5 Optuna Search Results (F1 Score):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_l2_regularization</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_max_leaf_nodes</th>\n",
       "      <th>params_min_samples_leaf</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>0.714886</td>\n",
       "      <td>2025-07-03 21:41:02.217345</td>\n",
       "      <td>2025-07-03 21:41:04.128405</td>\n",
       "      <td>0 days 00:00:01.911060</td>\n",
       "      <td>0.934488</td>\n",
       "      <td>0.207877</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>448</td>\n",
       "      <td>0.714381</td>\n",
       "      <td>2025-07-03 21:47:48.195763</td>\n",
       "      <td>2025-07-03 21:47:50.214876</td>\n",
       "      <td>0 days 00:00:02.019113</td>\n",
       "      <td>1.823534</td>\n",
       "      <td>0.160123</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>0.714339</td>\n",
       "      <td>2025-07-03 21:36:54.206512</td>\n",
       "      <td>2025-07-03 21:36:56.031021</td>\n",
       "      <td>0 days 00:00:01.824509</td>\n",
       "      <td>1.888719</td>\n",
       "      <td>0.206497</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>283</td>\n",
       "      <td>0.713900</td>\n",
       "      <td>2025-07-03 21:42:45.063728</td>\n",
       "      <td>2025-07-03 21:42:46.723591</td>\n",
       "      <td>0 days 00:00:01.659863</td>\n",
       "      <td>0.697809</td>\n",
       "      <td>0.250201</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>0.713877</td>\n",
       "      <td>2025-07-03 21:39:57.594489</td>\n",
       "      <td>2025-07-03 21:39:59.495576</td>\n",
       "      <td>0 days 00:00:01.901087</td>\n",
       "      <td>1.678706</td>\n",
       "      <td>0.182670</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number     value             datetime_start          datetime_complete  \\\n",
       "223     223  0.714886 2025-07-03 21:41:02.217345 2025-07-03 21:41:04.128405   \n",
       "448     448  0.714381 2025-07-03 21:47:48.195763 2025-07-03 21:47:50.214876   \n",
       "92       92  0.714339 2025-07-03 21:36:54.206512 2025-07-03 21:36:56.031021   \n",
       "283     283  0.713900 2025-07-03 21:42:45.063728 2025-07-03 21:42:46.723591   \n",
       "189     189  0.713877 2025-07-03 21:39:57.594489 2025-07-03 21:39:59.495576   \n",
       "\n",
       "                  duration  params_l2_regularization  params_learning_rate  \\\n",
       "223 0 days 00:00:01.911060                  0.934488              0.207877   \n",
       "448 0 days 00:00:02.019113                  1.823534              0.160123   \n",
       "92  0 days 00:00:01.824509                  1.888719              0.206497   \n",
       "283 0 days 00:00:01.659863                  0.697809              0.250201   \n",
       "189 0 days 00:00:01.901087                  1.678706              0.182670   \n",
       "\n",
       "     params_max_depth  params_max_leaf_nodes  params_min_samples_leaf  \\\n",
       "223                 2                     24                       10   \n",
       "448                 2                     16                       16   \n",
       "92                  2                     32                       10   \n",
       "283                 2                     16                       10   \n",
       "189                 2                     43                       15   \n",
       "\n",
       "        state  \n",
       "223  COMPLETE  \n",
       "448  COMPLETE  \n",
       "92   COMPLETE  \n",
       "283  COMPLETE  \n",
       "189  COMPLETE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best F1 Score from Optuna: 0.7149\n",
      "Best Parameters: {'learning_rate': 0.20787700729016054, 'max_leaf_nodes': 24, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9344877277799697}\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Define the objective function for Optuna to optimize.\n",
    "# The function takes a 'trial' object, which suggests hyperparameter values.\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space using Optuna's suggestion methods.\n",
    "    # This is equivalent to the distribution dictionary in RandomizedSearchCV.\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 16, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 10, 200),\n",
    "        'l2_regularization': trial.suggest_float('l2_regularization', 0.0, 2.0, log=False)\n",
    "    }\n",
    "\n",
    "    # Create a new instance of the model with the suggested hyperparameters for this trial.\n",
    "    # The 'gb__' prefix targets the model within the pipeline.\n",
    "    model = pipelined_model.set_params(**{f\"gb__{key}\": value for key, value in params.items()})\n",
    "\n",
    "    # Set up the same stratified K-Fold cross-validator\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    # Perform cross-validation and get the mean F1 score\n",
    "    f1_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='f1')\n",
    "    \n",
    "    # Optuna will try to maximize this return value\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# Create a study object. 'direction=\"maximize\"' tells Optuna we want to maximize the F1 score.\n",
    "study = optuna.create_study(direction='maximize', study_name='hgbc_f1_optimization')\n",
    "\n",
    "print(\"Running Optuna Search...\")\n",
    "# Start the timer\n",
    "start_time_optuna = time.time()\n",
    "\n",
    "# Start the optimization process. Optuna will call the 'objective' function for n_trials.\n",
    "try:\n",
    "    study.optimize(objective, n_trials=500)  # Run for 500 trials\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Study stopped manually.\") # Allows stopping the study early\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time_optuna = time.time() - start_time_optuna\n",
    "print(f\"Search complete in {format_hms(elapsed_time_optuna)}.\")\n",
    "\n",
    "\n",
    "# Create a DataFrame from the study's trials to display results\n",
    "optuna_results_df = study.trials_dataframe()\n",
    "\n",
    "# Sort by the best value (F1 score) and display the top 5 trials\n",
    "top_5_optuna_results = optuna_results_df.sort_values(by='value', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Optuna Search Results (F1 Score):\")\n",
    "display(top_5_optuna_results.head())\n",
    "\n",
    "# Print the best score and parameters found\n",
    "print(f\"\\nBest F1 Score from Optuna: {study.best_value:.4f}\")\n",
    "print(f\"Best Parameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 Graded Answer\n",
    "\n",
    "Set `a3` to the mean F1 score of the best model found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a3 = study.best_value                     # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3 = 0.7149\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a3 = {a3:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Final Model Evaluation on Test Set\n",
    "\n",
    "In this problem, you will take the best hyperparameter configuration you found in your earlier experiments (Randomized Search or Optuna) and fully evaluate the resulting model on the test set.\n",
    "\n",
    "**Background:**\n",
    "When performing hyperparameter tuning, we typically optimize for a single metric (e.g., F1). However, before deployment, it is essential to check **all relevant metrics** on the final test set to understand the model’s behavior in a balanced way.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Take the best hyperparameters you found in Problems 2 or 3 and apply them to your `pipelined_model`.\n",
    "2. Re-train this final tuned model on the **entire training set** (not just the folds).\n",
    "3. Evaluate the final model on the heldout **test set**, reporting the following metrics:\n",
    "\n",
    "   * Precision\n",
    "   * Recall\n",
    "   * F1 score\n",
    "   * Balanced accuracy\n",
    "4. Use `classification_report` **on the test set** to print precision, recall, and F1 score, and use `balanced_accuracy_score` separately to calculate and print balanced accuracy.\n",
    "5. Answer the graded questions.\n",
    "\n",
    "**Note:** We evaluate the metrics on the test set because it was never seen during training or hyperparameter tuning. This gives us an unbiased estimate of how the model will perform on truly unseen data. Evaluating on the training set would be misleading, because the model has already learned from that data and could appear artificially good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model on the entire training set...\n",
      "Training complete.\n",
      "\n",
      "--- Final Model Evaluation on Test Set ---\n",
      "Balanced Accuracy: 0.8451\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9514    0.8241    0.8832      7431\n",
      "           1     0.6077    0.8661    0.7143      2338\n",
      "\n",
      "    accuracy                         0.8342      9769\n",
      "   macro avg     0.7796    0.8451    0.7987      9769\n",
      "weighted avg     0.8691    0.8342    0.8428      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Use the best hyperparameters found from your best experiment (e.g., Optuna)\n",
    "# The keys need to be prefixed with 'gb__' to target the model inside the pipeline.\n",
    "best_params = {f\"gb__{key}\": value for key, value in study.best_params.items()}\n",
    "\n",
    "# Create a new pipeline instance with the best hyperparameters\n",
    "final_model = pipelined_model.set_params(**best_params)\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "print(\"Training final model on the entire training set...\")\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Make predictions on the unseen test set\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "\n",
    "# --- Evaluate the final model on the test set ---\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Generate the classification report (includes precision, recall, f1-score)\n",
    "class_report = classification_report(y_test, y_pred_test, digits=4)\n",
    "\n",
    "# Generate a dictionary for the classification report\n",
    "report_dict = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "\n",
    "# Print the final evaluation metrics\n",
    "print(\"\\n--- Final Model Evaluation on Test Set ---\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 Graded Questions\n",
    "\n",
    "- Set `a4a` to the balanced accuracy score of the best model.\n",
    "- Set `a4b` to the macro average precision of this model.\n",
    "- Set `a4c` to the macro average recall score of the this model.\n",
    "\n",
    "**Note:** Macro average takes the mean of each class’s precision/recall without considering how many samples each class has, which is appropriate for a balanced evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4a = balanced_acc                     # replace 0 with your answer, use variable or expression from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4a = 0.8451\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4a = {a4a:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4b = report_dict['macro avg']['precision']                     # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4b = 0.7796\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4b = {a4b:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4c = report_dict['macro avg']['recall']                     # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4c = 0.8451\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4c = {a4c:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Understanding Precision, Recall, F1, and Balanced Accuracy\n",
    "\n",
    "**Tutorial**\n",
    "\n",
    "In binary classification, you will often evaluate these key metrics:\n",
    "\n",
    "* **Precision**: *Of all the positive predictions the model made, how many were actually correct?*\n",
    "\n",
    "  * High precision = few false positives\n",
    "  * Low precision = many false positives\n",
    "\n",
    "* **Recall**: *Of all the actual positive cases, how many did the model correctly identify?*\n",
    "\n",
    "  * High recall = few false negatives\n",
    "  * Low recall = many false negatives\n",
    "\n",
    "* **F1 score**: The harmonic mean of precision and recall, which balances them in a single measure.\n",
    "\n",
    "  * F1 is **highest** when precision and recall are both high and similar in value.\n",
    "  * If precision and recall are unbalanced, F1 will drop to reflect that imbalance.\n",
    "\n",
    "* **Balanced accuracy**: The average of recall across both classes (positive and negative).\n",
    "\n",
    "  * It ensures the classifier is performing reasonably well on *both* groups, correcting for class imbalance.\n",
    "  * Balanced accuracy is especially important if the classes are very unequal in size.\n",
    "\n",
    "**Typical trade-offs to remember:**\n",
    "\n",
    "* **Higher recall, lower precision**: the model finds most true positives but also mislabels some negatives as positives\n",
    "* **Higher precision, lower recall**: the model is strict about positive predictions, but misses some true positives\n",
    "* **Balanced precision and recall (good F1)**: a practical compromise\n",
    "* **Balanced accuracy**: checks fairness across both classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Problem 5 Graded Question (multiple choice)\n",
    "\n",
    "A bank uses your model to identify customers earning over $50K for a premium product invitation. Based on your final test set evaluation, including macro-averaged precision and recall, which of the following best describes what might happen?\n",
    "\n",
    "(1) The bank will miss some eligible high-income customers, but will avoid marketing mistakes by sending invitations only to those it is  confident about.\n",
    "\n",
    "(2) The bank will successfully reach most high-income customers, but will also waste resources sending invitations to some low-income customers.\n",
    "\n",
    "(3) The bank will perfectly identify all high-income and low-income customers, resulting in no wasted invitations and no missed opportunities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a5 = 2                     # replace 0 with one of 1, 2, or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a5 = 2\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a5 = {a5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix One: Feature Engineering\n",
    "\n",
    "Here are some practical feature-engineering tweaks worth considering (beyond simply ordinal-encoding the categoricals)\n",
    "\n",
    "| Feature(s)                                                           | Why the tweak can help                                                                                                                                                     | How to do it (quick version)                                                                                                                                                    | Keep / drop?      |\n",
    "| -------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------- |\n",
    "| **`fnlwgt`**                                                         | Survey sampling weight, not a predictor. Leaving it in often lets the model “cheat.”                                                                                       | `df = df.drop(columns=[\"fnlwgt\"])`                                                                                                                                              | **Drop**          |\n",
    "| **`education` *vs.* `education-num`**                                | They encode the **same** information twice (categorical label and its ordinal rank). Keeping both is redundant and can cause leakage of a perfectly predictive feature.    | Usually keep **only one**. For tree models `education-num` is simplest: `df = df.drop(columns=[\"education\"])`                                                                   | **Drop one**      |\n",
    "| **`capital-gain`, `capital-loss`**                                   | Highly skewed; most values are zero with a long upper tail. The sign (gain vs. loss) matters, but treating them separately wastes a feature slot.                          | 1) Combine: `df[\"capital_net\"] = df[\"capital-gain\"] - df[\"capital-loss\"]`; 2) Log-transform to reduce skew: `df[\"capital_net_log\"] = np.log1p(df[\"capital_net\"].clip(lower=0))` | Replace originals |\n",
    "| **`age`, `hours-per-week`**                                          | Continuous but with natural plateaus—trees handle splits fine, yet log or square-root scaling can soften extreme values; bucketing makes partial-dependence plots clearer. | Simple bucket: `df[\"age_bin\"] = pd.cut(df[\"age\"], bins=[16,25,35,45,55,65,90])` (optional)                                                                                      | Optional          |\n",
    "| **Missing categories** (`workclass`, `occupation`, `native-country`) | HGB handles `-1`/`-2` codes fine, but you may want *explicit* “Missing” bucket for interpretability.                                                                       | Use `encoded_missing_value=-2` during encoding.                                                                                                            | Keep as is        |\n",
    "| **Rare categories in `native-country`**                              | Hundreds of low-frequency countries dilute signal; grouping boosts stability.                                                                                              | Map infrequent categories to “Other”:                                                                                                                                           |                   |\n",
    "\n",
    "\n",
    "#### Minimum set of tweaks (good baseline, low effort)\n",
    "\n",
    "1. **Drop `fnlwgt`.**  \n",
    "2. **Keep `education-num`, drop `education`.**  \n",
    "3. **Combine `capital-gain` and `capital-loss` into `capital_net`** (optionally add a log-scaled version).  \n",
    "4. Leave other numeric/categorical features as is; your histogram-GBDT will cope.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
