{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 08: Classification\n",
    "\n",
    "**Due:** Midnight on June 11th, BUT no late points will be charged if you get it in by the last late deadline. \n",
    "\n",
    "### Overview\n",
    "\n",
    "In this final homework before starting our course project, we will introduce the essential machine learning paradigm of **classification**. We will work with the **UCI Adult** dataset. This is a binary classification task.\n",
    "\n",
    "As we’ve discussed in this week’s lessons, the classification workflow is similar to what we’ve done for regression, with a few key differences:\n",
    "- We use `StratifiedKFold` instead of plain `KFold` so that every fold keeps the original class proportions.\n",
    "- We use classification metrics (e.g., accuracy, precision, recall, F1-score for binary classification) instead of regression metrics.\n",
    "- We could explore misclassified instances through a confusion matrix (though we will not do that in this homework).\n",
    "\n",
    "For this assignment, you’ll build a gradient boosting classification using `HistGradientBoostingClassifier` (HGBC) and explore ways of tuning the hyperparameters, including using the technique of early stopping, which basically avoiding have to tune the number of estimators (called `max_iter` in HGBC). \n",
    "\n",
    "HGBC has many advantages, which we explain below. \n",
    "\n",
    "\n",
    "### Grading\n",
    "\n",
    "There are 7 graded problems, each worth 7 points, and you get 1 point free if you complete the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abcbb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General utilities\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import zipfile\n",
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# Data handling and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    " \n",
    "# Data source\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    " \n",
    "# scikit-learn core tools \n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    " \n",
    "# Import model \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    " \n",
    "# Metrics\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    " \n",
    "# Distributions for random search\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "\n",
    "# pandas dtypes helpers\n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "from pandas import CategoricalDtype\n",
    "\n",
    "# Optuna Hyperparameter Search tool    (may need to be installed)\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Misc\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "def format_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelude 1: Load and Preprocess the UCI Adult Income Dataset\n",
    "\n",
    "- Load the dataset from sklearn\n",
    "- Preliminary EDA\n",
    "- Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   age             48842 non-null  int64   \n",
      " 1   workclass       46043 non-null  category\n",
      " 2   fnlwgt          48842 non-null  int64   \n",
      " 3   education       48842 non-null  category\n",
      " 4   education-num   48842 non-null  int64   \n",
      " 5   marital-status  48842 non-null  category\n",
      " 6   occupation      46033 non-null  category\n",
      " 7   relationship    48842 non-null  category\n",
      " 8   race            48842 non-null  category\n",
      " 9   sex             48842 non-null  category\n",
      " 10  capital-gain    48842 non-null  int64   \n",
      " 11  capital-loss    48842 non-null  int64   \n",
      " 12  hours-per-week  48842 non-null  int64   \n",
      " 13  native-country  47985 non-null  category\n",
      " 14  class           48842 non-null  category\n",
      "dtypes: category(9), int64(6)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Load and clean\n",
    "df = fetch_openml(name='adult', version=2, as_frame=True).frame\n",
    "\n",
    "df.replace(\"?\", np.nan, inplace=True)            # Some datasets use ? instead of Nan for missing data\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check: Is the dataset imbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "<=50K    0.760718\n",
      ">50K     0.239282\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YES:** It looks like this dataset is somewhat imbalanced. Therefore, we will \n",
    "1. Tell the model to compensate during training by setting `class_weight='balanced'` when defining the model;\n",
    "2. Evaluate it `balanced_accuracy` instead of `accuracy` and with class-aware metrics (precision, recall, F1); and\n",
    "3. [Optional] Adjust the probability threshold instead of relying on raw accuracy alone after examining the precision-recall trade-off you observe at 0.5.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Based on the considerations in **Appendix One**, we'll make the following changes to the dataset to facilitate training:\n",
    "\n",
    "\n",
    "1. Drop `fnlwgt` and `education`.   \n",
    "3. Replace `capital-gain` and `capital-loss` by their difference `capital_net` and add a log-scaled version `capital_net_log`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   age              48842 non-null  int64   \n",
      " 1   workclass        46043 non-null  category\n",
      " 2   education-num    48842 non-null  int64   \n",
      " 3   marital-status   48842 non-null  category\n",
      " 4   occupation       46033 non-null  category\n",
      " 5   relationship     48842 non-null  category\n",
      " 6   race             48842 non-null  category\n",
      " 7   sex              48842 non-null  category\n",
      " 8   hours-per-week   48842 non-null  int64   \n",
      " 9   native-country   47985 non-null  category\n",
      " 10  class            48842 non-null  category\n",
      " 11  capital_net      48842 non-null  int64   \n",
      " 12  capital_net_log  48842 non-null  float64 \n",
      "dtypes: category(8), float64(1), int64(4)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop the survey-weight column\n",
    "df_eng = df.drop(columns=[\"fnlwgt\"])\n",
    "\n",
    "# Keep only the ordinal education feature\n",
    "df_eng = df_eng.drop(columns=[\"education\"])      # retain 'education-num'\n",
    "\n",
    "# Combine capital gains and losses, add a log-scaled variant\n",
    "df_eng[\"capital_net\"]     = df_eng[\"capital-gain\"] - df_eng[\"capital-loss\"]\n",
    "df_eng[\"capital_net_log\"] = np.log1p(df_eng[\"capital_net\"].clip(lower=0))\n",
    "df_eng = df_eng.drop(columns=[\"capital-gain\", \"capital-loss\"])\n",
    "\n",
    "# check\n",
    "df_eng.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate target and split\n",
    "\n",
    "Create the feature set `X` and the target set `y` (using `class` as the target) and split the dataset into 80% training and 20% testing sets, making sure to stratify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (39073, 12) (39073,)\n",
      "Test : (9769, 12) (9769,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_eng.drop(columns=[\"class\"])\n",
    "y = (df_eng[\"class\"] == \">50K\").astype(int)\n",
    "\n",
    "# Split (with stratification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=random_seed,\n",
    "    stratify=y                           # So same proportion of classes in train and test sets\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test :\", X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelude 2: Create a data pipeline and the `HistGradientBoostingClassifier` model\n",
    "\n",
    "Histogram-based gradient boosting improves on the standard version by:\n",
    "\n",
    "* **Histogram splits:** bins each feature into ≤ `max_bins` quantiles (i.e., each bin is approximately the same size) and tests splits only between bins, slashing compute time and scaling to large data sets. Default for `max_bins` = 255. \n",
    "* **Native NaN handling:** treats missing values as their own bin—no imputation needed.\n",
    "* **Native Categorical Support**: accepts integer-encoded categories directly and tests “category c vs. all others” splits, eliminating one-hot blow-ups and fake orderings.\n",
    "* **Built-in early stopping:** stops training after no improvement in validation loss after `n_iter_no_change` rounds. `tol` defines \"improvement\" (default is 1e-7). \n",
    "* **Leaf shrinkage:** adds `l2_regularization`, which ridge-shrinks each leaf value (without changing tree shape) so tiny, noisy leaves have less effect.\n",
    "\n",
    ">**Summary:**  Histogram-based GB trades a tiny approximation error (binning) for a **huge speed-up** and adds extra conveniences, making it the preferred choice for large tabular data sets. Tuning workflow relies on **Early stopping** to stop training before overfitting occurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a baseline model \n",
    "\n",
    "HGBC_model = HistGradientBoostingClassifier(\n",
    "    # tree structure and learning rate\n",
    "    learning_rate=0.1,            # These 5 parameters are at defaults for our baseline training in Problem 1             \n",
    "    max_leaf_nodes=31,            # but will be tuned by randomized search in Problem 2 and Optuna in Problem 3               \n",
    "    max_depth=None,               \n",
    "    min_samples_leaf=20,          \n",
    "    l2_regularization=0.0,        \n",
    "\n",
    "    # bins and iteration\n",
    "    max_bins=255,                 # default\n",
    "    max_iter=500,                 # high enough for early stopping\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    validation_fraction=0.2,      # 20% monitored for early stopping\n",
    "    tol=1e-7,                     # default tolerance for validation improvement\n",
    "\n",
    "    # class imbalance\n",
    "    class_weight=\"balanced\",\n",
    "\n",
    "    random_state=random_seed,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline appropriate for HGBC \n",
    "\n",
    "**Why use a `Pipeline` instead of encoding in the dataset first?**\n",
    "\n",
    "* **Avoid data leakage.** In each CV fold, the `OrdinalEncoder` is refit only on that fold’s training data, so the validation split never influences the encoder.\n",
    "* **Single, reusable object.** The pipeline bundles preprocessing + model, letting you call `fit`/`predict` on raw data anywhere (CV, Optuna, production) with identical behavior.\n",
    "* **Compatible with search tools.** `cross_validate`, `GridSearchCV`, and Optuna expect an estimator that can be cloned and refit; a pipeline meets that requirement automatically.\n",
    "\n",
    "Put simply, the pipeline gives you leak-free evaluation and portable, hassle-free tuning without extra code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",   # Allow unseen categories during transform\n",
    "    unknown_value=-1,                     # Code for unseen categories\n",
    "    encoded_missing_value=-2,             # Code for missing values (NaN)\n",
    "    dtype=np.int64                        # Needed for HistGradientBoostingClassifier\n",
    ")\n",
    "\n",
    "# Categorical features\n",
    "cat_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "# Numeric features (everything that isn’t object / category)\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [(\"cat\", enc, cat_cols),\n",
    "     (\"num\", \"passthrough\", num_cols)]\n",
    ")\n",
    "\n",
    "pipelined_model = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"gb\",   HGBC_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Baseline Cross-Validation with F1\n",
    "\n",
    "In this problem, you will run a baseline cross-validation evaluation of your `HistGradientBoostingClassifier` pipeline, using `HGBC_model` defined above. \n",
    "\n",
    "**Background:**\n",
    "\n",
    "* Since the Adult dataset is imbalanced (about 24% positives, 76% negatives), accuracy alone is not reliable.\n",
    "* We will use the **F1 score** as the evaluation metric, since it balances precision (avoiding false positives) and recall (avoiding false negatives) in a single measure. This is a fairer metric for imbalanced classification, where both types of error matter.\n",
    "* We will apply **5-fold stratified cross-validation** to make sure each fold has the same proportion of the classes as the original dataset.\n",
    "* Repeated cross-validation is optional and not required here, because the Adult dataset is large and `HistGradientBoostingClassifier` is robust to small sampling differences. \n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Set up a `StratifiedKFold` cross-validation object with 5 splits, shuffling enabled, and `random_state=random_seed`.\n",
    "2. Use `cross_val_score` to estimate the mean F1 score and its standard deviation across the folds.\n",
    "3. Print out the mean and standard deviation of the F1 score, rounded to 4 decimal places.\n",
    "4. Answer the graded question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basesline F1 Score: 0.7123 +/- 0.0035\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "#Set up the 5 fold stratified cross-validation\n",
    "skf = StratifiedKFold(\n",
    "    n_splits = 5,\n",
    "    shuffle= True,\n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "# Calculate F1 scores using cross-validation\n",
    "#The peplnined_model bundles preprocessing and HGBC model.\n",
    "#cv=skf ensure straified splits are used\n",
    "#scoring='f1' specified the evalusation metric\n",
    "f1_scores = cross_val_score(\n",
    "    pipelined_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=skf,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "# Calculate the mean and standard deviation of the F1 scores\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "# Print the results, formatted to 4 decical places\n",
    "print(f\"Basesline F1 Score: {mean_f1:.4f} +/- {std_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Graded Answer\n",
    "\n",
    "Set `a1` to the mean F1 score of the baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a1 = mean_f1                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = 0.7123\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a1 = {a1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Hyperparameter Optimization with Randomized Search for F1\n",
    "\n",
    "In this problem, you will tune your `pipelined_model` using `RandomizedSearchCV` to identify the best combination of tree structure and learning rate parameters that maximize the **F1 score**.\n",
    "\n",
    "**Background:**\n",
    "The F1 score is our main metric because it balances precision and recall on an imbalanced dataset. Optimizing hyperparameters for F1 ensures we manage both false positives and false negatives in a single measure.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Set up a randomized search over the following hyperparameter ranges, using appropriate random-number distributions:\n",
    "\n",
    "   * `learning_rate` (log-uniform between 1e-3 and 0.3)\n",
    "   * `max_leaf_nodes` (integer from 16 to 256)\n",
    "   * `max_depth` (integer from 2 to 10)\n",
    "   * `min_samples_leaf` (integer from 10 to 200)\n",
    "   * `l2_regularization` (uniform between 0.0 and 2.0)\n",
    "2. Use **5-fold stratified cross-validation**, with the same settings as in Problem 1.\n",
    "3. Set `n_iter` to at least 100 trials. More trials will generally yield better results, if your time and machine allow.\n",
    "4. After running the search, show a neatly formatted table of the top 5 results, using `display(...)` showing their mean F1 scores, standard deviation, and the chosen hyperparameter values.\n",
    "5. Answer the graded question.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Search completed in 00:01:21.\n",
      "\n",
      "Top-5 parameter sets by mean F1:\n",
      " mean_test_score  std_test_score  param_gb__learning_rate  param_gb__max_leaf_nodes  param_gb__max_depth  param_gb__min_samples_leaf  param_gb__l2_regularization\n",
      "        0.712122        0.003238                 0.255401                        27                    5                          48                     0.727259\n",
      "        0.712020        0.003146                 0.166921                       175                    6                          18                     0.186206\n",
      "        0.711805        0.003347                 0.243783                       131                    2                         169                     1.933310\n",
      "        0.711772        0.003205                 0.101566                       167                    2                          22                     1.618722\n",
      "        0.711707        0.002373                 0.218286                       143                    5                         169                     1.887783\n",
      "\n",
      "Best params: {'gb__l2_regularization': 0.727259204758588, 'gb__learning_rate': 0.2554006816661351, 'gb__max_depth': 5, 'gb__max_leaf_nodes': 27, 'gb__min_samples_leaf': 48}\n",
      "Best mean CV F1: 0.7121222889240192\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "# The 'gb__' prefix targets the 'gb' (HistGradientBosstingClassifier) setp in the pipeline.\n",
    "param_dist_rs = {\n",
    "    'gb__learning_rate': loguniform(1e-3, 0.3),\n",
    "    'gb__max_leaf_nodes': randint(16, 256),\n",
    "    'gb__max_depth': randint(2, 10),\n",
    "    'gb__min_samples_leaf': randint(10, 200),\n",
    "    'gb__l2_regularization': uniform(0.0, 2.0)\n",
    "}\n",
    "\n",
    "# Set up the same stratified K-fold cross-validator as before\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "# Set up RandomizedSearchCV to find the best F1 score\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipelined_model,      # pipeline object created earlier\n",
    "    param_distributions=param_dist_rs,\n",
    "    n_iter=100,\n",
    "    scoring=\"f1\",\n",
    "    cv=skf,\n",
    "    random_state=random_seed,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Running RandomizedSearchCV...\")\n",
    "# Start the Timer\n",
    "start_time_rs = time.time()\n",
    "\n",
    "# Fit the model to the training data to start the search.\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time_rs = time.time() - start_time_rs\n",
    "print(f\"Search completed in {format_hms(elapsed_time_rs)}.\")\n",
    "\n",
    "# Creaate a df with the results for easy viewing\n",
    "rs_results_df = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "# Define columns to display for clarity\n",
    "cols_to_show = [\n",
    "    'mean_test_score', 'std_test_score', 'param_gb__learning_rate',\n",
    "    'param_gb__max_leaf_nodes', 'param_gb__max_depth', 'param_gb__min_samples_leaf',\n",
    "    'param_gb__l2_regularization'\n",
    "]\n",
    "\n",
    "# Sort by the best mean test score and display the top 5 results\n",
    "top_5_rs_results = rs_results_df.sort_values(by='mean_test_score', ascending=False)[cols_to_show].head(5)\n",
    "\n",
    "print(\"\\nTop-5 parameter sets by mean F1:\")\n",
    "print(top_5_rs_results.to_string(index=False))\n",
    "\n",
    "print(\"\\nBest params:\", random_search.best_params_)\n",
    "print(\"Best mean CV F1:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Graded Answer\n",
    "\n",
    "Set `a2` to the mean F1 score of the best model found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a2 = random_search.best_score_                  # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = 0.7121\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a2 = {a2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Hyperparameter Optimization with Optuna for F1\n",
    "\n",
    "In this problem, you will explore **Optuna**, a powerful hyperparameter optimization framework, to identify the best combination of hyperparameters that maximize the F1 score of your `pipelined_model`.\n",
    "\n",
    "**Background:**\n",
    "Optuna uses a smarter sampling strategy than grid search or randomized search, allowing you to explore the hyperparameter space more efficiently. It also supports *pruning*, which can stop unpromising trials early to save time. This makes it a popular SOTA optimization tool.\n",
    "\n",
    "**Before you start** browse the [Optuna documentation](https://optuna.org) and view the [tutorial video](https://optuna.readthedocs.io/en/stable/tutorial/index.html). \n",
    "\n",
    "As before, we focus on the **F1 score** because it balances precision and recall, making it more robust on an imbalanced dataset.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Define an Optuna objective function to optimize F1 score, sampling the exact same hyperparameter ranges you did in Problem 2 and using the same CV settings.  \n",
    "3. Set up an Optuna study with a reasonable number of trials (e.g., 100–500 depending on runtime resources--on my machine Optuna runs about 10x faster than randomized search for the same number of trials, but YMMV).\n",
    "4. After running the optimization, `display` a clean table with the top 5 trials showing their F1 scores and corresponding hyperparameter settings.\n",
    "5. Answer the graded question. \n",
    "\n",
    "**Note:**  There are many resources on Optuna you can find on the web, but for this problem, you have my permission to let ChatGPT write the code for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-04 10:36:36,598] A new study created in memory with name: hgbc_f1_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Optuna Search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-04 10:36:39,175] Trial 0 finished with value: 0.6078567069936144 and parameters: {'learning_rate': 0.0010428980722324592, 'max_leaf_nodes': 53, 'max_depth': 3, 'min_samples_leaf': 187, 'l2_regularization': 1.007561045603161}. Best is trial 0 with value: 0.6078567069936144.\n",
      "[I 2025-07-04 10:36:45,177] Trial 1 finished with value: 0.6746599789077559 and parameters: {'learning_rate': 0.003180517208030726, 'max_leaf_nodes': 32, 'max_depth': 9, 'min_samples_leaf': 186, 'l2_regularization': 0.6855582223609633}. Best is trial 1 with value: 0.6746599789077559.\n",
      "[I 2025-07-04 10:36:49,323] Trial 2 finished with value: 0.7094330962991204 and parameters: {'learning_rate': 0.050283459753777925, 'max_leaf_nodes': 239, 'max_depth': 9, 'min_samples_leaf': 28, 'l2_regularization': 1.4700667195607977}. Best is trial 2 with value: 0.7094330962991204.\n",
      "[I 2025-07-04 10:36:51,576] Trial 3 finished with value: 0.7111048043143792 and parameters: {'learning_rate': 0.09378479915875548, 'max_leaf_nodes': 255, 'max_depth': 3, 'min_samples_leaf': 32, 'l2_regularization': 0.6006115286765481}. Best is trial 3 with value: 0.7111048043143792.\n",
      "[I 2025-07-04 10:36:57,630] Trial 4 finished with value: 0.6683711600561575 and parameters: {'learning_rate': 0.001629913436108672, 'max_leaf_nodes': 199, 'max_depth': 7, 'min_samples_leaf': 199, 'l2_regularization': 1.7523614493235204}. Best is trial 3 with value: 0.7111048043143792.\n",
      "[I 2025-07-04 10:36:59,625] Trial 5 finished with value: 0.704111500574055 and parameters: {'learning_rate': 0.05691304815567106, 'max_leaf_nodes': 130, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.9758385128323197}. Best is trial 3 with value: 0.7111048043143792.\n",
      "[I 2025-07-04 10:37:02,930] Trial 6 finished with value: 0.7106580905033324 and parameters: {'learning_rate': 0.04992399787555489, 'max_leaf_nodes': 159, 'max_depth': 5, 'min_samples_leaf': 147, 'l2_regularization': 1.208007123599686}. Best is trial 3 with value: 0.7111048043143792.\n",
      "[I 2025-07-04 10:37:08,803] Trial 7 finished with value: 0.707267345228866 and parameters: {'learning_rate': 0.019726615155510635, 'max_leaf_nodes': 139, 'max_depth': 9, 'min_samples_leaf': 164, 'l2_regularization': 1.076292668849733}. Best is trial 3 with value: 0.7111048043143792.\n",
      "[I 2025-07-04 10:37:15,208] Trial 8 finished with value: 0.6651722584616112 and parameters: {'learning_rate': 0.0012442545932907453, 'max_leaf_nodes': 108, 'max_depth': 6, 'min_samples_leaf': 13, 'l2_regularization': 1.7124925091695538}. Best is trial 3 with value: 0.7111048043143792.\n",
      "[I 2025-07-04 10:37:17,185] Trial 9 finished with value: 0.630253008389408 and parameters: {'learning_rate': 0.0037606503531374467, 'max_leaf_nodes': 113, 'max_depth': 2, 'min_samples_leaf': 152, 'l2_regularization': 0.815473622114971}. Best is trial 3 with value: 0.7111048043143792.\n",
      "[I 2025-07-04 10:37:18,232] Trial 10 finished with value: 0.7111538452391477 and parameters: {'learning_rate': 0.29174800614353125, 'max_leaf_nodes': 254, 'max_depth': 4, 'min_samples_leaf': 72, 'l2_regularization': 0.12711422794840344}. Best is trial 10 with value: 0.7111538452391477.\n",
      "[I 2025-07-04 10:37:19,487] Trial 11 finished with value: 0.7113005846503707 and parameters: {'learning_rate': 0.25175308744852076, 'max_leaf_nodes': 255, 'max_depth': 4, 'min_samples_leaf': 69, 'l2_regularization': 0.031677523240560446}. Best is trial 11 with value: 0.7113005846503707.\n",
      "[I 2025-07-04 10:37:20,536] Trial 12 finished with value: 0.7105797263476304 and parameters: {'learning_rate': 0.2816805752593752, 'max_leaf_nodes': 209, 'max_depth': 5, 'min_samples_leaf': 79, 'l2_regularization': 0.009056887040427064}. Best is trial 11 with value: 0.7113005846503707.\n",
      "[I 2025-07-04 10:37:21,729] Trial 13 finished with value: 0.7113696390622342 and parameters: {'learning_rate': 0.295264191769874, 'max_leaf_nodes': 207, 'max_depth': 4, 'min_samples_leaf': 79, 'l2_regularization': 0.0393266467638575}. Best is trial 13 with value: 0.7113696390622342.\n",
      "[I 2025-07-04 10:37:23,611] Trial 14 finished with value: 0.7099776940937621 and parameters: {'learning_rate': 0.13757510828524266, 'max_leaf_nodes': 199, 'max_depth': 7, 'min_samples_leaf': 99, 'l2_regularization': 0.37187882075613543}. Best is trial 13 with value: 0.7113696390622342.\n",
      "[I 2025-07-04 10:37:26,729] Trial 15 finished with value: 0.6969241679526764 and parameters: {'learning_rate': 0.015706239239321164, 'max_leaf_nodes': 217, 'max_depth': 4, 'min_samples_leaf': 60, 'l2_regularization': 0.32745519642642956}. Best is trial 13 with value: 0.7113696390622342.\n",
      "[I 2025-07-04 10:37:28,340] Trial 16 finished with value: 0.7108643803690091 and parameters: {'learning_rate': 0.16704157411216908, 'max_leaf_nodes': 166, 'max_depth': 5, 'min_samples_leaf': 108, 'l2_regularization': 0.31707539845576543}. Best is trial 13 with value: 0.7113696390622342.\n",
      "[I 2025-07-04 10:37:33,587] Trial 17 finished with value: 0.7068686689106402 and parameters: {'learning_rate': 0.02166683447230112, 'max_leaf_nodes': 177, 'max_depth': 7, 'min_samples_leaf': 113, 'l2_regularization': 0.1660272945458101}. Best is trial 13 with value: 0.7113696390622342.\n",
      "[I 2025-07-04 10:37:35,590] Trial 18 finished with value: 0.7117113147960751 and parameters: {'learning_rate': 0.11434474033958746, 'max_leaf_nodes': 228, 'max_depth': 4, 'min_samples_leaf': 58, 'l2_regularization': 0.5391824057406212}. Best is trial 18 with value: 0.7117113147960751.\n",
      "[I 2025-07-04 10:37:37,809] Trial 19 finished with value: 0.7115907997380874 and parameters: {'learning_rate': 0.09103833029510273, 'max_leaf_nodes': 79, 'max_depth': 3, 'min_samples_leaf': 50, 'l2_regularization': 0.5400521997266992}. Best is trial 18 with value: 0.7117113147960751.\n",
      "[I 2025-07-04 10:37:40,290] Trial 20 finished with value: 0.6824655840326584 and parameters: {'learning_rate': 0.011716058764733604, 'max_leaf_nodes': 79, 'max_depth': 3, 'min_samples_leaf': 52, 'l2_regularization': 0.5282714366912061}. Best is trial 18 with value: 0.7117113147960751.\n",
      "[I 2025-07-04 10:37:42,494] Trial 21 finished with value: 0.7112440429076469 and parameters: {'learning_rate': 0.09491072747798147, 'max_leaf_nodes': 81, 'max_depth': 3, 'min_samples_leaf': 41, 'l2_regularization': 0.7867797993950769}. Best is trial 18 with value: 0.7117113147960751.\n",
      "[I 2025-07-04 10:37:44,407] Trial 22 finished with value: 0.7110168778532526 and parameters: {'learning_rate': 0.15562719594793223, 'max_leaf_nodes': 219, 'max_depth': 2, 'min_samples_leaf': 88, 'l2_regularization': 0.41863238902319333}. Best is trial 18 with value: 0.7117113147960751.\n",
      "[I 2025-07-04 10:37:46,931] Trial 23 finished with value: 0.711868668114338 and parameters: {'learning_rate': 0.09686276468829517, 'max_leaf_nodes': 180, 'max_depth': 4, 'min_samples_leaf': 124, 'l2_regularization': 0.8625850066720213}. Best is trial 23 with value: 0.711868668114338.\n",
      "[I 2025-07-04 10:37:49,636] Trial 24 finished with value: 0.7102924129623045 and parameters: {'learning_rate': 0.08236245165254429, 'max_leaf_nodes': 174, 'max_depth': 6, 'min_samples_leaf': 133, 'l2_regularization': 0.7789941668065393}. Best is trial 23 with value: 0.711868668114338.\n",
      "[I 2025-07-04 10:37:53,401] Trial 25 finished with value: 0.7069232645991086 and parameters: {'learning_rate': 0.029699237314040623, 'max_leaf_nodes': 143, 'max_depth': 5, 'min_samples_leaf': 122, 'l2_regularization': 1.2842726767270924}. Best is trial 23 with value: 0.711868668114338.\n",
      "[I 2025-07-04 10:37:56,050] Trial 26 finished with value: 0.7004414158495688 and parameters: {'learning_rate': 0.031691235013111184, 'max_leaf_nodes': 81, 'max_depth': 3, 'min_samples_leaf': 95, 'l2_regularization': 0.9227343493160077}. Best is trial 23 with value: 0.711868668114338.\n",
      "[I 2025-07-04 10:38:10,341] Trial 27 finished with value: 0.6976185506847223 and parameters: {'learning_rate': 0.00744837541641465, 'max_leaf_nodes': 189, 'max_depth': 10, 'min_samples_leaf': 54, 'l2_regularization': 0.5085957453689}. Best is trial 23 with value: 0.711868668114338.\n",
      "[I 2025-07-04 10:38:13,239] Trial 28 finished with value: 0.7108763895704027 and parameters: {'learning_rate': 0.0703131766990474, 'max_leaf_nodes': 228, 'max_depth': 4, 'min_samples_leaf': 129, 'l2_regularization': 0.6591281278529547}. Best is trial 23 with value: 0.711868668114338.\n",
      "[I 2025-07-04 10:38:15,265] Trial 29 finished with value: 0.7111314217694645 and parameters: {'learning_rate': 0.11996785903960647, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 52, 'l2_regularization': 1.020356306823395}. Best is trial 23 with value: 0.711868668114338.\n",
      "[I 2025-07-04 10:38:17,759] Trial 30 finished with value: 0.7040279478529843 and parameters: {'learning_rate': 0.035426234789116696, 'max_leaf_nodes': 54, 'max_depth': 3, 'min_samples_leaf': 39, 'l2_regularization': 0.8873480986477733}. Best is trial 23 with value: 0.711868668114338.\n",
      "[I 2025-07-04 10:38:19,144] Trial 31 finished with value: 0.7105262536362951 and parameters: {'learning_rate': 0.19379023847960916, 'max_leaf_nodes': 235, 'max_depth': 4, 'min_samples_leaf': 81, 'l2_regularization': 0.2113100488207935}. Best is trial 23 with value: 0.711868668114338.\n",
      "[I 2025-07-04 10:38:20,603] Trial 32 finished with value: 0.7119915050170105 and parameters: {'learning_rate': 0.20657201162290165, 'max_leaf_nodes': 188, 'max_depth': 4, 'min_samples_leaf': 65, 'l2_regularization': 0.4822325523231082}. Best is trial 32 with value: 0.7119915050170105.\n",
      "[I 2025-07-04 10:38:22,159] Trial 33 finished with value: 0.7104174479478103 and parameters: {'learning_rate': 0.19082942000289846, 'max_leaf_nodes': 155, 'max_depth': 6, 'min_samples_leaf': 68, 'l2_regularization': 0.503013076868312}. Best is trial 32 with value: 0.7119915050170105.\n",
      "[I 2025-07-04 10:38:24,209] Trial 34 finished with value: 0.7110294795920179 and parameters: {'learning_rate': 0.11224451487904875, 'max_leaf_nodes': 185, 'max_depth': 5, 'min_samples_leaf': 38, 'l2_regularization': 0.6534118923657709}. Best is trial 32 with value: 0.7119915050170105.\n",
      "[I 2025-07-04 10:38:26,687] Trial 35 finished with value: 0.7101115816299588 and parameters: {'learning_rate': 0.060316065968244174, 'max_leaf_nodes': 49, 'max_depth': 3, 'min_samples_leaf': 25, 'l2_regularization': 0.7269693475827999}. Best is trial 32 with value: 0.7119915050170105.\n",
      "[I 2025-07-04 10:38:29,094] Trial 36 finished with value: 0.7104015977096207 and parameters: {'learning_rate': 0.0932216720709308, 'max_leaf_nodes': 116, 'max_depth': 3, 'min_samples_leaf': 171, 'l2_regularization': 0.5613095234825488}. Best is trial 32 with value: 0.7119915050170105.\n",
      "[I 2025-07-04 10:38:32,058] Trial 37 finished with value: 0.7086511796451284 and parameters: {'learning_rate': 0.046829877230075395, 'max_leaf_nodes': 193, 'max_depth': 4, 'min_samples_leaf': 91, 'l2_regularization': 1.134822355234432}. Best is trial 32 with value: 0.7119915050170105.\n",
      "[I 2025-07-04 10:38:33,604] Trial 38 finished with value: 0.7120627159590609 and parameters: {'learning_rate': 0.20680043769763856, 'max_leaf_nodes': 97, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.43686302096256124}. Best is trial 38 with value: 0.7120627159590609.\n",
      "[I 2025-07-04 10:38:35,545] Trial 39 finished with value: 0.7126503585402869 and parameters: {'learning_rate': 0.20031062514103437, 'max_leaf_nodes': 99, 'max_depth': 2, 'min_samples_leaf': 143, 'l2_regularization': 0.25155130081876836}. Best is trial 39 with value: 0.7126503585402869.\n",
      "[I 2025-07-04 10:38:37,353] Trial 40 finished with value: 0.7111957361665431 and parameters: {'learning_rate': 0.19951188043824852, 'max_leaf_nodes': 99, 'max_depth': 2, 'min_samples_leaf': 143, 'l2_regularization': 0.2548417757087939}. Best is trial 39 with value: 0.7126503585402869.\n",
      "[I 2025-07-04 10:38:39,374] Trial 41 finished with value: 0.7132870344531157 and parameters: {'learning_rate': 0.13894538001031584, 'max_leaf_nodes': 90, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.4404470218869748}. Best is trial 41 with value: 0.7132870344531157.\n",
      "[I 2025-07-04 10:38:41,132] Trial 42 finished with value: 0.712785446632337 and parameters: {'learning_rate': 0.22567534265741288, 'max_leaf_nodes': 99, 'max_depth': 2, 'min_samples_leaf': 11, 'l2_regularization': 0.41697090389547764}. Best is trial 41 with value: 0.7132870344531157.\n",
      "[I 2025-07-04 10:38:42,803] Trial 43 finished with value: 0.7121676989502438 and parameters: {'learning_rate': 0.22495276607239326, 'max_leaf_nodes': 96, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.42627727691047035}. Best is trial 41 with value: 0.7132870344531157.\n",
      "[I 2025-07-04 10:38:44,382] Trial 44 finished with value: 0.7115494983019637 and parameters: {'learning_rate': 0.22193644164668258, 'max_leaf_nodes': 97, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.26172583294604684}. Best is trial 41 with value: 0.7132870344531157.\n",
      "[I 2025-07-04 10:38:46,337] Trial 45 finished with value: 0.7133721657796833 and parameters: {'learning_rate': 0.14723123122514245, 'max_leaf_nodes': 61, 'max_depth': 2, 'min_samples_leaf': 12, 'l2_regularization': 0.39811960418460207}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:38:48,226] Trial 46 finished with value: 0.7125500571182176 and parameters: {'learning_rate': 0.14686877694895653, 'max_leaf_nodes': 64, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.09192812967453798}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:38:50,242] Trial 47 finished with value: 0.7115870511084297 and parameters: {'learning_rate': 0.13733241285503114, 'max_leaf_nodes': 60, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 0.12600030340038157}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:38:52,320] Trial 48 finished with value: 0.6223136860650291 and parameters: {'learning_rate': 0.003357436630580642, 'max_leaf_nodes': 42, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.14309208809201351}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:38:54,023] Trial 49 finished with value: 0.709079319152878 and parameters: {'learning_rate': 0.1539906950753127, 'max_leaf_nodes': 70, 'max_depth': 8, 'min_samples_leaf': 186, 'l2_regularization': 0.07911184935940219}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:38:56,113] Trial 50 finished with value: 0.70590289893542 and parameters: {'learning_rate': 0.06679664173805955, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.3216295260309594}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:38:57,652] Trial 51 finished with value: 0.7121981433647494 and parameters: {'learning_rate': 0.2545780976217079, 'max_leaf_nodes': 66, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.41611239311253906}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:38:59,464] Trial 52 finished with value: 0.7129584191536741 and parameters: {'learning_rate': 0.1349991178399183, 'max_leaf_nodes': 67, 'max_depth': 3, 'min_samples_leaf': 21, 'l2_regularization': 0.22608219450394845}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:01,396] Trial 53 finished with value: 0.7128817666456327 and parameters: {'learning_rate': 0.13183508170873273, 'max_leaf_nodes': 34, 'max_depth': 3, 'min_samples_leaf': 34, 'l2_regularization': 0.27208713007814467}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:03,869] Trial 54 finished with value: 0.7077972825723854 and parameters: {'learning_rate': 0.04875398483881877, 'max_leaf_nodes': 31, 'max_depth': 3, 'min_samples_leaf': 33, 'l2_regularization': 0.213868632497261}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:06,412] Trial 55 finished with value: 0.6262109129044424 and parameters: {'learning_rate': 0.001947630275456101, 'max_leaf_nodes': 38, 'max_depth': 3, 'min_samples_leaf': 43, 'l2_regularization': 0.31616765090971033}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:07,709] Trial 56 finished with value: 0.7117596786620705 and parameters: {'learning_rate': 0.29351776908047195, 'max_leaf_nodes': 107, 'max_depth': 3, 'min_samples_leaf': 32, 'l2_regularization': 1.6215411512389275}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:10,060] Trial 57 finished with value: 0.7114090974381041 and parameters: {'learning_rate': 0.07752822237967517, 'max_leaf_nodes': 89, 'max_depth': 3, 'min_samples_leaf': 21, 'l2_regularization': 0.36492816546393125}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:12,064] Trial 58 finished with value: 0.7102222044394308 and parameters: {'learning_rate': 0.1305347660354641, 'max_leaf_nodes': 18, 'max_depth': 2, 'min_samples_leaf': 162, 'l2_regularization': 0.5995379374194512}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:14,074] Trial 59 finished with value: 0.7097225434749829 and parameters: {'learning_rate': 0.10514976133080384, 'max_leaf_nodes': 72, 'max_depth': 2, 'min_samples_leaf': 47, 'l2_regularization': 0.21581476466512112}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:15,792] Trial 60 finished with value: 0.7123476619992165 and parameters: {'learning_rate': 0.16889960166389528, 'max_leaf_nodes': 54, 'max_depth': 3, 'min_samples_leaf': 29, 'l2_regularization': 1.3417735635392156}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:17,681] Trial 61 finished with value: 0.7129818242439906 and parameters: {'learning_rate': 0.14899574017595427, 'max_leaf_nodes': 62, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.059967297462912184}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:19,548] Trial 62 finished with value: 0.7126280340878033 and parameters: {'learning_rate': 0.1666616454413689, 'max_leaf_nodes': 46, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.2878177986842311}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:21,275] Trial 63 finished with value: 0.7130209865433701 and parameters: {'learning_rate': 0.24332618514268003, 'max_leaf_nodes': 28, 'max_depth': 2, 'min_samples_leaf': 35, 'l2_regularization': 0.015359661278743941}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:23,907] Trial 64 finished with value: 0.6692019677177092 and parameters: {'learning_rate': 0.005938039358253928, 'max_leaf_nodes': 33, 'max_depth': 3, 'min_samples_leaf': 35, 'l2_regularization': 0.009640269670112521}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:25,364] Trial 65 finished with value: 0.7110875607878435 and parameters: {'learning_rate': 0.26345311656412584, 'max_leaf_nodes': 26, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 0.17475804573281933}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:27,712] Trial 66 finished with value: 0.7118744735002196 and parameters: {'learning_rate': 0.11426410101267591, 'max_leaf_nodes': 59, 'max_depth': 3, 'min_samples_leaf': 45, 'l2_regularization': 0.06916330603827134}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:29,789] Trial 67 finished with value: 0.7118460521219794 and parameters: {'learning_rate': 0.12819381778056302, 'max_leaf_nodes': 74, 'max_depth': 2, 'min_samples_leaf': 11, 'l2_regularization': 0.004129684361571724}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:31,879] Trial 68 finished with value: 0.7122699330546904 and parameters: {'learning_rate': 0.16992656055763714, 'max_leaf_nodes': 86, 'max_depth': 3, 'min_samples_leaf': 17, 'l2_regularization': 0.35967048244490396}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:33,955] Trial 69 finished with value: 0.7082308535417118 and parameters: {'learning_rate': 0.07794543552439004, 'max_leaf_nodes': 40, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 0.16549806472833378}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:35,206] Trial 70 finished with value: 0.7104498577929828 and parameters: {'learning_rate': 0.2569078139694589, 'max_leaf_nodes': 26, 'max_depth': 3, 'min_samples_leaf': 37, 'l2_regularization': 0.11087854333968857}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:36,930] Trial 71 finished with value: 0.7120037098774603 and parameters: {'learning_rate': 0.22960605995297576, 'max_leaf_nodes': 88, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.23933419400547096}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:38,667] Trial 72 finished with value: 0.7119914539404283 and parameters: {'learning_rate': 0.1760179448958042, 'max_leaf_nodes': 125, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.462345713723519}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:40,827] Trial 73 finished with value: 0.7107958080376042 and parameters: {'learning_rate': 0.14452602678626605, 'max_leaf_nodes': 48, 'max_depth': 2, 'min_samples_leaf': 176, 'l2_regularization': 0.28759015867765997}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:42,872] Trial 74 finished with value: 0.7086523198750697 and parameters: {'learning_rate': 0.10449701808524521, 'max_leaf_nodes': 103, 'max_depth': 2, 'min_samples_leaf': 117, 'l2_regularization': 0.05858640150528574}. Best is trial 45 with value: 0.7133721657796833.\n",
      "[I 2025-07-04 10:39:45,386] Trial 75 finished with value: 0.7142092903514289 and parameters: {'learning_rate': 0.08732936744092441, 'max_leaf_nodes': 115, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 0.3911899763454227}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:39:47,626] Trial 76 finished with value: 0.7127717171760136 and parameters: {'learning_rate': 0.08364551870689756, 'max_leaf_nodes': 133, 'max_depth': 4, 'min_samples_leaf': 10, 'l2_regularization': 0.37213322712673935}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:39:50,063] Trial 77 finished with value: 0.7100487643708299 and parameters: {'learning_rate': 0.05922333534615817, 'max_leaf_nodes': 113, 'max_depth': 3, 'min_samples_leaf': 26, 'l2_regularization': 0.5953674395256937}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:39:52,422] Trial 78 finished with value: 0.7116857029120075 and parameters: {'learning_rate': 0.11730893001568925, 'max_leaf_nodes': 119, 'max_depth': 10, 'min_samples_leaf': 16, 'l2_regularization': 0.695681656681423}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:39:54,080] Trial 79 finished with value: 0.7102743337865562 and parameters: {'learning_rate': 0.1374635755252844, 'max_leaf_nodes': 78, 'max_depth': 4, 'min_samples_leaf': 57, 'l2_regularization': 0.14518306768545883}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:39:58,244] Trial 80 finished with value: 0.7109654479326338 and parameters: {'learning_rate': 0.04053983244077291, 'max_leaf_nodes': 60, 'max_depth': 8, 'min_samples_leaf': 34, 'l2_regularization': 0.3710055428879788}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:00,464] Trial 81 finished with value: 0.7131026077344409 and parameters: {'learning_rate': 0.0928378754653768, 'max_leaf_nodes': 138, 'max_depth': 3, 'min_samples_leaf': 11, 'l2_regularization': 1.9972453972971473}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:02,768] Trial 82 finished with value: 0.7116549336304939 and parameters: {'learning_rate': 0.09363650196167188, 'max_leaf_nodes': 145, 'max_depth': 3, 'min_samples_leaf': 22, 'l2_regularization': 1.8985270107193295}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:04,080] Trial 83 finished with value: 0.7111810523090478 and parameters: {'learning_rate': 0.22631725241381823, 'max_leaf_nodes': 158, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.477192975708394}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:05,664] Trial 84 finished with value: 0.711744906052122 and parameters: {'learning_rate': 0.17941512579237281, 'max_leaf_nodes': 141, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 1.8781652314214512}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:07,623] Trial 85 finished with value: 0.7057787968779033 and parameters: {'learning_rate': 0.06572220240319077, 'max_leaf_nodes': 149, 'max_depth': 2, 'min_samples_leaf': 29, 'l2_regularization': 0.18374614344139295}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:09,937] Trial 86 finished with value: 0.6822025085879652 and parameters: {'learning_rate': 0.011994341286813402, 'max_leaf_nodes': 92, 'max_depth': 3, 'min_samples_leaf': 40, 'l2_regularization': 0.45980324185899996}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:14,141] Trial 87 finished with value: 0.7103904591342488 and parameters: {'learning_rate': 0.02455416278663469, 'max_leaf_nodes': 84, 'max_depth': 5, 'min_samples_leaf': 20, 'l2_regularization': 0.4112951794919665}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:15,864] Trial 88 finished with value: 0.7119298271097809 and parameters: {'learning_rate': 0.12656354694301766, 'max_leaf_nodes': 108, 'max_depth': 4, 'min_samples_leaf': 14, 'l2_regularization': 0.5217035168214141}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:17,809] Trial 89 finished with value: 0.7134154370296594 and parameters: {'learning_rate': 0.15464951867670662, 'max_leaf_nodes': 135, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.5772592746923526}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:19,739] Trial 90 finished with value: 0.709129485883305 and parameters: {'learning_rate': 0.08678296924334535, 'max_leaf_nodes': 165, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.6335507807447878}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:21,514] Trial 91 finished with value: 0.7130768573153982 and parameters: {'learning_rate': 0.15349918529817216, 'max_leaf_nodes': 128, 'max_depth': 2, 'min_samples_leaf': 32, 'l2_regularization': 1.9889904970174748}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:23,364] Trial 92 finished with value: 0.7110700586037859 and parameters: {'learning_rate': 0.15228301852434967, 'max_leaf_nodes': 135, 'max_depth': 2, 'min_samples_leaf': 49, 'l2_regularization': 1.999488993314029}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:25,630] Trial 93 finished with value: 0.7114600321544371 and parameters: {'learning_rate': 0.1049153990314974, 'max_leaf_nodes': 124, 'max_depth': 3, 'min_samples_leaf': 32, 'l2_regularization': 1.8961565494497667}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:27,174] Trial 94 finished with value: 0.71133666013822 and parameters: {'learning_rate': 0.19806196459817862, 'max_leaf_nodes': 130, 'max_depth': 2, 'min_samples_leaf': 42, 'l2_regularization': 1.8356837786838964}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:29,123] Trial 95 finished with value: 0.7061850222395223 and parameters: {'learning_rate': 0.07162536628662296, 'max_leaf_nodes': 35, 'max_depth': 2, 'min_samples_leaf': 36, 'l2_regularization': 1.7763833846906372}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:31,271] Trial 96 finished with value: 0.7119084371183881 and parameters: {'learning_rate': 0.1271765083003402, 'max_leaf_nodes': 150, 'max_depth': 3, 'min_samples_leaf': 27, 'l2_regularization': 1.9711659438124285}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:33,059] Trial 97 finished with value: 0.7121277742247007 and parameters: {'learning_rate': 0.15440941128325153, 'max_leaf_nodes': 66, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.6778988599394271}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:35,134] Trial 98 finished with value: 0.7128932254433515 and parameters: {'learning_rate': 0.10373282536447356, 'max_leaf_nodes': 52, 'max_depth': 3, 'min_samples_leaf': 15, 'l2_regularization': 1.5082656981389808}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:37,169] Trial 99 finished with value: 0.7110144921763007 and parameters: {'learning_rate': 0.09431577613383943, 'max_leaf_nodes': 138, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.4729364342214564}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:39,630] Trial 100 finished with value: 0.7109882314580426 and parameters: {'learning_rate': 0.10808850028510175, 'max_leaf_nodes': 52, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 1.1545710770653086}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:42,100] Trial 101 finished with value: 0.7087329504834127 and parameters: {'learning_rate': 0.054461395528389786, 'max_leaf_nodes': 44, 'max_depth': 3, 'min_samples_leaf': 30, 'l2_regularization': 1.5690298258821367}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:43,708] Trial 102 finished with value: 0.7118531992307957 and parameters: {'learning_rate': 0.14410675517840663, 'max_leaf_nodes': 57, 'max_depth': 3, 'min_samples_leaf': 14, 'l2_regularization': 1.2992330404194905}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:44,965] Trial 103 finished with value: 0.7105242982675737 and parameters: {'learning_rate': 0.1880225401404055, 'max_leaf_nodes': 24, 'max_depth': 4, 'min_samples_leaf': 21, 'l2_regularization': 1.7736017463026255}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:46,849] Trial 104 finished with value: 0.7121897492636524 and parameters: {'learning_rate': 0.11977791148033336, 'max_leaf_nodes': 75, 'max_depth': 3, 'min_samples_leaf': 18, 'l2_regularization': 1.9327628180978287}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:48,784] Trial 105 finished with value: 0.71150147915404 and parameters: {'learning_rate': 0.16671737234893658, 'max_leaf_nodes': 129, 'max_depth': 2, 'min_samples_leaf': 37, 'l2_regularization': 0.9570596521703231}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:51,225] Trial 106 finished with value: 0.7095820891937505 and parameters: {'learning_rate': 0.09944506771832715, 'max_leaf_nodes': 51, 'max_depth': 7, 'min_samples_leaf': 102, 'l2_regularization': 1.5248753180457373}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:52,720] Trial 107 finished with value: 0.7122656345515679 and parameters: {'learning_rate': 0.28302901834688754, 'max_leaf_nodes': 31, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.9424326580411775}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:54,893] Trial 108 finished with value: 0.7028516003104623 and parameters: {'learning_rate': 0.07432951717153549, 'max_leaf_nodes': 70, 'max_depth': 2, 'min_samples_leaf': 197, 'l2_regularization': 1.394400200678466}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:56,024] Trial 109 finished with value: 0.7101157862983162 and parameters: {'learning_rate': 0.24048749548479598, 'max_leaf_nodes': 117, 'max_depth': 4, 'min_samples_leaf': 32, 'l2_regularization': 1.0528252899221617}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:57,869] Trial 110 finished with value: 0.7127455245985448 and parameters: {'learning_rate': 0.13683543120265193, 'max_leaf_nodes': 64, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.04211238709343701}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:40:59,471] Trial 111 finished with value: 0.7123136720271785 and parameters: {'learning_rate': 0.21051306668274886, 'max_leaf_nodes': 105, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.8186583924890003}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:00,838] Trial 112 finished with value: 0.7115551961097006 and parameters: {'learning_rate': 0.18094858404930889, 'max_leaf_nodes': 120, 'max_depth': 6, 'min_samples_leaf': 19, 'l2_regularization': 1.2344006968411554}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:02,822] Trial 113 finished with value: 0.7124174005902061 and parameters: {'learning_rate': 0.15683671941235428, 'max_leaf_nodes': 111, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.2956957758560569}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:04,004] Trial 114 finished with value: 0.7117795508086926 and parameters: {'learning_rate': 0.2607786363154327, 'max_leaf_nodes': 38, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 0.10434571694546635}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:06,009] Trial 115 finished with value: 0.7116344915048474 and parameters: {'learning_rate': 0.1227341884951338, 'max_leaf_nodes': 17, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 0.33504240132315605}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:08,275] Trial 116 finished with value: 0.7121680116590079 and parameters: {'learning_rate': 0.08702861696771018, 'max_leaf_nodes': 102, 'max_depth': 3, 'min_samples_leaf': 22, 'l2_regularization': 0.20546690882400706}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:09,908] Trial 117 finished with value: 0.7128812516662609 and parameters: {'learning_rate': 0.22509243378657295, 'max_leaf_nodes': 91, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.4163869187432352}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:11,949] Trial 118 finished with value: 0.6069567226690468 and parameters: {'learning_rate': 0.001121492739540505, 'max_leaf_nodes': 46, 'max_depth': 2, 'min_samples_leaf': 44, 'l2_regularization': 1.3720817353955486}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:13,406] Trial 119 finished with value: 0.7129372814444078 and parameters: {'learning_rate': 0.2057537780360978, 'max_leaf_nodes': 82, 'max_depth': 3, 'min_samples_leaf': 14, 'l2_regularization': 1.4316670196360453}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:14,974] Trial 120 finished with value: 0.7102926691201394 and parameters: {'learning_rate': 0.1829412970262827, 'max_leaf_nodes': 56, 'max_depth': 3, 'min_samples_leaf': 25, 'l2_regularization': 1.5629003092721185}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:16,210] Trial 121 finished with value: 0.7130496938079462 and parameters: {'learning_rate': 0.29684994283500316, 'max_leaf_nodes': 81, 'max_depth': 3, 'min_samples_leaf': 14, 'l2_regularization': 1.3819394302938608}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:17,393] Trial 122 finished with value: 0.7127187716166168 and parameters: {'learning_rate': 0.2877247792959372, 'max_leaf_nodes': 80, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 1.535364321977253}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:18,718] Trial 123 finished with value: 0.7117403554528731 and parameters: {'learning_rate': 0.24821454226028397, 'max_leaf_nodes': 67, 'max_depth': 3, 'min_samples_leaf': 22, 'l2_regularization': 1.320436722562494}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:20,142] Trial 124 finished with value: 0.7117648736942527 and parameters: {'learning_rate': 0.20848377058606, 'max_leaf_nodes': 84, 'max_depth': 3, 'min_samples_leaf': 19, 'l2_regularization': 1.718377738798083}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:21,782] Trial 125 finished with value: 0.712340846577397 and parameters: {'learning_rate': 0.15964931912416103, 'max_leaf_nodes': 74, 'max_depth': 4, 'min_samples_leaf': 30, 'l2_regularization': 1.4239855554731533}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:23,855] Trial 126 finished with value: 0.7115814669884725 and parameters: {'learning_rate': 0.11491449363018715, 'max_leaf_nodes': 94, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 1.5901341853763733}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:25,715] Trial 127 finished with value: 0.7114589584685095 and parameters: {'learning_rate': 0.14237395836236824, 'max_leaf_nodes': 62, 'max_depth': 3, 'min_samples_leaf': 35, 'l2_regularization': 1.4555286517431922}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:26,982] Trial 128 finished with value: 0.710895295665212 and parameters: {'learning_rate': 0.18957070600759493, 'max_leaf_nodes': 23, 'max_depth': 9, 'min_samples_leaf': 18, 'l2_regularization': 1.6818705838451555}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:29,373] Trial 129 finished with value: 0.7111101036920575 and parameters: {'learning_rate': 0.10551520685049681, 'max_leaf_nodes': 145, 'max_depth': 3, 'min_samples_leaf': 27, 'l2_regularization': 1.358891842155156}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:31,061] Trial 130 finished with value: 0.7127010489128084 and parameters: {'learning_rate': 0.13450623078819404, 'max_leaf_nodes': 41, 'max_depth': 4, 'min_samples_leaf': 10, 'l2_regularization': 1.1381305493920193}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:32,470] Trial 131 finished with value: 0.7117602387829453 and parameters: {'learning_rate': 0.2952274517183857, 'max_leaf_nodes': 91, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.5068584590319856}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:34,152] Trial 132 finished with value: 0.7122985956524353 and parameters: {'learning_rate': 0.22694786233858305, 'max_leaf_nodes': 78, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 1.2602722352199167}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:35,738] Trial 133 finished with value: 0.712680386985929 and parameters: {'learning_rate': 0.2110645656246364, 'max_leaf_nodes': 70, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.4382550333709694}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:37,682] Trial 134 finished with value: 0.7108960867856651 and parameters: {'learning_rate': 0.16545723514977828, 'max_leaf_nodes': 85, 'max_depth': 2, 'min_samples_leaf': 76, 'l2_regularization': 1.4259492065183916}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:39,294] Trial 135 finished with value: 0.7132941055222917 and parameters: {'learning_rate': 0.25125019130389076, 'max_leaf_nodes': 128, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 1.1912878669604203}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:40,474] Trial 136 finished with value: 0.7094983781545869 and parameters: {'learning_rate': 0.24909884213048025, 'max_leaf_nodes': 127, 'max_depth': 8, 'min_samples_leaf': 20, 'l2_regularization': 0.03362406500486719}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:42,403] Trial 137 finished with value: 0.7125296652289266 and parameters: {'learning_rate': 0.14419178332917149, 'max_leaf_nodes': 133, 'max_depth': 2, 'min_samples_leaf': 40, 'l2_regularization': 0.2612766137186079}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:43,949] Trial 138 finished with value: 0.7109990067604265 and parameters: {'learning_rate': 0.18855717206674505, 'max_leaf_nodes': 137, 'max_depth': 3, 'min_samples_leaf': 31, 'l2_regularization': 1.2084704899268643}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:46,466] Trial 139 finished with value: 0.6699710921691513 and parameters: {'learning_rate': 0.006389111118210001, 'max_leaf_nodes': 121, 'max_depth': 3, 'min_samples_leaf': 26, 'l2_regularization': 1.6301494373278798}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:48,293] Trial 140 finished with value: 0.711775260368328 and parameters: {'learning_rate': 0.11854945195511267, 'max_leaf_nodes': 142, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.0991426175889807}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:49,956] Trial 141 finished with value: 0.7123729975835082 and parameters: {'learning_rate': 0.26608491887670216, 'max_leaf_nodes': 152, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.3755207469759232}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:51,738] Trial 142 finished with value: 0.7127118377435775 and parameters: {'learning_rate': 0.2257512052302687, 'max_leaf_nodes': 114, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.2796556390886964}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:53,761] Trial 143 finished with value: 0.7135459945618141 and parameters: {'learning_rate': 0.16903779605965336, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.0001361141471177274}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:55,612] Trial 144 finished with value: 0.7128725109927483 and parameters: {'learning_rate': 0.164043815480617, 'max_leaf_nodes': 31, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.09989230038050767}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:41:58,120] Trial 145 finished with value: 0.7107731467408448 and parameters: {'learning_rate': 0.09890083771443313, 'max_leaf_nodes': 35, 'max_depth': 3, 'min_samples_leaf': 63, 'l2_regularization': 0.05812621769203635}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:00,157] Trial 146 finished with value: 0.7133928324135721 and parameters: {'learning_rate': 0.1474647183547123, 'max_leaf_nodes': 54, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.002506833195864866}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:02,040] Trial 147 finished with value: 0.7129073246529146 and parameters: {'learning_rate': 0.19726490807115998, 'max_leaf_nodes': 56, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.13549423202267952}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:04,163] Trial 148 finished with value: 0.6204733822988683 and parameters: {'learning_rate': 0.002292884091462308, 'max_leaf_nodes': 59, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 0.006280377998762545}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:05,995] Trial 149 finished with value: 0.7125821871690897 and parameters: {'learning_rate': 0.19188305236881495, 'max_leaf_nodes': 67, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.13820055546968232}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:07,860] Trial 150 finished with value: 0.7121558913430255 and parameters: {'learning_rate': 0.1748552444497018, 'max_leaf_nodes': 132, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.07759414404758616}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:09,912] Trial 151 finished with value: 0.713408287359749 and parameters: {'learning_rate': 0.15071232996416076, 'max_leaf_nodes': 50, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.013204406116956483}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:12,102] Trial 152 finished with value: 0.7123969633798873 and parameters: {'learning_rate': 0.1472365484176507, 'max_leaf_nodes': 49, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.02345609683175707}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:13,974] Trial 153 finished with value: 0.7127669991553132 and parameters: {'learning_rate': 0.2049935433186234, 'max_leaf_nodes': 55, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.071040786149824}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:15,919] Trial 154 finished with value: 0.7124958438942003 and parameters: {'learning_rate': 0.1555149247129313, 'max_leaf_nodes': 62, 'max_depth': 2, 'min_samples_leaf': 32, 'l2_regularization': 0.13400681202768006}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:17,948] Trial 155 finished with value: 0.7129976767626026 and parameters: {'learning_rate': 0.1308759149506174, 'max_leaf_nodes': 74, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.17571009714598274}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:19,810] Trial 156 finished with value: 0.710614050075759 and parameters: {'learning_rate': 0.12767092837081429, 'max_leaf_nodes': 76, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.17771191647932205}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:21,789] Trial 157 finished with value: 0.7114371365964922 and parameters: {'learning_rate': 0.1312724501441871, 'max_leaf_nodes': 73, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 0.0009794683295072694}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:23,581] Trial 158 finished with value: 0.7135450699619948 and parameters: {'learning_rate': 0.15681265294590596, 'max_leaf_nodes': 126, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.04590713709070132}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:25,563] Trial 159 finished with value: 0.7118209223089327 and parameters: {'learning_rate': 0.11467159969730377, 'max_leaf_nodes': 127, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.040535601421207844}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:27,174] Trial 160 finished with value: 0.711456780358214 and parameters: {'learning_rate': 0.17131019807235348, 'max_leaf_nodes': 140, 'max_depth': 2, 'min_samples_leaf': 35, 'l2_regularization': 0.047142236365095576}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:29,090] Trial 161 finished with value: 0.7129094720083877 and parameters: {'learning_rate': 0.15108074167372934, 'max_leaf_nodes': 136, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.09411263049078412}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:30,806] Trial 162 finished with value: 0.7115556823266289 and parameters: {'learning_rate': 0.24112009110556473, 'max_leaf_nodes': 80, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.22334064795020667}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:32,825] Trial 163 finished with value: 0.7125360110630272 and parameters: {'learning_rate': 0.13354919535455728, 'max_leaf_nodes': 123, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 0.09870706764196477}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:34,586] Trial 164 finished with value: 0.7125371041977944 and parameters: {'learning_rate': 0.16710674280264895, 'max_leaf_nodes': 69, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.1722291576018107}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:36,417] Trial 165 finished with value: 0.7117814222086533 and parameters: {'learning_rate': 0.18489006377281467, 'max_leaf_nodes': 246, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.9953383324400025}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:37,800] Trial 166 finished with value: 0.711691892680182 and parameters: {'learning_rate': 0.29559624737917395, 'max_leaf_nodes': 128, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.004217930149084125}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:39,551] Trial 167 finished with value: 0.7103697882857795 and parameters: {'learning_rate': 0.1184438329001028, 'max_leaf_nodes': 110, 'max_depth': 5, 'min_samples_leaf': 30, 'l2_regularization': 1.182583617665635}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:41,370] Trial 168 finished with value: 0.7119263094502785 and parameters: {'learning_rate': 0.145888375183098, 'max_leaf_nodes': 45, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.9941508605468153}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:42,739] Trial 169 finished with value: 0.710847971159378 and parameters: {'learning_rate': 0.26306719389408084, 'max_leaf_nodes': 63, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.05648194925086535}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:44,474] Trial 170 finished with value: 0.7135047518597577 and parameters: {'learning_rate': 0.21138718762031866, 'max_leaf_nodes': 147, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8373099554784027}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:46,175] Trial 171 finished with value: 0.7125174653208659 and parameters: {'learning_rate': 0.21270099106908194, 'max_leaf_nodes': 145, 'max_depth': 2, 'min_samples_leaf': 12, 'l2_regularization': 0.6534514723423615}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:48,034] Trial 172 finished with value: 0.7130295554323935 and parameters: {'learning_rate': 0.17080167412884198, 'max_leaf_nodes': 150, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8793245871853207}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:49,849] Trial 173 finished with value: 0.7133391512922769 and parameters: {'learning_rate': 0.15808201683302595, 'max_leaf_nodes': 153, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.49140516699082226}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:51,635] Trial 174 finished with value: 0.712299201812758 and parameters: {'learning_rate': 0.1740421705583804, 'max_leaf_nodes': 164, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.8690728139048555}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:53,442] Trial 175 finished with value: 0.7132928122463632 and parameters: {'learning_rate': 0.15690456981380152, 'max_leaf_nodes': 154, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.742630338418661}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:55,386] Trial 176 finished with value: 0.7129038403972452 and parameters: {'learning_rate': 0.1523500711162004, 'max_leaf_nodes': 162, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.7915402519873167}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:57,286] Trial 177 finished with value: 0.7131300698522572 and parameters: {'learning_rate': 0.16260330235346304, 'max_leaf_nodes': 152, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.9124892565495959}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:42:59,067] Trial 178 finished with value: 0.7112388019621325 and parameters: {'learning_rate': 0.23689138475601113, 'max_leaf_nodes': 171, 'max_depth': 2, 'min_samples_leaf': 85, 'l2_regularization': 0.903111769021152}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:00,875] Trial 179 finished with value: 0.7132200712594526 and parameters: {'learning_rate': 0.18725059892065968, 'max_leaf_nodes': 155, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8290461339901422}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:02,684] Trial 180 finished with value: 0.7126054507269135 and parameters: {'learning_rate': 0.1742682135942301, 'max_leaf_nodes': 156, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8358569132344431}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:04,412] Trial 181 finished with value: 0.7128146018230185 and parameters: {'learning_rate': 0.19141835649524017, 'max_leaf_nodes': 153, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.7591024563980802}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:06,179] Trial 182 finished with value: 0.712003235590924 and parameters: {'learning_rate': 0.1604073476905427, 'max_leaf_nodes': 149, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9757601238446068}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:07,845] Trial 183 finished with value: 0.7122262577598613 and parameters: {'learning_rate': 0.21444503477303678, 'max_leaf_nodes': 159, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.7263744959955358}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:09,217] Trial 184 finished with value: 0.7132661426112046 and parameters: {'learning_rate': 0.24961415998934836, 'max_leaf_nodes': 149, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.9172297784172521}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:10,982] Trial 185 finished with value: 0.7134374397212149 and parameters: {'learning_rate': 0.18387779004212312, 'max_leaf_nodes': 148, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.9284469722159321}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:12,521] Trial 186 finished with value: 0.7115012393809099 and parameters: {'learning_rate': 0.2635624228329129, 'max_leaf_nodes': 146, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 0.8410309458936452}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:14,135] Trial 187 finished with value: 0.7127586597960774 and parameters: {'learning_rate': 0.19443892839581103, 'max_leaf_nodes': 156, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.9130724009780397}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:15,697] Trial 188 finished with value: 0.7126408399198609 and parameters: {'learning_rate': 0.22136918626043628, 'max_leaf_nodes': 140, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.019042448117852}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:17,596] Trial 189 finished with value: 0.7124015990974673 and parameters: {'learning_rate': 0.14282294105908214, 'max_leaf_nodes': 161, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.8048100725903009}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:19,542] Trial 190 finished with value: 0.6781257055124905 and parameters: {'learning_rate': 0.017119386627746692, 'max_leaf_nodes': 168, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.9432186573366239}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:21,278] Trial 191 finished with value: 0.7128673075369676 and parameters: {'learning_rate': 0.16966896388690145, 'max_leaf_nodes': 154, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.8861902063502284}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:23,079] Trial 192 finished with value: 0.7132098713496632 and parameters: {'learning_rate': 0.17971052239231922, 'max_leaf_nodes': 150, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0550457908107695}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:24,790] Trial 193 finished with value: 0.711576907648011 and parameters: {'learning_rate': 0.1892949955061262, 'max_leaf_nodes': 148, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.5521130135528176}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:26,949] Trial 194 finished with value: 0.7131642421828787 and parameters: {'learning_rate': 0.15924539239603047, 'max_leaf_nodes': 143, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.9493456483173348}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:28,886] Trial 195 finished with value: 0.7125814368114071 and parameters: {'learning_rate': 0.1565646956234346, 'max_leaf_nodes': 143, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.048229442974951}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:30,692] Trial 196 finished with value: 0.7126478023183249 and parameters: {'learning_rate': 0.14398219986827782, 'max_leaf_nodes': 136, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.9363898940903601}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:32,759] Trial 197 finished with value: 0.7123566719228723 and parameters: {'learning_rate': 0.12796922480469355, 'max_leaf_nodes': 151, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.9646959637896566}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:35,053] Trial 198 finished with value: 0.6406225505758134 and parameters: {'learning_rate': 0.004367182832130783, 'max_leaf_nodes': 142, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.7485569931913717}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:37,020] Trial 199 finished with value: 0.7130092306672375 and parameters: {'learning_rate': 0.18316335680078288, 'max_leaf_nodes': 157, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.48062040741564094}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:38,853] Trial 200 finished with value: 0.7132784553910987 and parameters: {'learning_rate': 0.2035920270893969, 'max_leaf_nodes': 132, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.3888222722921552}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:40,833] Trial 201 finished with value: 0.7121248212949489 and parameters: {'learning_rate': 0.15809207485814875, 'max_leaf_nodes': 136, 'max_depth': 2, 'min_samples_leaf': 135, 'l2_regularization': 0.4194728593785841}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:42,489] Trial 202 finished with value: 0.7120686133817974 and parameters: {'learning_rate': 0.20233045887097537, 'max_leaf_nodes': 132, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.8271942832904691}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:44,437] Trial 203 finished with value: 0.7122605933552497 and parameters: {'learning_rate': 0.13989930623300426, 'max_leaf_nodes': 145, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.9109188704378249}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:46,279] Trial 204 finished with value: 0.7127006103666117 and parameters: {'learning_rate': 0.17260805037637106, 'max_leaf_nodes': 139, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.3868536869492269}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:47,808] Trial 205 finished with value: 0.7128971037943714 and parameters: {'learning_rate': 0.22931312547448576, 'max_leaf_nodes': 131, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.4557105656878208}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:49,789] Trial 206 finished with value: 0.7131616784754098 and parameters: {'learning_rate': 0.1528154255202378, 'max_leaf_nodes': 148, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.0714927087812862}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:51,708] Trial 207 finished with value: 0.7127129796883169 and parameters: {'learning_rate': 0.1942239938562866, 'max_leaf_nodes': 149, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.0728457696351104}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:53,640] Trial 208 finished with value: 0.713802819294084 and parameters: {'learning_rate': 0.15939312479547418, 'max_leaf_nodes': 153, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.1001148059487535}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:55,577] Trial 209 finished with value: 0.7111811246125278 and parameters: {'learning_rate': 0.15394027128881999, 'max_leaf_nodes': 154, 'max_depth': 2, 'min_samples_leaf': 111, 'l2_regularization': 1.0936364563715018}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:57,347] Trial 210 finished with value: 0.7115747659092977 and parameters: {'learning_rate': 0.17794021927910242, 'max_leaf_nodes': 158, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.9860136392188495}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:43:59,347] Trial 211 finished with value: 0.7121975227479118 and parameters: {'learning_rate': 0.12403197128650212, 'max_leaf_nodes': 147, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.0394775798186195}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:01,188] Trial 212 finished with value: 0.7131110239679902 and parameters: {'learning_rate': 0.20992872892678283, 'max_leaf_nodes': 152, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.1085417515292648}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:02,581] Trial 213 finished with value: 0.7117607414569309 and parameters: {'learning_rate': 0.21250174598228655, 'max_leaf_nodes': 162, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.1128973673033482}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:04,037] Trial 214 finished with value: 0.712105115930199 and parameters: {'learning_rate': 0.24091359124450876, 'max_leaf_nodes': 154, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.1582689055218969}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:05,896] Trial 215 finished with value: 0.7136562004819712 and parameters: {'learning_rate': 0.15999854152932033, 'max_leaf_nodes': 151, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0004041634562955}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:07,895] Trial 216 finished with value: 0.7134086053731188 and parameters: {'learning_rate': 0.1635754498565435, 'max_leaf_nodes': 145, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.010635303427412}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:09,970] Trial 217 finished with value: 0.6688752823203348 and parameters: {'learning_rate': 0.010029866756257987, 'max_leaf_nodes': 142, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.9961482372687578}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:11,793] Trial 218 finished with value: 0.7124197126736075 and parameters: {'learning_rate': 0.13686044059600633, 'max_leaf_nodes': 146, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.016797235631057}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:13,626] Trial 219 finished with value: 0.7130719141139537 and parameters: {'learning_rate': 0.17895892771251748, 'max_leaf_nodes': 159, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.5946754362898766}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:15,629] Trial 220 finished with value: 0.6915792448750004 and parameters: {'learning_rate': 0.027278507966327196, 'max_leaf_nodes': 143, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0422914224186568}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:17,433] Trial 221 finished with value: 0.7126617093028247 and parameters: {'learning_rate': 0.1589182520714813, 'max_leaf_nodes': 150, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.9500456319353666}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:19,204] Trial 222 finished with value: 0.7133973148457894 and parameters: {'learning_rate': 0.15948678191187565, 'max_leaf_nodes': 152, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.8530269892359963}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:21,135] Trial 223 finished with value: 0.7131836256501706 and parameters: {'learning_rate': 0.14899285617635766, 'max_leaf_nodes': 167, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.8379331085745501}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:23,256] Trial 224 finished with value: 0.7120041272540918 and parameters: {'learning_rate': 0.13697995385470688, 'max_leaf_nodes': 170, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.7084322940446193}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:24,954] Trial 225 finished with value: 0.7117353329748819 and parameters: {'learning_rate': 0.17144015366982784, 'max_leaf_nodes': 165, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.8432178371504705}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:26,839] Trial 226 finished with value: 0.7119561715179732 and parameters: {'learning_rate': 0.18489801753199772, 'max_leaf_nodes': 159, 'max_depth': 2, 'min_samples_leaf': 154, 'l2_regularization': 0.8156341070464369}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:28,885] Trial 227 finished with value: 0.7127984729671729 and parameters: {'learning_rate': 0.14706520897125086, 'max_leaf_nodes': 138, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.8773963790197494}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:30,789] Trial 228 finished with value: 0.7127007845830156 and parameters: {'learning_rate': 0.11805160723973024, 'max_leaf_nodes': 155, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.3481977026940072}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:32,418] Trial 229 finished with value: 0.7129382445427905 and parameters: {'learning_rate': 0.19983116905885648, 'max_leaf_nodes': 174, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.5155778375383537}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:34,214] Trial 230 finished with value: 0.7124609019106645 and parameters: {'learning_rate': 0.16444200927834504, 'max_leaf_nodes': 134, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.3882211258253786}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:36,071] Trial 231 finished with value: 0.712993908308121 and parameters: {'learning_rate': 0.1439020266228373, 'max_leaf_nodes': 148, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.9620568254083913}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:37,921] Trial 232 finished with value: 0.7124614793588084 and parameters: {'learning_rate': 0.1529827738283902, 'max_leaf_nodes': 146, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.021283287118106}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:39,490] Trial 233 finished with value: 0.7118945109345561 and parameters: {'learning_rate': 0.18078219787192698, 'max_leaf_nodes': 151, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.8778212470367276}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:41,439] Trial 234 finished with value: 0.7128476987743646 and parameters: {'learning_rate': 0.1344299596859273, 'max_leaf_nodes': 141, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 0.7883316782057329}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:43,313] Trial 235 finished with value: 0.7131438720080123 and parameters: {'learning_rate': 0.16029830951173363, 'max_leaf_nodes': 125, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.0714824840445556}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:44,978] Trial 236 finished with value: 0.7130311546733653 and parameters: {'learning_rate': 0.1943876218070686, 'max_leaf_nodes': 117, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.9182201749001733}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:46,899] Trial 237 finished with value: 0.711108813418363 and parameters: {'learning_rate': 0.12792633241320003, 'max_leaf_nodes': 178, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.44048692250523835}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:48,972] Trial 238 finished with value: 0.7128217644785739 and parameters: {'learning_rate': 0.15019732371076824, 'max_leaf_nodes': 165, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8541112212778369}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:50,693] Trial 239 finished with value: 0.7099036331282395 and parameters: {'learning_rate': 0.17298298870145243, 'max_leaf_nodes': 156, 'max_depth': 6, 'min_samples_leaf': 24, 'l2_regularization': 0.992677829679516}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:52,550] Trial 240 finished with value: 0.7124869852527425 and parameters: {'learning_rate': 0.2243797537258999, 'max_leaf_nodes': 146, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 0.929607115729401}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:54,326] Trial 241 finished with value: 0.7132160620233207 and parameters: {'learning_rate': 0.1596787846002669, 'max_leaf_nodes': 121, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.7823470416247039}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:56,149] Trial 242 finished with value: 0.7136874689692985 and parameters: {'learning_rate': 0.16017620024469367, 'max_leaf_nodes': 122, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.8099857674589171}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:57,977] Trial 243 finished with value: 0.7125128353764112 and parameters: {'learning_rate': 0.1679509124419006, 'max_leaf_nodes': 121, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.7948753455551743}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:44:59,746] Trial 244 finished with value: 0.7136003344995968 and parameters: {'learning_rate': 0.19128157661838394, 'max_leaf_nodes': 118, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.7558853925413861}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:01,362] Trial 245 finished with value: 0.7119243095355948 and parameters: {'learning_rate': 0.2025926792100383, 'max_leaf_nodes': 115, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.6874617835611593}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:03,087] Trial 246 finished with value: 0.7127419809675256 and parameters: {'learning_rate': 0.18679096276754367, 'max_leaf_nodes': 123, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.7645840625202122}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:05,069] Trial 247 finished with value: 0.7124420909291198 and parameters: {'learning_rate': 0.14215769891662794, 'max_leaf_nodes': 128, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.7747251556844978}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:06,960] Trial 248 finished with value: 0.7113825999015362 and parameters: {'learning_rate': 0.2334659561128943, 'max_leaf_nodes': 119, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.8332317477660214}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:08,777] Trial 249 finished with value: 0.7132972280408065 and parameters: {'learning_rate': 0.17976768606521618, 'max_leaf_nodes': 111, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.8078168653091193}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:10,497] Trial 250 finished with value: 0.7114757169750077 and parameters: {'learning_rate': 0.20270965951622769, 'max_leaf_nodes': 111, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 0.805453007000012}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:12,294] Trial 251 finished with value: 0.7122071719324504 and parameters: {'learning_rate': 0.1771077648387683, 'max_leaf_nodes': 106, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 0.7111435299964635}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:13,925] Trial 252 finished with value: 0.7119659077385192 and parameters: {'learning_rate': 0.2645467299886354, 'max_leaf_nodes': 117, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.7354480113495008}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:15,968] Trial 253 finished with value: 0.6995778222841144 and parameters: {'learning_rate': 0.041987956330835505, 'max_leaf_nodes': 123, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.762818820444773}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:17,624] Trial 254 finished with value: 0.712908752587201 and parameters: {'learning_rate': 0.21517720452005024, 'max_leaf_nodes': 113, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.32806037011730654}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:19,489] Trial 255 finished with value: 0.7119087304644484 and parameters: {'learning_rate': 0.18839418622913204, 'max_leaf_nodes': 125, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.4009387778734125}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:21,604] Trial 256 finished with value: 0.6860314706238398 and parameters: {'learning_rate': 0.020879050885581257, 'max_leaf_nodes': 130, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.6316985476752242}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:23,323] Trial 257 finished with value: 0.7125589440282505 and parameters: {'learning_rate': 0.1659074417838169, 'max_leaf_nodes': 120, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.4976501778996375}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:24,614] Trial 258 finished with value: 0.7135212867807329 and parameters: {'learning_rate': 0.2453384042659207, 'max_leaf_nodes': 101, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.7894410628267954}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:25,755] Trial 259 finished with value: 0.7103462488269714 and parameters: {'learning_rate': 0.24636001768801913, 'max_leaf_nodes': 112, 'max_depth': 7, 'min_samples_leaf': 22, 'l2_regularization': 0.8619598804419474}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:26,985] Trial 260 finished with value: 0.7113055869329413 and parameters: {'learning_rate': 0.26903739632470913, 'max_leaf_nodes': 118, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.8041154848980376}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:28,575] Trial 261 finished with value: 0.7123077028528277 and parameters: {'learning_rate': 0.2370701792095079, 'max_leaf_nodes': 105, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.7924732668955008}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:30,101] Trial 262 finished with value: 0.7113039540882916 and parameters: {'learning_rate': 0.2156179016562376, 'max_leaf_nodes': 101, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.8716543973852837}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:32,086] Trial 263 finished with value: 0.7124343804417566 and parameters: {'learning_rate': 0.11342073323187303, 'max_leaf_nodes': 132, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.7359949639277331}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:33,997] Trial 264 finished with value: 0.7125110997370829 and parameters: {'learning_rate': 0.12932261874954412, 'max_leaf_nodes': 106, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.7496304316834901}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:35,698] Trial 265 finished with value: 0.7120390726128163 and parameters: {'learning_rate': 0.20202718356715396, 'max_leaf_nodes': 114, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 0.8206416029224185}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:37,633] Trial 266 finished with value: 0.7130881796897725 and parameters: {'learning_rate': 0.1625882641902289, 'max_leaf_nodes': 127, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.6761409728430026}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:39,509] Trial 267 finished with value: 0.7128887760220619 and parameters: {'learning_rate': 0.1391762622870156, 'max_leaf_nodes': 135, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.4455207743383036}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:41,372] Trial 268 finished with value: 0.7132037242523911 and parameters: {'learning_rate': 0.18222593843232124, 'max_leaf_nodes': 109, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.004242630153237834}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:43,037] Trial 269 finished with value: 0.71245952465445 and parameters: {'learning_rate': 0.22664692543963935, 'max_leaf_nodes': 98, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.8486497302992559}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:44,746] Trial 270 finished with value: 0.7130138549970184 and parameters: {'learning_rate': 0.2567696642382313, 'max_leaf_nodes': 120, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.6322294019707613}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:46,485] Trial 271 finished with value: 0.712508473461589 and parameters: {'learning_rate': 0.15707893873119474, 'max_leaf_nodes': 154, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.7683174053584441}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:47,942] Trial 272 finished with value: 0.7128735018761991 and parameters: {'learning_rate': 0.19696402055266932, 'max_leaf_nodes': 160, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.9032310933570613}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:49,897] Trial 273 finished with value: 0.7103574075539054 and parameters: {'learning_rate': 0.12425274100160354, 'max_leaf_nodes': 50, 'max_depth': 2, 'min_samples_leaf': 71, 'l2_regularization': 0.357633036088147}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:51,827] Trial 274 finished with value: 0.712484459123471 and parameters: {'learning_rate': 0.1424725902005122, 'max_leaf_nodes': 139, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.04463680533074649}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:53,551] Trial 275 finished with value: 0.7121344636155678 and parameters: {'learning_rate': 0.1761894114888877, 'max_leaf_nodes': 40, 'max_depth': 2, 'min_samples_leaf': 28, 'l2_regularization': 0.873307756190636}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:55,156] Trial 276 finished with value: 0.713104926297156 and parameters: {'learning_rate': 0.20899698699799693, 'max_leaf_nodes': 128, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.7015570321649746}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:56,884] Trial 277 finished with value: 0.7126435176290732 and parameters: {'learning_rate': 0.16172623731931668, 'max_leaf_nodes': 117, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.3029161547273016}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:58,386] Trial 278 finished with value: 0.7129102808495259 and parameters: {'learning_rate': 0.2965629644872556, 'max_leaf_nodes': 133, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8188122328516605}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:45:59,948] Trial 279 finished with value: 0.7116162426967352 and parameters: {'learning_rate': 0.18891305416362875, 'max_leaf_nodes': 122, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.41754483334966275}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:01,900] Trial 280 finished with value: 0.7125731711111523 and parameters: {'learning_rate': 0.1467805587205486, 'max_leaf_nodes': 95, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.5392815503277111}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:03,429] Trial 281 finished with value: 0.713028619166403 and parameters: {'learning_rate': 0.236793286965012, 'max_leaf_nodes': 152, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.8969119665305024}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:05,069] Trial 282 finished with value: 0.7123579747292577 and parameters: {'learning_rate': 0.17361548370584742, 'max_leaf_nodes': 143, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.7890974740807831}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:07,049] Trial 283 finished with value: 0.7135065284320511 and parameters: {'learning_rate': 0.13411305029803008, 'max_leaf_nodes': 125, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.46446317664632564}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:09,056] Trial 284 finished with value: 0.7128769347064371 and parameters: {'learning_rate': 0.133002387127281, 'max_leaf_nodes': 137, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.4858224141827687}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:26,555] Trial 285 finished with value: 0.6820501200809466 and parameters: {'learning_rate': 0.0014421848290648192, 'max_leaf_nodes': 157, 'max_depth': 9, 'min_samples_leaf': 13, 'l2_regularization': 0.3818019999098671}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:28,485] Trial 286 finished with value: 0.7129695355638968 and parameters: {'learning_rate': 0.12103027399523911, 'max_leaf_nodes': 129, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.4554763423036717}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:30,417] Trial 287 finished with value: 0.7120919982806597 and parameters: {'learning_rate': 0.10896823768881606, 'max_leaf_nodes': 201, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.9388477067739913}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:32,292] Trial 288 finished with value: 0.7128776676132071 and parameters: {'learning_rate': 0.14098073225650307, 'max_leaf_nodes': 146, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.5711292065974531}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:34,252] Trial 289 finished with value: 0.7120682121092583 and parameters: {'learning_rate': 0.20781087916003566, 'max_leaf_nodes': 20, 'max_depth': 2, 'min_samples_leaf': 120, 'l2_regularization': 0.07606188887348656}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:36,104] Trial 290 finished with value: 0.712413677675482 and parameters: {'learning_rate': 0.18442346079279445, 'max_leaf_nodes': 152, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.00906701684017141}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:37,970] Trial 291 finished with value: 0.7120667137125609 and parameters: {'learning_rate': 0.15479595930657636, 'max_leaf_nodes': 110, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.4204706480932502}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:39,688] Trial 292 finished with value: 0.7112771622109164 and parameters: {'learning_rate': 0.2646485958648561, 'max_leaf_nodes': 126, 'max_depth': 2, 'min_samples_leaf': 182, 'l2_regularization': 0.5080627470591739}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:41,704] Trial 293 finished with value: 0.7128439321823822 and parameters: {'learning_rate': 0.12846659834197122, 'max_leaf_nodes': 27, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.4631001093567158}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:43,536] Trial 294 finished with value: 0.7110263637146955 and parameters: {'learning_rate': 0.2197044190537977, 'max_leaf_nodes': 140, 'max_depth': 2, 'min_samples_leaf': 98, 'l2_regularization': 0.8475133583235398}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:45,376] Trial 295 finished with value: 0.7118016206652804 and parameters: {'learning_rate': 0.16554976899232152, 'max_leaf_nodes': 160, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.9671008664689883}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:47,223] Trial 296 finished with value: 0.7133889565408096 and parameters: {'learning_rate': 0.19206969601552387, 'max_leaf_nodes': 217, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.9063528871887009}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:48,747] Trial 297 finished with value: 0.7123972602308892 and parameters: {'learning_rate': 0.24616578799954572, 'max_leaf_nodes': 103, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 1.2110639065707898}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:50,166] Trial 298 finished with value: 0.7129386671245164 and parameters: {'learning_rate': 0.1421254894852486, 'max_leaf_nodes': 214, 'max_depth': 5, 'min_samples_leaf': 18, 'l2_regularization': 1.010280058300627}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:52,157] Trial 299 finished with value: 0.7118416015799667 and parameters: {'learning_rate': 0.11483573867614595, 'max_leaf_nodes': 235, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.9166536000659029}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:53,793] Trial 300 finished with value: 0.7119538530869833 and parameters: {'learning_rate': 0.19713086029316668, 'max_leaf_nodes': 227, 'max_depth': 2, 'min_samples_leaf': 30, 'l2_regularization': 0.37745718602584766}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:55,570] Trial 301 finished with value: 0.7110861287159905 and parameters: {'learning_rate': 0.17400654517724481, 'max_leaf_nodes': 131, 'max_depth': 10, 'min_samples_leaf': 16, 'l2_regularization': 0.9713797824916816}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:57,435] Trial 302 finished with value: 0.7123924914297023 and parameters: {'learning_rate': 0.15043208002989378, 'max_leaf_nodes': 55, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.003653297561119123}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:46:58,980] Trial 303 finished with value: 0.711831612806652 and parameters: {'learning_rate': 0.21726253264259773, 'max_leaf_nodes': 190, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.041345740486458026}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:00,934] Trial 304 finished with value: 0.7128395930727492 and parameters: {'learning_rate': 0.13237100413731503, 'max_leaf_nodes': 43, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.8757252674116932}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:02,780] Trial 305 finished with value: 0.7121582673533611 and parameters: {'learning_rate': 0.16697239169699207, 'max_leaf_nodes': 182, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.9117133748631161}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:04,764] Trial 306 finished with value: 0.6753525290580267 and parameters: {'learning_rate': 0.01467907806705093, 'max_leaf_nodes': 248, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.30817864374306647}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:06,523] Trial 307 finished with value: 0.7133666626453887 and parameters: {'learning_rate': 0.1902271019222647, 'max_leaf_nodes': 115, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.4238353479471193}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:08,283] Trial 308 finished with value: 0.7122605453414173 and parameters: {'learning_rate': 0.18246653865029078, 'max_leaf_nodes': 114, 'max_depth': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.4293317817948593}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:10,052] Trial 309 finished with value: 0.7110015576022849 and parameters: {'learning_rate': 0.15309810447079347, 'max_leaf_nodes': 109, 'max_depth': 2, 'min_samples_leaf': 33, 'l2_regularization': 0.3910156084331161}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:11,811] Trial 310 finished with value: 0.7123489925399273 and parameters: {'learning_rate': 0.19719600166537943, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 0.3503451089096525}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:13,908] Trial 311 finished with value: 0.7115756207024223 and parameters: {'learning_rate': 0.10452260171133836, 'max_leaf_nodes': 99, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.4986991959909568}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:15,672] Trial 312 finished with value: 0.711068796533152 and parameters: {'learning_rate': 0.16870533196827728, 'max_leaf_nodes': 116, 'max_depth': 2, 'min_samples_leaf': 31, 'l2_regularization': 0.4720674817988346}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:17,530] Trial 313 finished with value: 0.7125729274097353 and parameters: {'learning_rate': 0.13784870296691065, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.1244402265791693}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:19,284] Trial 314 finished with value: 0.7139412629664531 and parameters: {'learning_rate': 0.1574754126338565, 'max_leaf_nodes': 116, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.5691777215697142}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:20,967] Trial 315 finished with value: 0.7099283643364085 and parameters: {'learning_rate': 0.15029983400478408, 'max_leaf_nodes': 114, 'max_depth': 8, 'min_samples_leaf': 25, 'l2_regularization': 0.5337054403826893}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:22,973] Trial 316 finished with value: 0.7124578666980674 and parameters: {'learning_rate': 0.12223662055145501, 'max_leaf_nodes': 120, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.5548070464108394}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:25,147] Trial 317 finished with value: 0.7115457647641786 and parameters: {'learning_rate': 0.16208610469684476, 'max_leaf_nodes': 109, 'max_depth': 2, 'min_samples_leaf': 128, 'l2_regularization': 0.7296092849350523}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:27,155] Trial 318 finished with value: 0.712684358538385 and parameters: {'learning_rate': 0.13505845467731895, 'max_leaf_nodes': 104, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 0.6423121867162754}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:28,855] Trial 319 finished with value: 0.71275932226249 and parameters: {'learning_rate': 0.17952495966492305, 'max_leaf_nodes': 202, 'max_depth': 2, 'min_samples_leaf': 29, 'l2_regularization': 0.4701544910427709}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:30,583] Trial 320 finished with value: 0.711550534508539 and parameters: {'learning_rate': 0.1492540623980214, 'max_leaf_nodes': 117, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.5216148969591645}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:32,408] Trial 321 finished with value: 0.7128726758706229 and parameters: {'learning_rate': 0.16710565920761733, 'max_leaf_nodes': 112, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.08154102730019193}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:34,555] Trial 322 finished with value: 0.713331191472533 and parameters: {'learning_rate': 0.11806283447976307, 'max_leaf_nodes': 91, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 0.7412682012275584}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:36,794] Trial 323 finished with value: 0.7127122649298813 and parameters: {'learning_rate': 0.09588808119835421, 'max_leaf_nodes': 47, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 0.5986980599561257}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:38,834] Trial 324 finished with value: 0.7137232285051696 and parameters: {'learning_rate': 0.12170455538383645, 'max_leaf_nodes': 119, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 0.6736722651161088}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:40,888] Trial 325 finished with value: 0.7137557381116617 and parameters: {'learning_rate': 0.10959535224566398, 'max_leaf_nodes': 118, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 0.6706318098577616}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:42,865] Trial 326 finished with value: 0.7125088056115358 and parameters: {'learning_rate': 0.10839974736373456, 'max_leaf_nodes': 118, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 0.6658266875178588}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:45,250] Trial 327 finished with value: 0.7131519757587222 and parameters: {'learning_rate': 0.09994076765922748, 'max_leaf_nodes': 111, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 0.6059995312294402}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:47,095] Trial 328 finished with value: 0.7128109388964319 and parameters: {'learning_rate': 0.11799964477970552, 'max_leaf_nodes': 122, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 0.6350924031678689}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:49,260] Trial 329 finished with value: 0.7127497268664011 and parameters: {'learning_rate': 0.10809873668065843, 'max_leaf_nodes': 107, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 0.7085356931640518}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:51,444] Trial 330 finished with value: 0.7115144274638474 and parameters: {'learning_rate': 0.12377761200600518, 'max_leaf_nodes': 115, 'max_depth': 3, 'min_samples_leaf': 14, 'l2_regularization': 0.6646122907259614}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:53,710] Trial 331 finished with value: 0.7116050737666015 and parameters: {'learning_rate': 0.08621422359945094, 'max_leaf_nodes': 37, 'max_depth': 3, 'min_samples_leaf': 23, 'l2_regularization': 0.5712856006533257}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:55,390] Trial 332 finished with value: 0.7122039920188754 and parameters: {'learning_rate': 0.12988872233356702, 'max_leaf_nodes': 88, 'max_depth': 3, 'min_samples_leaf': 18, 'l2_regularization': 0.6867267139857095}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:57,149] Trial 333 finished with value: 0.7121242175961499 and parameters: {'learning_rate': 0.11956937553735064, 'max_leaf_nodes': 118, 'max_depth': 4, 'min_samples_leaf': 13, 'l2_regularization': 0.7459900987768008}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:47:59,558] Trial 334 finished with value: 0.7112659748163307 and parameters: {'learning_rate': 0.07845131751596852, 'max_leaf_nodes': 121, 'max_depth': 3, 'min_samples_leaf': 26, 'l2_regularization': 0.7682428761342193}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:01,598] Trial 335 finished with value: 0.71270224318464 and parameters: {'learning_rate': 0.1132851341475893, 'max_leaf_nodes': 102, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 0.7063727410908729}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:03,994] Trial 336 finished with value: 0.7123469670390716 and parameters: {'learning_rate': 0.09131657395752256, 'max_leaf_nodes': 195, 'max_depth': 3, 'min_samples_leaf': 20, 'l2_regularization': 0.7771813962292812}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:05,850] Trial 337 finished with value: 0.7115218912168231 and parameters: {'learning_rate': 0.1391073174063114, 'max_leaf_nodes': 112, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 0.615763094357768}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:07,649] Trial 338 finished with value: 0.7117390157455583 and parameters: {'learning_rate': 0.13061768842065158, 'max_leaf_nodes': 59, 'max_depth': 3, 'min_samples_leaf': 22, 'l2_regularization': 0.8079541369810818}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:09,528] Trial 339 finished with value: 0.7122598887369477 and parameters: {'learning_rate': 0.1444010603447706, 'max_leaf_nodes': 107, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 0.6732685722723821}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:11,388] Trial 340 finished with value: 0.7126569854095154 and parameters: {'learning_rate': 0.10609635576574714, 'max_leaf_nodes': 125, 'max_depth': 4, 'min_samples_leaf': 18, 'l2_regularization': 0.11730277578558773}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:12,988] Trial 341 finished with value: 0.7111028314435294 and parameters: {'learning_rate': 0.18185379882439953, 'max_leaf_nodes': 95, 'max_depth': 3, 'min_samples_leaf': 27, 'l2_regularization': 0.04149601335780688}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:14,855] Trial 342 finished with value: 0.7120015085386104 and parameters: {'learning_rate': 0.15333794216986432, 'max_leaf_nodes': 224, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.8458313740221309}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:16,508] Trial 343 finished with value: 0.710610077043726 and parameters: {'learning_rate': 0.11808941082650325, 'max_leaf_nodes': 117, 'max_depth': 6, 'min_samples_leaf': 17, 'l2_regularization': 0.7317764496413772}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:18,500] Trial 344 finished with value: 0.713066115449471 and parameters: {'learning_rate': 0.1376844587085735, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 0.8240791589906742}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:20,062] Trial 345 finished with value: 0.7120186689228738 and parameters: {'learning_rate': 0.16381175358402147, 'max_leaf_nodes': 114, 'max_depth': 3, 'min_samples_leaf': 14, 'l2_regularization': 0.7391933239686445}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:22,152] Trial 346 finished with value: 0.6650193528389021 and parameters: {'learning_rate': 0.008156821776451353, 'max_leaf_nodes': 120, 'max_depth': 2, 'min_samples_leaf': 33, 'l2_regularization': 0.03471839656785429}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:23,799] Trial 347 finished with value: 0.7125677638445911 and parameters: {'learning_rate': 0.19065942729569546, 'max_leaf_nodes': 134, 'max_depth': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.0005196006644396997}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:25,828] Trial 348 finished with value: 0.7097318097594906 and parameters: {'learning_rate': 0.1307538095314102, 'max_leaf_nodes': 127, 'max_depth': 2, 'min_samples_leaf': 193, 'l2_regularization': 0.5628690914914919}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:27,824] Trial 349 finished with value: 0.7121662431160616 and parameters: {'learning_rate': 0.15308981720031145, 'max_leaf_nodes': 108, 'max_depth': 2, 'min_samples_leaf': 54, 'l2_regularization': 0.8812424168287785}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:32,398] Trial 350 finished with value: 0.6665105877575872 and parameters: {'learning_rate': 0.0028396287593419494, 'max_leaf_nodes': 99, 'max_depth': 5, 'min_samples_leaf': 20, 'l2_regularization': 0.8019000071125211}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:34,067] Trial 351 finished with value: 0.7130259656956536 and parameters: {'learning_rate': 0.17490461974839716, 'max_leaf_nodes': 51, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.7020844850736452}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:35,419] Trial 352 finished with value: 0.7111302910328773 and parameters: {'learning_rate': 0.20527992379645163, 'max_leaf_nodes': 114, 'max_depth': 3, 'min_samples_leaf': 17, 'l2_regularization': 0.06932112684676482}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:37,328] Trial 353 finished with value: 0.7108308077911604 and parameters: {'learning_rate': 0.09943412879051237, 'max_leaf_nodes': 30, 'max_depth': 7, 'min_samples_leaf': 13, 'l2_regularization': 0.7689257379622179}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:39,303] Trial 354 finished with value: 0.7119709422975393 and parameters: {'learning_rate': 0.147046766837182, 'max_leaf_nodes': 211, 'max_depth': 2, 'min_samples_leaf': 29, 'l2_regularization': 0.9440823244497976}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:41,047] Trial 355 finished with value: 0.7126226679737659 and parameters: {'learning_rate': 0.17622319830224215, 'max_leaf_nodes': 120, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 0.8501250603593373}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:42,911] Trial 356 finished with value: 0.7121859584850139 and parameters: {'learning_rate': 0.12468627279334754, 'max_leaf_nodes': 130, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.5872032776443146}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:44,851] Trial 357 finished with value: 0.7129033873541911 and parameters: {'learning_rate': 0.16059889595886148, 'max_leaf_nodes': 139, 'max_depth': 2, 'min_samples_leaf': 37, 'l2_regularization': 0.49989768310844723}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:46,787] Trial 358 finished with value: 0.7135303415575514 and parameters: {'learning_rate': 0.1961902809167288, 'max_leaf_nodes': 111, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9948698200559969}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:48,655] Trial 359 finished with value: 0.7134051816457169 and parameters: {'learning_rate': 0.19903810982903689, 'max_leaf_nodes': 123, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.988759755726785}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:50,739] Trial 360 finished with value: 0.7131120888221242 and parameters: {'learning_rate': 0.20946086327560787, 'max_leaf_nodes': 16, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0137814478115266}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:52,896] Trial 361 finished with value: 0.7125655907936344 and parameters: {'learning_rate': 0.2198655352782282, 'max_leaf_nodes': 255, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.9911314970558089}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:54,995] Trial 362 finished with value: 0.7136642308140215 and parameters: {'learning_rate': 0.19379818957850037, 'max_leaf_nodes': 125, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.9967413547391927}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:57,061] Trial 363 finished with value: 0.7118441234246408 and parameters: {'learning_rate': 0.2243275146086327, 'max_leaf_nodes': 126, 'max_depth': 2, 'min_samples_leaf': 164, 'l2_regularization': 1.053484637341117}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:48:58,977] Trial 364 finished with value: 0.7135304767621193 and parameters: {'learning_rate': 0.19645210058316354, 'max_leaf_nodes': 123, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9864827121230374}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:00,748] Trial 365 finished with value: 0.7132181954298893 and parameters: {'learning_rate': 0.19692843773732618, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9811026117656345}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:02,405] Trial 366 finished with value: 0.7124510815493443 and parameters: {'learning_rate': 0.2149960578525932, 'max_leaf_nodes': 131, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.0382717611847823}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:04,524] Trial 367 finished with value: 0.6956133372136132 and parameters: {'learning_rate': 0.031940962081106604, 'max_leaf_nodes': 129, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9684841323927321}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:06,042] Trial 368 finished with value: 0.7115227531579182 and parameters: {'learning_rate': 0.23250913617490257, 'max_leaf_nodes': 121, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.0173549193176057}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:07,868] Trial 369 finished with value: 0.7136527648733569 and parameters: {'learning_rate': 0.1937561480933362, 'max_leaf_nodes': 136, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.0762650873314352}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:09,754] Trial 370 finished with value: 0.711097902257176 and parameters: {'learning_rate': 0.19597960862298647, 'max_leaf_nodes': 135, 'max_depth': 2, 'min_samples_leaf': 61, 'l2_regularization': 1.0743692259726239}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:11,302] Trial 371 finished with value: 0.7129712450774134 and parameters: {'learning_rate': 0.24227520119018475, 'max_leaf_nodes': 134, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.0290758650491476}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:13,012] Trial 372 finished with value: 0.7135789152978705 and parameters: {'learning_rate': 0.19367632316176905, 'max_leaf_nodes': 128, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 0.9933663215351136}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:14,376] Trial 373 finished with value: 0.7105143107100789 and parameters: {'learning_rate': 0.22251647530063948, 'max_leaf_nodes': 126, 'max_depth': 8, 'min_samples_leaf': 104, 'l2_regularization': 1.112002716962926}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:16,226] Trial 374 finished with value: 0.7109029283638522 and parameters: {'learning_rate': 0.17845823702172073, 'max_leaf_nodes': 136, 'max_depth': 2, 'min_samples_leaf': 83, 'l2_regularization': 0.9991703968275014}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:18,064] Trial 375 finished with value: 0.7131903535613289 and parameters: {'learning_rate': 0.20259842759700428, 'max_leaf_nodes': 129, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.074262543364303}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:20,139] Trial 376 finished with value: 0.7135593955545716 and parameters: {'learning_rate': 0.16917094428316973, 'max_leaf_nodes': 141, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.9435810459343152}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:22,100] Trial 377 finished with value: 0.7125964359210111 and parameters: {'learning_rate': 0.17171556430009052, 'max_leaf_nodes': 141, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 0.960205932026816}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:23,943] Trial 378 finished with value: 0.7126270827334107 and parameters: {'learning_rate': 0.19437590674561525, 'max_leaf_nodes': 144, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 0.9439838682130437}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:25,345] Trial 379 finished with value: 0.7131270906175942 and parameters: {'learning_rate': 0.2717113632373628, 'max_leaf_nodes': 137, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9621977029762635}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:26,986] Trial 380 finished with value: 0.7123091938229715 and parameters: {'learning_rate': 0.23655091395875588, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.0519016853883492}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:28,717] Trial 381 finished with value: 0.7130094470819235 and parameters: {'learning_rate': 0.17670822288534443, 'max_leaf_nodes': 133, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.9838127568049041}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:30,505] Trial 382 finished with value: 0.7138169271166204 and parameters: {'learning_rate': 0.20989624933402948, 'max_leaf_nodes': 129, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.1462445975820248}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:32,040] Trial 383 finished with value: 0.7116304142138601 and parameters: {'learning_rate': 0.21681742727764003, 'max_leaf_nodes': 129, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.16667911850916}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:33,585] Trial 384 finished with value: 0.7117003652666665 and parameters: {'learning_rate': 0.20571232311733914, 'max_leaf_nodes': 121, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0975618266778655}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:35,252] Trial 385 finished with value: 0.7138084541048609 and parameters: {'learning_rate': 0.24304025191897077, 'max_leaf_nodes': 131, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.141781142735164}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:36,997] Trial 386 finished with value: 0.7134385074977224 and parameters: {'learning_rate': 0.23424908711869283, 'max_leaf_nodes': 137, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.1411818723181897}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:38,603] Trial 387 finished with value: 0.7102686346619335 and parameters: {'learning_rate': 0.27565536182748296, 'max_leaf_nodes': 138, 'max_depth': 2, 'min_samples_leaf': 92, 'l2_regularization': 1.1711061620903198}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:40,062] Trial 388 finished with value: 0.7122303870845987 and parameters: {'learning_rate': 0.24412206844071063, 'max_leaf_nodes': 139, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.234390564972309}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:41,327] Trial 389 finished with value: 0.7122247704985546 and parameters: {'learning_rate': 0.27850233048332557, 'max_leaf_nodes': 133, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.1187314865770634}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:42,498] Trial 390 finished with value: 0.7105234875467238 and parameters: {'learning_rate': 0.2341146870511701, 'max_leaf_nodes': 143, 'max_depth': 4, 'min_samples_leaf': 19, 'l2_regularization': 1.113830427087608}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:44,046] Trial 391 finished with value: 0.7129095763137282 and parameters: {'learning_rate': 0.24701567797478777, 'max_leaf_nodes': 130, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.1706375762958445}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:45,878] Trial 392 finished with value: 0.7127656697722982 and parameters: {'learning_rate': 0.2213212182158455, 'max_leaf_nodes': 138, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.0707187614806684}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:47,511] Trial 393 finished with value: 0.7128562814027798 and parameters: {'learning_rate': 0.26081931312267376, 'max_leaf_nodes': 135, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.1378523980744375}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:49,134] Trial 394 finished with value: 0.7125390961939347 and parameters: {'learning_rate': 0.22470011982018526, 'max_leaf_nodes': 128, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.0135944994126707}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:51,337] Trial 395 finished with value: 0.7035938379538985 and parameters: {'learning_rate': 0.05260702207983473, 'max_leaf_nodes': 143, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.2176778725909974}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:53,127] Trial 396 finished with value: 0.7139261408873271 and parameters: {'learning_rate': 0.2428914045455628, 'max_leaf_nodes': 127, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.0814568692042084}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:54,754] Trial 397 finished with value: 0.7117895128254365 and parameters: {'learning_rate': 0.2592740195454483, 'max_leaf_nodes': 127, 'max_depth': 2, 'min_samples_leaf': 157, 'l2_regularization': 1.1040634995171557}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:56,111] Trial 398 finished with value: 0.7120637283226336 and parameters: {'learning_rate': 0.2957454426511899, 'max_leaf_nodes': 132, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.1582735795374162}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:58,141] Trial 399 finished with value: 0.7064626314454611 and parameters: {'learning_rate': 0.06466465036810495, 'max_leaf_nodes': 119, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.2621087779104707}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:49:59,842] Trial 400 finished with value: 0.7137494404523868 and parameters: {'learning_rate': 0.2449373673680685, 'max_leaf_nodes': 126, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0774936338507664}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:01,390] Trial 401 finished with value: 0.7120430372180085 and parameters: {'learning_rate': 0.2644315397657466, 'max_leaf_nodes': 123, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.1433596526217833}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:02,834] Trial 402 finished with value: 0.7119127668977521 and parameters: {'learning_rate': 0.24411110453101262, 'max_leaf_nodes': 126, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.070876089638126}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:04,307] Trial 403 finished with value: 0.7104974786935558 and parameters: {'learning_rate': 0.2852979424005965, 'max_leaf_nodes': 120, 'max_depth': 2, 'min_samples_leaf': 75, 'l2_regularization': 1.0835293112776183}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:05,412] Trial 404 finished with value: 0.7112358876150022 and parameters: {'learning_rate': 0.23140810278295276, 'max_leaf_nodes': 129, 'max_depth': 5, 'min_samples_leaf': 13, 'l2_regularization': 1.187887582424047}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:06,582] Trial 405 finished with value: 0.7112324653020187 and parameters: {'learning_rate': 0.29958169605316926, 'max_leaf_nodes': 116, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.0316408124303573}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:08,204] Trial 406 finished with value: 0.7115918733723854 and parameters: {'learning_rate': 0.24188071743270576, 'max_leaf_nodes': 132, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.0460164275331238}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:09,550] Trial 407 finished with value: 0.712750268182791 and parameters: {'learning_rate': 0.21322368665540345, 'max_leaf_nodes': 123, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 1.1362008649108817}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:10,643] Trial 408 finished with value: 0.7113080950710137 and parameters: {'learning_rate': 0.2587373125737627, 'max_leaf_nodes': 118, 'max_depth': 4, 'min_samples_leaf': 10, 'l2_regularization': 1.0740709898041898}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:12,597] Trial 409 finished with value: 0.7127893093332345 and parameters: {'learning_rate': 0.2227005901257086, 'max_leaf_nodes': 127, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.1380432123676194}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:14,394] Trial 410 finished with value: 0.7132277172221351 and parameters: {'learning_rate': 0.20122252056003273, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 1.1005162003634272}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:16,392] Trial 411 finished with value: 0.6425762114790864 and parameters: {'learning_rate': 0.004432397900558569, 'max_leaf_nodes': 116, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0962727186174217}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:18,005] Trial 412 finished with value: 0.7129719998582993 and parameters: {'learning_rate': 0.2124551608719467, 'max_leaf_nodes': 132, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.0435419844581904}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:19,545] Trial 413 finished with value: 0.7133968816846922 and parameters: {'learning_rate': 0.2512934511396195, 'max_leaf_nodes': 136, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 1.021458578343313}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:21,247] Trial 414 finished with value: 0.7139461926736889 and parameters: {'learning_rate': 0.19335411302144337, 'max_leaf_nodes': 121, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.1875706853900332}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:23,036] Trial 415 finished with value: 0.7122153188215379 and parameters: {'learning_rate': 0.19040617860182066, 'max_leaf_nodes': 119, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.2360547200204715}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:24,825] Trial 416 finished with value: 0.7114425349013092 and parameters: {'learning_rate': 0.23061850395200614, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 137, 'l2_regularization': 1.1931691491177001}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:26,516] Trial 417 finished with value: 0.7112354466315624 and parameters: {'learning_rate': 0.2117919151197815, 'max_leaf_nodes': 113, 'max_depth': 10, 'min_samples_leaf': 20, 'l2_regularization': 1.157483220814157}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:27,899] Trial 418 finished with value: 0.7116803725325049 and parameters: {'learning_rate': 0.19324646218082833, 'max_leaf_nodes': 127, 'max_depth': 3, 'min_samples_leaf': 16, 'l2_regularization': 1.1805422687892488}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:29,402] Trial 419 finished with value: 0.711952791145159 and parameters: {'learning_rate': 0.2518046113502362, 'max_leaf_nodes': 120, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.1471703971307445}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:31,214] Trial 420 finished with value: 0.7129975523187161 and parameters: {'learning_rate': 0.18853983992610904, 'max_leaf_nodes': 130, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.2146635537908275}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:32,832] Trial 421 finished with value: 0.7121787366082672 and parameters: {'learning_rate': 0.23029106012286019, 'max_leaf_nodes': 116, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.121906502233776}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:34,346] Trial 422 finished with value: 0.7109911362855499 and parameters: {'learning_rate': 0.2732887766321407, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.085381217958684}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:35,787] Trial 423 finished with value: 0.7124843697619571 and parameters: {'learning_rate': 0.2022911258488981, 'max_leaf_nodes': 113, 'max_depth': 3, 'min_samples_leaf': 17, 'l2_regularization': 1.054976606020398}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:37,623] Trial 424 finished with value: 0.7127769742963542 and parameters: {'learning_rate': 0.1815905700012159, 'max_leaf_nodes': 121, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.1051375987545158}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:39,188] Trial 425 finished with value: 0.7122345330274336 and parameters: {'learning_rate': 0.21559538328247152, 'max_leaf_nodes': 131, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 1.0430362739398493}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:40,681] Trial 426 finished with value: 0.7139060589719578 and parameters: {'learning_rate': 0.2979706713529334, 'max_leaf_nodes': 110, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.0013780967573735}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:42,140] Trial 427 finished with value: 0.7121920820436778 and parameters: {'learning_rate': 0.29290983082718536, 'max_leaf_nodes': 109, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.9840985336092708}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:43,610] Trial 428 finished with value: 0.7117034235812553 and parameters: {'learning_rate': 0.2770801706539316, 'max_leaf_nodes': 105, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0182513642282045}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:45,101] Trial 429 finished with value: 0.7119383899554125 and parameters: {'learning_rate': 0.273664219059084, 'max_leaf_nodes': 109, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.0053438262191452}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:46,623] Trial 430 finished with value: 0.7119900069606939 and parameters: {'learning_rate': 0.25304633487863387, 'max_leaf_nodes': 117, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.9336485762660942}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:47,834] Trial 431 finished with value: 0.7116200850370291 and parameters: {'learning_rate': 0.2944811496866424, 'max_leaf_nodes': 113, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 0.6433994905650354}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:49,767] Trial 432 finished with value: 0.7125739615605541 and parameters: {'learning_rate': 0.17402452314925793, 'max_leaf_nodes': 119, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.071826985913298}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:51,607] Trial 433 finished with value: 0.7124117422800466 and parameters: {'learning_rate': 0.20261226790773448, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.9857865510408029}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:53,493] Trial 434 finished with value: 0.7121676835490273 and parameters: {'learning_rate': 0.17258240850044346, 'max_leaf_nodes': 112, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.0249088843566514}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:55,256] Trial 435 finished with value: 0.7123401765591751 and parameters: {'learning_rate': 0.24896292212948426, 'max_leaf_nodes': 127, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0654905911931267}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:56,993] Trial 436 finished with value: 0.7128980712920361 and parameters: {'learning_rate': 0.22347048344433365, 'max_leaf_nodes': 117, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.9538143033496403}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:50:58,875] Trial 437 finished with value: 0.7118064252624567 and parameters: {'learning_rate': 0.18750496264780914, 'max_leaf_nodes': 107, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 1.0993269091001794}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:00,683] Trial 438 finished with value: 0.7126715198177072 and parameters: {'learning_rate': 0.17038045450459252, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.0408125602537717}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:02,432] Trial 439 finished with value: 0.7118881014569954 and parameters: {'learning_rate': 0.21532700170291783, 'max_leaf_nodes': 121, 'max_depth': 2, 'min_samples_leaf': 65, 'l2_regularization': 0.9704986085003787}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:03,896] Trial 440 finished with value: 0.7108855195918548 and parameters: {'learning_rate': 0.16433878943055044, 'max_leaf_nodes': 130, 'max_depth': 3, 'min_samples_leaf': 23, 'l2_regularization': 0.6601311763337405}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:05,363] Trial 441 finished with value: 0.7124405409226175 and parameters: {'learning_rate': 0.2987453145582193, 'max_leaf_nodes': 115, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.1989335033899144}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:07,185] Trial 442 finished with value: 0.7125622783596782 and parameters: {'learning_rate': 0.19125231907017673, 'max_leaf_nodes': 127, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.9235391817997294}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:09,249] Trial 443 finished with value: 0.6743677771292863 and parameters: {'learning_rate': 0.014341733030655078, 'max_leaf_nodes': 111, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.9909961059484125}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:10,935] Trial 444 finished with value: 0.7135905938059783 and parameters: {'learning_rate': 0.24596693017658114, 'max_leaf_nodes': 102, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0225232821420387}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:12,500] Trial 445 finished with value: 0.7129279890278001 and parameters: {'learning_rate': 0.25820624843563145, 'max_leaf_nodes': 98, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.0461261644130386}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:15,120] Trial 446 finished with value: 0.6959878996947044 and parameters: {'learning_rate': 0.023050632788261114, 'max_leaf_nodes': 103, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.2850063256199107}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:16,584] Trial 447 finished with value: 0.7119768886734885 and parameters: {'learning_rate': 0.24043313107929054, 'max_leaf_nodes': 101, 'max_depth': 2, 'min_samples_leaf': 22, 'l2_regularization': 1.1109445293578841}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:17,805] Trial 448 finished with value: 0.7131750722144082 and parameters: {'learning_rate': 0.299879660262589, 'max_leaf_nodes': 107, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.25463210229013855}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:19,756] Trial 449 finished with value: 0.7017059436980662 and parameters: {'learning_rate': 0.04447502525980386, 'max_leaf_nodes': 122, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.002348126613399}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:21,368] Trial 450 finished with value: 0.7121605215430402 and parameters: {'learning_rate': 0.25900351567805185, 'max_leaf_nodes': 119, 'max_depth': 2, 'min_samples_leaf': 20, 'l2_regularization': 1.0801951206643308}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:22,533] Trial 451 finished with value: 0.7116648255993758 and parameters: {'learning_rate': 0.22224245663436196, 'max_leaf_nodes': 114, 'max_depth': 4, 'min_samples_leaf': 10, 'l2_regularization': 0.6172013823622661}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:24,419] Trial 452 finished with value: 0.7129374315893016 and parameters: {'learning_rate': 0.14556606737467007, 'max_leaf_nodes': 104, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.0385430997451064}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:26,163] Trial 453 finished with value: 0.712574374353865 and parameters: {'learning_rate': 0.19661519151289572, 'max_leaf_nodes': 132, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.1442483802240393}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:27,689] Trial 454 finished with value: 0.7115742580445661 and parameters: {'learning_rate': 0.16430322240648612, 'max_leaf_nodes': 126, 'max_depth': 3, 'min_samples_leaf': 19, 'l2_regularization': 1.0115238299298}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:29,077] Trial 455 finished with value: 0.7093800608325495 and parameters: {'learning_rate': 0.26110193231942497, 'max_leaf_nodes': 110, 'max_depth': 9, 'min_samples_leaf': 13, 'l2_regularization': 0.9572961557093139}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:31,130] Trial 456 finished with value: 0.6983749907295296 and parameters: {'learning_rate': 0.036672995072528455, 'max_leaf_nodes': 117, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.0749987613854046}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:32,861] Trial 457 finished with value: 0.7123234071135982 and parameters: {'learning_rate': 0.22994543264339012, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.1229950197643985}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:34,143] Trial 458 finished with value: 0.7112816015886994 and parameters: {'learning_rate': 0.18200133881634573, 'max_leaf_nodes': 134, 'max_depth': 5, 'min_samples_leaf': 10, 'l2_regularization': 1.1643232762182978}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:36,164] Trial 459 finished with value: 0.7124787082793816 and parameters: {'learning_rate': 0.14562216638607708, 'max_leaf_nodes': 121, 'max_depth': 2, 'min_samples_leaf': 23, 'l2_regularization': 1.2389773986444048}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:37,712] Trial 460 finished with value: 0.7129779654254028 and parameters: {'learning_rate': 0.20898087428231168, 'max_leaf_nodes': 129, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.6836006331715208}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:39,519] Trial 461 finished with value: 0.7132461908191419 and parameters: {'learning_rate': 0.16835810771272344, 'max_leaf_nodes': 111, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.0253444378436463}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:40,863] Trial 462 finished with value: 0.7132000913900043 and parameters: {'learning_rate': 0.2359294794962626, 'max_leaf_nodes': 117, 'max_depth': 3, 'min_samples_leaf': 13, 'l2_regularization': 0.9825752049620718}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:42,189] Trial 463 finished with value: 0.7113654768231732 and parameters: {'learning_rate': 0.19839950604200496, 'max_leaf_nodes': 104, 'max_depth': 6, 'min_samples_leaf': 18, 'l2_regularization': 1.0619601827594864}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:44,233] Trial 464 finished with value: 0.6804873617165714 and parameters: {'learning_rate': 0.01846004835093502, 'max_leaf_nodes': 127, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 0.9517956471822526}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:46,355] Trial 465 finished with value: 0.6166267511912633 and parameters: {'learning_rate': 0.0019443548871304092, 'max_leaf_nodes': 120, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.5954972097785156}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:48,656] Trial 466 finished with value: 0.7091216099635356 and parameters: {'learning_rate': 0.0875076512598454, 'max_leaf_nodes': 134, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 1.1020728249514522}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:50,590] Trial 467 finished with value: 0.7129344279872939 and parameters: {'learning_rate': 0.15580213612680194, 'max_leaf_nodes': 114, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 0.5530136816079502}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:52,297] Trial 468 finished with value: 0.7120761351314451 and parameters: {'learning_rate': 0.2595505904934613, 'max_leaf_nodes': 122, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 1.019132884824706}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:54,175] Trial 469 finished with value: 0.7124430481288053 and parameters: {'learning_rate': 0.13041663903490752, 'max_leaf_nodes': 109, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.1839883458067872}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:55,927] Trial 470 finished with value: 0.7122655194422858 and parameters: {'learning_rate': 0.18684251120030074, 'max_leaf_nodes': 130, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.9057029802362929}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:57,521] Trial 471 finished with value: 0.7124912379185595 and parameters: {'learning_rate': 0.20944254150851468, 'max_leaf_nodes': 126, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.0823666135857557}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:51:59,621] Trial 472 finished with value: 0.7128191861774111 and parameters: {'learning_rate': 0.09978382588823653, 'max_leaf_nodes': 118, 'max_depth': 3, 'min_samples_leaf': 21, 'l2_regularization': 0.9789951001892448}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:01,507] Trial 473 finished with value: 0.7133483148610873 and parameters: {'learning_rate': 0.1591470799354361, 'max_leaf_nodes': 137, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.0441411433308245}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:03,588] Trial 474 finished with value: 0.6071844990838776 and parameters: {'learning_rate': 0.0010148919013083513, 'max_leaf_nodes': 95, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.1213362300945424}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:05,129] Trial 475 finished with value: 0.7127932713338805 and parameters: {'learning_rate': 0.23555492624004742, 'max_leaf_nodes': 114, 'max_depth': 2, 'min_samples_leaf': 17, 'l2_regularization': 0.6432108939112441}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:06,780] Trial 476 finished with value: 0.7102383277647322 and parameters: {'learning_rate': 0.13751386301798035, 'max_leaf_nodes': 122, 'max_depth': 3, 'min_samples_leaf': 19, 'l2_regularization': 0.9339244169794522}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:08,576] Trial 477 finished with value: 0.7131763172535599 and parameters: {'learning_rate': 0.17331138065600585, 'max_leaf_nodes': 131, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.7155252224299782}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:10,763] Trial 478 finished with value: 0.7122020023527604 and parameters: {'learning_rate': 0.11079186879369371, 'max_leaf_nodes': 108, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.003586932664158}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:12,132] Trial 479 finished with value: 0.7132480173726319 and parameters: {'learning_rate': 0.29952667441183267, 'max_leaf_nodes': 125, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.0583956663127443}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:14,033] Trial 480 finished with value: 0.7138783205080879 and parameters: {'learning_rate': 0.19853805087748846, 'max_leaf_nodes': 118, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.325931271663525}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:16,024] Trial 481 finished with value: 0.7110673112651124 and parameters: {'learning_rate': 0.2158511135123244, 'max_leaf_nodes': 117, 'max_depth': 2, 'min_samples_leaf': 174, 'l2_regularization': 1.3408044348234045}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:18,054] Trial 482 finished with value: 0.7121020819353621 and parameters: {'learning_rate': 0.18997574182067137, 'max_leaf_nodes': 102, 'max_depth': 2, 'min_samples_leaf': 47, 'l2_regularization': 1.4079449039501462}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:19,144] Trial 483 finished with value: 0.7111855386282077 and parameters: {'learning_rate': 0.26961417849016284, 'max_leaf_nodes': 112, 'max_depth': 6, 'min_samples_leaf': 19, 'l2_regularization': 1.2826026224529359}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:20,639] Trial 484 finished with value: 0.7125588259416544 and parameters: {'learning_rate': 0.23580071385513074, 'max_leaf_nodes': 109, 'max_depth': 2, 'min_samples_leaf': 15, 'l2_regularization': 1.0087878490495157}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:21,981] Trial 485 finished with value: 0.7121389550289269 and parameters: {'learning_rate': 0.1980799930980386, 'max_leaf_nodes': 117, 'max_depth': 3, 'min_samples_leaf': 22, 'l2_regularization': 1.139512873563241}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:24,392] Trial 486 finished with value: 0.7071426372953739 and parameters: {'learning_rate': 0.07293738142869179, 'max_leaf_nodes': 140, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.084945026635513}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:26,333] Trial 487 finished with value: 0.7132951185536027 and parameters: {'learning_rate': 0.20991831760697585, 'max_leaf_nodes': 121, 'max_depth': 2, 'min_samples_leaf': 18, 'l2_regularization': 0.9577736361956939}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:28,229] Trial 488 finished with value: 0.7128133880608656 and parameters: {'learning_rate': 0.18257029487861068, 'max_leaf_nodes': 115, 'max_depth': 2, 'min_samples_leaf': 26, 'l2_regularization': 1.203122285935632}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:29,794] Trial 489 finished with value: 0.7125691768465403 and parameters: {'learning_rate': 0.24173984008322486, 'max_leaf_nodes': 105, 'max_depth': 2, 'min_samples_leaf': 10, 'l2_regularization': 1.365025869378096}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:31,716] Trial 490 finished with value: 0.7113766278635643 and parameters: {'learning_rate': 0.21806506646693696, 'max_leaf_nodes': 134, 'max_depth': 2, 'min_samples_leaf': 110, 'l2_regularization': 1.304873442374206}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:32,741] Trial 491 finished with value: 0.709359200688496 and parameters: {'learning_rate': 0.26212489384581994, 'max_leaf_nodes': 128, 'max_depth': 4, 'min_samples_leaf': 16, 'l2_regularization': 1.4798593745392958}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:34,578] Trial 492 finished with value: 0.7121585769993584 and parameters: {'learning_rate': 0.17466978750622114, 'max_leaf_nodes': 120, 'max_depth': 2, 'min_samples_leaf': 13, 'l2_regularization': 1.0457425229484545}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:36,194] Trial 493 finished with value: 0.7119476962937239 and parameters: {'learning_rate': 0.19238190689299872, 'max_leaf_nodes': 111, 'max_depth': 2, 'min_samples_leaf': 21, 'l2_regularization': 0.9969341487254005}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:37,712] Trial 494 finished with value: 0.7124944804262822 and parameters: {'learning_rate': 0.22879640421697872, 'max_leaf_nodes': 124, 'max_depth': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.9043445366317803}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:39,159] Trial 495 finished with value: 0.7114995589443363 and parameters: {'learning_rate': 0.1612997745393968, 'max_leaf_nodes': 99, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 1.1137237787940757}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:40,819] Trial 496 finished with value: 0.7122668824815388 and parameters: {'learning_rate': 0.2648340439292446, 'max_leaf_nodes': 130, 'max_depth': 2, 'min_samples_leaf': 140, 'l2_regularization': 1.0331739075834523}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:42,261] Trial 497 finished with value: 0.7118846087410832 and parameters: {'learning_rate': 0.20453779754862478, 'max_leaf_nodes': 116, 'max_depth': 2, 'min_samples_leaf': 14, 'l2_regularization': 1.249740072148184}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:44,150] Trial 498 finished with value: 0.7124965030829421 and parameters: {'learning_rate': 0.17989514168481954, 'max_leaf_nodes': 135, 'max_depth': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.950135092592496}. Best is trial 75 with value: 0.7142092903514289.\n",
      "[I 2025-07-04 10:52:45,779] Trial 499 finished with value: 0.711962135575847 and parameters: {'learning_rate': 0.22940395042114584, 'max_leaf_nodes': 120, 'max_depth': 2, 'min_samples_leaf': 24, 'l2_regularization': 0.6892853683285198}. Best is trial 75 with value: 0.7142092903514289.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search complete in 00:16:09.\n",
      "\n",
      "Top 5 Optuna Search Results (F1 Score):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_l2_regularization</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_max_leaf_nodes</th>\n",
       "      <th>params_min_samples_leaf</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>0.714209</td>\n",
       "      <td>2025-07-04 10:39:42.873828</td>\n",
       "      <td>2025-07-04 10:39:45.386681</td>\n",
       "      <td>0 days 00:00:02.512853</td>\n",
       "      <td>0.391190</td>\n",
       "      <td>0.087329</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>414</td>\n",
       "      <td>0.713946</td>\n",
       "      <td>2025-07-04 10:50:19.545653</td>\n",
       "      <td>2025-07-04 10:50:21.247960</td>\n",
       "      <td>0 days 00:00:01.702307</td>\n",
       "      <td>1.187571</td>\n",
       "      <td>0.193354</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>314</td>\n",
       "      <td>0.713941</td>\n",
       "      <td>2025-07-04 10:47:17.532220</td>\n",
       "      <td>2025-07-04 10:47:19.284623</td>\n",
       "      <td>0 days 00:00:01.752403</td>\n",
       "      <td>0.569178</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>18</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>0.713926</td>\n",
       "      <td>2025-07-04 10:49:51.337436</td>\n",
       "      <td>2025-07-04 10:49:53.127735</td>\n",
       "      <td>0 days 00:00:01.790299</td>\n",
       "      <td>1.081457</td>\n",
       "      <td>0.242891</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>16</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>426</td>\n",
       "      <td>0.713906</td>\n",
       "      <td>2025-07-04 10:50:39.189551</td>\n",
       "      <td>2025-07-04 10:50:40.681115</td>\n",
       "      <td>0 days 00:00:01.491564</td>\n",
       "      <td>1.001378</td>\n",
       "      <td>0.297971</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number     value             datetime_start          datetime_complete  \\\n",
       "75       75  0.714209 2025-07-04 10:39:42.873828 2025-07-04 10:39:45.386681   \n",
       "414     414  0.713946 2025-07-04 10:50:19.545653 2025-07-04 10:50:21.247960   \n",
       "314     314  0.713941 2025-07-04 10:47:17.532220 2025-07-04 10:47:19.284623   \n",
       "396     396  0.713926 2025-07-04 10:49:51.337436 2025-07-04 10:49:53.127735   \n",
       "426     426  0.713906 2025-07-04 10:50:39.189551 2025-07-04 10:50:40.681115   \n",
       "\n",
       "                  duration  params_l2_regularization  params_learning_rate  \\\n",
       "75  0 days 00:00:02.512853                  0.391190              0.087329   \n",
       "414 0 days 00:00:01.702307                  1.187571              0.193354   \n",
       "314 0 days 00:00:01.752403                  0.569178              0.157475   \n",
       "396 0 days 00:00:01.790299                  1.081457              0.242891   \n",
       "426 0 days 00:00:01.491564                  1.001378              0.297971   \n",
       "\n",
       "     params_max_depth  params_max_leaf_nodes  params_min_samples_leaf  \\\n",
       "75                  3                    115                       10   \n",
       "414                 2                    121                       14   \n",
       "314                 2                    116                       18   \n",
       "396                 2                    127                       16   \n",
       "426                 2                    110                       13   \n",
       "\n",
       "        state  \n",
       "75   COMPLETE  \n",
       "414  COMPLETE  \n",
       "314  COMPLETE  \n",
       "396  COMPLETE  \n",
       "426  COMPLETE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best F1 Score from Optuna: 0.7142\n",
      "Best Parameters: {'learning_rate': 0.08732936744092441, 'max_leaf_nodes': 115, 'max_depth': 3, 'min_samples_leaf': 10, 'l2_regularization': 0.3911899763454227}\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Define the objective function for Optuna to optimize.\n",
    "# The function takes a 'trial' object, which suggests hyperparameter values.\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space using Optuna's suggestion methods.\n",
    "    # This is equivalent to the distribution dictionary in RandomizedSearchCV.\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 16, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 10, 200),\n",
    "        'l2_regularization': trial.suggest_float('l2_regularization', 0.0, 2.0, log=False)\n",
    "    }\n",
    "\n",
    "    # Create a new instance of the model with the suggested hyperparameters for this trial.\n",
    "    # The 'gb__' prefix targets the model within the pipeline.\n",
    "    model = pipelined_model.set_params(**{f\"gb__{key}\": value for key, value in params.items()})\n",
    "\n",
    "    # Set up the same stratified K-Fold cross-validator\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    # Perform cross-validation and get the mean F1 score\n",
    "    f1_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='f1')\n",
    "    \n",
    "    # Optuna will try to maximize this return value\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# Create a study object. 'direction=\"maximize\"' tells Optuna we want to maximize the F1 score.\n",
    "study = optuna.create_study(direction='maximize', study_name='hgbc_f1_optimization')\n",
    "\n",
    "print(\"Running Optuna Search...\")\n",
    "# Start the timer\n",
    "start_time_optuna = time.time()\n",
    "\n",
    "# Start the optimization process. Optuna will call the 'objective' function for n_trials.\n",
    "try:\n",
    "    study.optimize(objective, n_trials=500)  # Run for 500 trials\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Study stopped manually.\") # Allows stopping the study early\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time_optuna = time.time() - start_time_optuna\n",
    "print(f\"Search complete in {format_hms(elapsed_time_optuna)}.\")\n",
    "\n",
    "\n",
    "# Create a DataFrame from the study's trials to display results\n",
    "optuna_results_df = study.trials_dataframe()\n",
    "\n",
    "# Sort by the best value (F1 score) and display the top 5 trials\n",
    "top_5_optuna_results = optuna_results_df.sort_values(by='value', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Optuna Search Results (F1 Score):\")\n",
    "display(top_5_optuna_results.head())\n",
    "\n",
    "# Print the best score and parameters found\n",
    "print(f\"\\nBest F1 Score from Optuna: {study.best_value:.4f}\")\n",
    "print(f\"Best Parameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 Graded Answer\n",
    "\n",
    "Set `a3` to the mean F1 score of the best model found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a3 = study.best_value                     # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3 = 0.7142\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a3 = {a3:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Final Model Evaluation on Test Set\n",
    "\n",
    "In this problem, you will take the best hyperparameter configuration you found in your earlier experiments (Randomized Search or Optuna) and fully evaluate the resulting model on the test set.\n",
    "\n",
    "**Background:**\n",
    "When performing hyperparameter tuning, we typically optimize for a single metric (e.g., F1). However, before deployment, it is essential to check **all relevant metrics** on the final test set to understand the model’s behavior in a balanced way.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Take the best hyperparameters you found in Problems 2 or 3 and apply them to your `pipelined_model`.\n",
    "2. Re-train this final tuned model on the **entire training set** (not just the folds).\n",
    "3. Evaluate the final model on the heldout **test set**, reporting the following metrics:\n",
    "\n",
    "   * Precision\n",
    "   * Recall\n",
    "   * F1 score\n",
    "   * Balanced accuracy\n",
    "4. Use `classification_report` **on the test set** to print precision, recall, and F1 score, and use `balanced_accuracy_score` separately to calculate and print balanced accuracy.\n",
    "5. Answer the graded questions.\n",
    "\n",
    "**Note:** We evaluate the metrics on the test set because it was never seen during training or hyperparameter tuning. This gives us an unbiased estimate of how the model will perform on truly unseen data. Evaluating on the training set would be misleading, because the model has already learned from that data and could appear artificially good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model on the entire training set...\n",
      "Training complete.\n",
      "\n",
      "--- Final Model Evaluation on Test Set ---\n",
      "Balanced Accuracy: 0.8465\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9533    0.8209    0.8821      7431\n",
      "           1     0.6050    0.8721    0.7144      2338\n",
      "\n",
      "    accuracy                         0.8331      9769\n",
      "   macro avg     0.7792    0.8465    0.7983      9769\n",
      "weighted avg     0.8699    0.8331    0.8420      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Use the best hyperparameters found from your best experiment (e.g., Optuna)\n",
    "# The keys need to be prefixed with 'gb__' to target the model inside the pipeline.\n",
    "best_params = {f\"gb__{key}\": value for key, value in study.best_params.items()}\n",
    "\n",
    "# Create a new pipeline instance with the best hyperparameters\n",
    "final_model = pipelined_model.set_params(**best_params)\n",
    "\n",
    "# Train the final model on the entire training dataset\n",
    "print(\"Training final model on the entire training set...\")\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Make predictions on the unseen test set\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "\n",
    "# --- Evaluate the final model on the test set ---\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Generate the classification report (includes precision, recall, f1-score)\n",
    "class_report = classification_report(y_test, y_pred_test, digits=4)\n",
    "\n",
    "# Generate a dictionary for the classification report\n",
    "report_dict = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "\n",
    "# Print the final evaluation metrics\n",
    "print(\"\\n--- Final Model Evaluation on Test Set ---\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 Graded Questions\n",
    "\n",
    "- Set `a4a` to the balanced accuracy score of the best model.\n",
    "- Set `a4b` to the macro average precision of this model.\n",
    "- Set `a4c` to the macro average recall score of the this model.\n",
    "\n",
    "**Note:** Macro average takes the mean of each class’s precision/recall without considering how many samples each class has, which is appropriate for a balanced evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4a = balanced_acc                     # replace 0 with your answer, use variable or expression from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4a = 0.8465\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4a = {a4a:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4b = report_dict['macro avg']['precision']                     # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4b = 0.7792\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4b = {a4b:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4c = report_dict['macro avg']['recall']                     # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4c = 0.8465\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4c = {a4c:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Understanding Precision, Recall, F1, and Balanced Accuracy\n",
    "\n",
    "**Tutorial**\n",
    "\n",
    "In binary classification, you will often evaluate these key metrics:\n",
    "\n",
    "* **Precision**: *Of all the positive predictions the model made, how many were actually correct?*\n",
    "\n",
    "  * High precision = few false positives\n",
    "  * Low precision = many false positives\n",
    "\n",
    "* **Recall**: *Of all the actual positive cases, how many did the model correctly identify?*\n",
    "\n",
    "  * High recall = few false negatives\n",
    "  * Low recall = many false negatives\n",
    "\n",
    "* **F1 score**: The harmonic mean of precision and recall, which balances them in a single measure.\n",
    "\n",
    "  * F1 is **highest** when precision and recall are both high and similar in value.\n",
    "  * If precision and recall are unbalanced, F1 will drop to reflect that imbalance.\n",
    "\n",
    "* **Balanced accuracy**: The average of recall across both classes (positive and negative).\n",
    "\n",
    "  * It ensures the classifier is performing reasonably well on *both* groups, correcting for class imbalance.\n",
    "  * Balanced accuracy is especially important if the classes are very unequal in size.\n",
    "\n",
    "**Typical trade-offs to remember:**\n",
    "\n",
    "* **Higher recall, lower precision**: the model finds most true positives but also mislabels some negatives as positives\n",
    "* **Higher precision, lower recall**: the model is strict about positive predictions, but misses some true positives\n",
    "* **Balanced precision and recall (good F1)**: a practical compromise\n",
    "* **Balanced accuracy**: checks fairness across both classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Problem 5 Graded Question (multiple choice)\n",
    "\n",
    "A bank uses your model to identify customers earning over $50K for a premium product invitation. Based on your final test set evaluation, including macro-averaged precision and recall, which of the following best describes what might happen?\n",
    "\n",
    "(1) The bank will miss some eligible high-income customers, but will avoid marketing mistakes by sending invitations only to those it is  confident about.\n",
    "\n",
    "(2) The bank will successfully reach most high-income customers, but will also waste resources sending invitations to some low-income customers.\n",
    "\n",
    "(3) The bank will perfectly identify all high-income and low-income customers, resulting in no wasted invitations and no missed opportunities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a5 = 2                     # replace 0 with one of 1, 2, or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a5 = 2\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a5 = {a5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix One: Feature Engineering\n",
    "\n",
    "Here are some practical feature-engineering tweaks worth considering (beyond simply ordinal-encoding the categoricals)\n",
    "\n",
    "| Feature(s)                                                           | Why the tweak can help                                                                                                                                                     | How to do it (quick version)                                                                                                                                                    | Keep / drop?      |\n",
    "| -------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------- |\n",
    "| **`fnlwgt`**                                                         | Survey sampling weight, not a predictor. Leaving it in often lets the model “cheat.”                                                                                       | `df = df.drop(columns=[\"fnlwgt\"])`                                                                                                                                              | **Drop**          |\n",
    "| **`education` *vs.* `education-num`**                                | They encode the **same** information twice (categorical label and its ordinal rank). Keeping both is redundant and can cause leakage of a perfectly predictive feature.    | Usually keep **only one**. For tree models `education-num` is simplest: `df = df.drop(columns=[\"education\"])`                                                                   | **Drop one**      |\n",
    "| **`capital-gain`, `capital-loss`**                                   | Highly skewed; most values are zero with a long upper tail. The sign (gain vs. loss) matters, but treating them separately wastes a feature slot.                          | 1) Combine: `df[\"capital_net\"] = df[\"capital-gain\"] - df[\"capital-loss\"]`; 2) Log-transform to reduce skew: `df[\"capital_net_log\"] = np.log1p(df[\"capital_net\"].clip(lower=0))` | Replace originals |\n",
    "| **`age`, `hours-per-week`**                                          | Continuous but with natural plateaus—trees handle splits fine, yet log or square-root scaling can soften extreme values; bucketing makes partial-dependence plots clearer. | Simple bucket: `df[\"age_bin\"] = pd.cut(df[\"age\"], bins=[16,25,35,45,55,65,90])` (optional)                                                                                      | Optional          |\n",
    "| **Missing categories** (`workclass`, `occupation`, `native-country`) | HGB handles `-1`/`-2` codes fine, but you may want *explicit* “Missing” bucket for interpretability.                                                                       | Use `encoded_missing_value=-2` during encoding.                                                                                                            | Keep as is        |\n",
    "| **Rare categories in `native-country`**                              | Hundreds of low-frequency countries dilute signal; grouping boosts stability.                                                                                              | Map infrequent categories to “Other”:                                                                                                                                           |                   |\n",
    "\n",
    "\n",
    "#### Minimum set of tweaks (good baseline, low effort)\n",
    "\n",
    "1. **Drop `fnlwgt`.**  \n",
    "2. **Keep `education-num`, drop `education`.**  \n",
    "3. **Combine `capital-gain` and `capital-loss` into `capital_net`** (optionally add a log-scaled version).  \n",
    "4. Leave other numeric/categorical features as is; your histogram-GBDT will cope.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
